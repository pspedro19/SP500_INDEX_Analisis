{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "   ---------------------------------------- 0.0/250.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/250.9 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 41.0/250.9 kB 653.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 250.9/250.9 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 18:40:03,349 [INFO] ================================================================================\n",
      "2025-03-27 18:40:03,350 [INFO] INICIANDO PROCESO: MyinvestingreportNormal\n",
      "2025-03-27 18:40:03,352 [INFO] Archivo de configuración: Data Engineering.xlsx\n",
      "2025-03-27 18:40:03,354 [INFO] Directorio raíz de datos: data/Macro/raw\n",
      "2025-03-27 18:40:03,355 [INFO] Fecha y hora: 2025-03-27 18:40:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 18:40:03,356 [INFO] ================================================================================\n",
      "2025-03-27 18:40:03,357 [INFO] Iniciando proceso completo MyinvestingreportNormal...\n",
      "2025-03-27 18:40:03,360 [INFO] Leyendo archivo de configuración...\n",
      "2025-03-27 18:40:03,396 [INFO] Se encontraron 28 configuraciones para procesar\n",
      "2025-03-27 18:40:03,398 [INFO] \n",
      "Procesando: Australia_10Y_Bond (bond)\n",
      "2025-03-27 18:40:03,398 [INFO] - Archivo: Australia_10Y_Bond\n",
      "2025-03-27 18:40:03,399 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:03,401 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Australia_10Y_Bond.csv\n",
      "2025-03-27 18:40:03,410 [INFO] - Filas encontradas: 3810\n",
      "2025-03-27 18:40:03,412 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:03,413 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:04,712 [INFO] - Valores no nulos en TARGET: 3810\n",
      "2025-03-27 18:40:04,714 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:04,715 [INFO] - Periodo: 2014-01-01 a 2025-03-26\n",
      "2025-03-27 18:40:04,716 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:04,719 [INFO] \n",
      "Procesando: Italy_10Y_Bond (bond)\n",
      "2025-03-27 18:40:04,721 [INFO] - Archivo: Italy_10Y_Bond\n",
      "2025-03-27 18:40:04,721 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:04,722 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Italy_10Y_Bond.csv\n",
      "2025-03-27 18:40:04,731 [INFO] - Filas encontradas: 3238\n",
      "2025-03-27 18:40:04,733 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:04,735 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:05,941 [INFO] - Valores no nulos en TARGET: 3238\n",
      "2025-03-27 18:40:05,943 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:05,944 [INFO] - Periodo: 2014-01-02 a 2025-03-26\n",
      "2025-03-27 18:40:05,947 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:05,949 [INFO] \n",
      "Procesando: Japan_10Y_Bond (bond)\n",
      "2025-03-27 18:40:05,950 [INFO] - Archivo: Japan_10Y_Bond\n",
      "2025-03-27 18:40:05,952 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:05,953 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Japan_10Y_Bond.csv\n",
      "2025-03-27 18:40:05,962 [INFO] - Filas encontradas: 3203\n",
      "2025-03-27 18:40:05,965 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:05,967 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:07,279 [INFO] - Valores no nulos en TARGET: 3203\n",
      "2025-03-27 18:40:07,280 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:07,280 [INFO] - Periodo: 2014-01-06 a 2025-03-26\n",
      "2025-03-27 18:40:07,282 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:07,285 [INFO] \n",
      "Procesando: UK_10Y_Bond (bond)\n",
      "2025-03-27 18:40:07,288 [INFO] - Archivo: UK_10Y_Bond\n",
      "2025-03-27 18:40:07,289 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:07,290 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\UK_10Y_Bond.csv\n",
      "2025-03-27 18:40:07,302 [INFO] - Filas encontradas: 3424\n",
      "2025-03-27 18:40:07,307 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:07,309 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:08,473 [INFO] - Valores no nulos en TARGET: 3424\n",
      "2025-03-27 18:40:08,475 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:08,476 [INFO] - Periodo: 2014-01-01 a 2025-03-26\n",
      "2025-03-27 18:40:08,479 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:08,481 [INFO] \n",
      "Procesando: Germany_10Y_Bond (bond)\n",
      "2025-03-27 18:40:08,481 [INFO] - Archivo: Germany_10Y_Bond\n",
      "2025-03-27 18:40:08,482 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:08,484 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Germany_10Y_Bond.csv\n",
      "2025-03-27 18:40:08,494 [INFO] - Filas encontradas: 3075\n",
      "2025-03-27 18:40:08,497 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:08,499 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:09,685 [INFO] - Valores no nulos en TARGET: 3075\n",
      "2025-03-27 18:40:09,687 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:09,687 [INFO] - Periodo: 2014-01-02 a 2025-03-26\n",
      "2025-03-27 18:40:09,687 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:09,688 [INFO] \n",
      "Procesando: Canada_10Y_Bond (bond)\n",
      "2025-03-27 18:40:09,688 [INFO] - Archivo: Canada_10Y_Bond\n",
      "2025-03-27 18:40:09,690 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:09,690 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Canada_10Y_Bond.csv\n",
      "2025-03-27 18:40:09,696 [INFO] - Filas encontradas: 2965\n",
      "2025-03-27 18:40:09,699 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:09,700 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:10,709 [INFO] - Valores no nulos en TARGET: 2965\n",
      "2025-03-27 18:40:10,710 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:10,711 [INFO] - Periodo: 2014-01-01 a 2025-03-26\n",
      "2025-03-27 18:40:10,713 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:10,715 [INFO] \n",
      "Procesando: China_10Y_Bond (bond)\n",
      "2025-03-27 18:40:10,715 [INFO] - Archivo: China_10Y_Bond\n",
      "2025-03-27 18:40:10,716 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:10,718 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\China_10Y_Bond.csv\n",
      "2025-03-27 18:40:10,723 [INFO] - Filas encontradas: 2914\n",
      "2025-03-27 18:40:10,729 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:10,729 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:11,788 [INFO] - Valores no nulos en TARGET: 2914\n",
      "2025-03-27 18:40:11,789 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:11,789 [INFO] - Periodo: 2014-01-02 a 2025-03-26\n",
      "2025-03-27 18:40:11,789 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:11,791 [INFO] \n",
      "Procesando: CrudeOil_WTI (commodities)\n",
      "2025-03-27 18:40:11,791 [INFO] - Archivo: CrudeOil_WTI\n",
      "2025-03-27 18:40:11,791 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:11,792 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\CrudeOil_WTI.csv\n",
      "2025-03-27 18:40:11,798 [INFO] - Filas encontradas: 2953\n",
      "2025-03-27 18:40:11,801 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:11,801 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:12,861 [INFO] - Valores no nulos en TARGET: 2953\n",
      "2025-03-27 18:40:12,861 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:12,862 [INFO] - Periodo: 2014-01-01 a 2025-03-26\n",
      "2025-03-27 18:40:12,864 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:12,864 [INFO] \n",
      "Procesando: Gold_Spot (commodities)\n",
      "2025-03-27 18:40:12,865 [INFO] - Archivo: Gold_Spot\n",
      "2025-03-27 18:40:12,865 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:12,865 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\Gold_Spot.csv\n",
      "2025-03-27 18:40:12,876 [INFO] - Filas encontradas: 2874\n",
      "2025-03-27 18:40:12,879 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:12,881 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:13,966 [INFO] - Valores no nulos en TARGET: 2874\n",
      "2025-03-27 18:40:13,966 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:13,968 [INFO] - Periodo: 2014-01-02 a 2025-03-26\n",
      "2025-03-27 18:40:13,968 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:13,969 [INFO] \n",
      "Procesando: Silver_Spot (commodities)\n",
      "2025-03-27 18:40:13,971 [INFO] - Archivo: Silver_Spot\n",
      "2025-03-27 18:40:13,972 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:13,972 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\Silver_Spot.csv\n",
      "2025-03-27 18:40:13,979 [INFO] - Filas encontradas: 2911\n",
      "2025-03-27 18:40:13,981 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:13,982 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:15,103 [INFO] - Valores no nulos en TARGET: 2911\n",
      "2025-03-27 18:40:15,105 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:15,105 [INFO] - Periodo: 2014-01-02 a 2025-03-26\n",
      "2025-03-27 18:40:15,106 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:15,108 [INFO] \n",
      "Procesando: Copper_Futures (commodities)\n",
      "2025-03-27 18:40:15,109 [INFO] - Archivo: Copper_Futures\n",
      "2025-03-27 18:40:15,109 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:15,111 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\Copper_Futures.csv\n",
      "2025-03-27 18:40:15,119 [INFO] - Filas encontradas: 2908\n",
      "2025-03-27 18:40:15,122 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:15,123 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:16,300 [INFO] - Valores no nulos en TARGET: 2908\n",
      "2025-03-27 18:40:16,301 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:16,301 [INFO] - Periodo: 2014-01-02 a 2025-03-26\n",
      "2025-03-27 18:40:16,303 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:16,304 [INFO] \n",
      "Procesando: Platinum_Spot (commodities)\n",
      "2025-03-27 18:40:16,306 [INFO] - Archivo: Platinum_Spot\n",
      "2025-03-27 18:40:16,306 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:16,308 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\Platinum_Spot.csv\n",
      "2025-03-27 18:40:16,325 [INFO] - Filas encontradas: 3463\n",
      "2025-03-27 18:40:16,326 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:16,328 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:17,498 [INFO] - Valores no nulos en TARGET: 3463\n",
      "2025-03-27 18:40:17,500 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:17,500 [INFO] - Periodo: 2014-01-01 a 2025-03-26\n",
      "2025-03-27 18:40:17,502 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:17,505 [INFO] \n",
      "Procesando: EUR_USD_Spot (exchange_rate)\n",
      "2025-03-27 18:40:17,505 [INFO] - Archivo: EUR_USD_Spot\n",
      "2025-03-27 18:40:17,505 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:17,507 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\EUR_USD_Spot.csv\n",
      "2025-03-27 18:40:17,514 [INFO] - Filas encontradas: 2932\n",
      "2025-03-27 18:40:17,518 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:17,520 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:18,689 [INFO] - Valores no nulos en TARGET: 2932\n",
      "2025-03-27 18:40:18,690 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:18,690 [INFO] - Periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-27 18:40:18,692 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:18,692 [INFO] \n",
      "Procesando: GBP_USD_Spot (exchange_rate)\n",
      "2025-03-27 18:40:18,692 [INFO] - Archivo: GBP_USD_Spot\n",
      "2025-03-27 18:40:18,693 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:18,695 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\GBP_USD_Spot.csv\n",
      "2025-03-27 18:40:18,699 [INFO] - Filas encontradas: 2932\n",
      "2025-03-27 18:40:18,701 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:18,702 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:19,697 [INFO] - Valores no nulos en TARGET: 2932\n",
      "2025-03-27 18:40:19,699 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:19,700 [INFO] - Periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-27 18:40:19,700 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:19,702 [INFO] \n",
      "Procesando: JPY_USD_Spot (exchange_rate)\n",
      "2025-03-27 18:40:19,703 [INFO] - Archivo: JPY_USD_Spot\n",
      "2025-03-27 18:40:19,705 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:19,706 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\JPY_USD_Spot.csv\n",
      "2025-03-27 18:40:19,714 [INFO] - Filas encontradas: 2932\n",
      "2025-03-27 18:40:19,715 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:19,717 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:20,798 [INFO] - Valores no nulos en TARGET: 2932\n",
      "2025-03-27 18:40:20,801 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:20,801 [INFO] - Periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-27 18:40:20,801 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:20,802 [INFO] \n",
      "Procesando: CNY_USD_Spot (exchange_rate)\n",
      "2025-03-27 18:40:20,802 [INFO] - Archivo: CNY_USD_Spot\n",
      "2025-03-27 18:40:20,804 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:20,805 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\CNY_USD_Spot.csv\n",
      "2025-03-27 18:40:20,813 [INFO] - Filas encontradas: 2933\n",
      "2025-03-27 18:40:20,816 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:20,817 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:21,993 [INFO] - Valores no nulos en TARGET: 2933\n",
      "2025-03-27 18:40:21,994 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:21,994 [INFO] - Periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-27 18:40:21,996 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:21,996 [INFO] \n",
      "Procesando: AUD_USD_Spot (exchange_rate)\n",
      "2025-03-27 18:40:21,997 [INFO] - Archivo: AUD_USD_Spot\n",
      "2025-03-27 18:40:21,998 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:22,000 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\AUD_USD_Spot.csv\n",
      "2025-03-27 18:40:22,006 [INFO] - Filas encontradas: 2932\n",
      "2025-03-27 18:40:22,008 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:22,009 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:23,137 [INFO] - Valores no nulos en TARGET: 2932\n",
      "2025-03-27 18:40:23,137 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:23,139 [INFO] - Periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-27 18:40:23,139 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:23,140 [INFO] \n",
      "Procesando: CAD_USD_Spot (exchange_rate)\n",
      "2025-03-27 18:40:23,140 [INFO] - Archivo: CAD_USD_Spot\n",
      "2025-03-27 18:40:23,142 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:23,144 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\CAD_USD_Spot.csv\n",
      "2025-03-27 18:40:23,152 [INFO] - Filas encontradas: 2932\n",
      "2025-03-27 18:40:23,155 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:23,155 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:24,188 [INFO] - Valores no nulos en TARGET: 2932\n",
      "2025-03-27 18:40:24,189 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:24,192 [INFO] - Periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-27 18:40:24,193 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:24,195 [INFO] \n",
      "Procesando: MXN_USD_Spot (exchange_rate)\n",
      "2025-03-27 18:40:24,195 [INFO] - Archivo: MXN_USD_Spot\n",
      "2025-03-27 18:40:24,196 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:24,199 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\MXN_USD_Spot.csv\n",
      "2025-03-27 18:40:24,207 [INFO] - Filas encontradas: 2932\n",
      "2025-03-27 18:40:24,210 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:24,210 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:25,278 [INFO] - Valores no nulos en TARGET: 2932\n",
      "2025-03-27 18:40:25,280 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:25,280 [INFO] - Periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-27 18:40:25,281 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:25,281 [INFO] \n",
      "Procesando: EUR_GBP_Cross (exchange_rate)\n",
      "2025-03-27 18:40:25,283 [INFO] - Archivo: EUR_GBP_Cross\n",
      "2025-03-27 18:40:25,283 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:25,283 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\EUR_GBP_Cross.csv\n",
      "2025-03-27 18:40:25,289 [INFO] - Filas encontradas: 2932\n",
      "2025-03-27 18:40:25,291 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:25,291 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:26,385 [INFO] - Valores no nulos en TARGET: 2932\n",
      "2025-03-27 18:40:26,387 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:26,387 [INFO] - Periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-27 18:40:26,389 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:26,390 [INFO] \n",
      "Procesando: S&P500_Index (index_pricing)\n",
      "2025-03-27 18:40:26,390 [INFO] - Archivo: S&P500_Index\n",
      "2025-03-27 18:40:26,392 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-27 18:40:26,392 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\S&P500_Index.csv\n",
      "2025-03-27 18:40:26,399 [INFO] - Filas encontradas: 2826\n",
      "2025-03-27 18:40:26,404 [INFO] - Columna de fecha identificada: Fecha\n",
      "2025-03-27 18:40:26,405 [WARNING] - AVISO: No se encontró columna 'ULTIMO', usando 'Último'\n",
      "2025-03-27 18:40:27,508 [INFO] - Valores no nulos en TARGET: 2826\n",
      "2025-03-27 18:40:27,509 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:27,510 [INFO] - Periodo: 2014-01-04 a 2025-12-03\n",
      "2025-03-27 18:40:27,510 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:27,512 [INFO] \n",
      "Procesando: NASDAQ_Composite (index_pricing)\n",
      "2025-03-27 18:40:27,513 [INFO] - Archivo: NASDAQ_Composite\n",
      "2025-03-27 18:40:27,515 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-27 18:40:27,517 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\NASDAQ_Composite.csv\n",
      "2025-03-27 18:40:27,529 [INFO] - Filas encontradas: 2826\n",
      "2025-03-27 18:40:27,532 [INFO] - Columna de fecha identificada: Fecha\n",
      "2025-03-27 18:40:27,535 [WARNING] - AVISO: No se encontró columna 'ULTIMO', usando 'Último'\n",
      "2025-03-27 18:40:28,659 [INFO] - Valores no nulos en TARGET: 2826\n",
      "2025-03-27 18:40:28,660 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:28,660 [INFO] - Periodo: 2014-01-04 a 2025-12-03\n",
      "2025-03-27 18:40:28,662 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:28,663 [INFO] \n",
      "Procesando: Russell_2000 (index_pricing)\n",
      "2025-03-27 18:40:28,663 [INFO] - Archivo: Russell_2000\n",
      "2025-03-27 18:40:28,663 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-27 18:40:28,665 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\Russell_2000.csv\n",
      "2025-03-27 18:40:28,672 [INFO] - Filas encontradas: 2840\n",
      "2025-03-27 18:40:28,674 [INFO] - Columna de fecha identificada: Fecha\n",
      "2025-03-27 18:40:28,677 [WARNING] - AVISO: No se encontró columna 'ULTIMO', usando 'Último'\n",
      "2025-03-27 18:40:29,854 [INFO] - Valores no nulos en TARGET: 2840\n",
      "2025-03-27 18:40:29,855 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:29,855 [INFO] - Periodo: 2014-01-04 a 2025-12-03\n",
      "2025-03-27 18:40:29,855 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:29,857 [INFO] \n",
      "Procesando: FTSE_100 (index_pricing)\n",
      "2025-03-27 18:40:29,859 [INFO] - Archivo: FTSE_100\n",
      "2025-03-27 18:40:29,860 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-27 18:40:29,860 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\FTSE_100.csv\n",
      "2025-03-27 18:40:29,870 [INFO] - Filas encontradas: 2840\n",
      "2025-03-27 18:40:29,872 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:29,873 [WARNING] - AVISO: No se encontró columna 'ULTIMO', usando 'Price'\n",
      "2025-03-27 18:40:30,852 [INFO] - Valores no nulos en TARGET: 2840\n",
      "2025-03-27 18:40:30,854 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:30,857 [INFO] - Periodo: 2014-01-02 a 2025-03-27\n",
      "2025-03-27 18:40:30,859 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:30,860 [INFO] \n",
      "Procesando: Nikkei_225 (index_pricing)\n",
      "2025-03-27 18:40:30,862 [INFO] - Archivo: Nikkei_225\n",
      "2025-03-27 18:40:30,862 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-27 18:40:30,863 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\Nikkei_225.csv\n",
      "2025-03-27 18:40:30,874 [INFO] - Filas encontradas: 2741\n",
      "2025-03-27 18:40:30,877 [INFO] - Columna de fecha identificada: Fecha\n",
      "2025-03-27 18:40:30,880 [WARNING] - AVISO: No se encontró columna 'ULTIMO', usando 'Último'\n",
      "2025-03-27 18:40:31,904 [INFO] - Valores no nulos en TARGET: 2741\n",
      "2025-03-27 18:40:31,906 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:31,906 [INFO] - Periodo: 2014-01-04 a 2025-12-03\n",
      "2025-03-27 18:40:31,908 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:31,908 [INFO] \n",
      "Procesando: DAX_30 (index_pricing)\n",
      "2025-03-27 18:40:31,909 [INFO] - Archivo: DAX_30\n",
      "2025-03-27 18:40:31,909 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-27 18:40:31,911 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\DAX_30.csv\n",
      "2025-03-27 18:40:31,920 [INFO] - Filas encontradas: 2851\n",
      "2025-03-27 18:40:31,922 [INFO] - Columna de fecha identificada: Fecha\n",
      "2025-03-27 18:40:31,925 [WARNING] - AVISO: No se encontró columna 'ULTIMO', usando 'Último'\n",
      "2025-03-27 18:40:33,082 [INFO] - Valores no nulos en TARGET: 2851\n",
      "2025-03-27 18:40:33,082 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:33,083 [INFO] - Periodo: 2014-01-04 a 2025-12-03\n",
      "2025-03-27 18:40:33,083 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:33,085 [INFO] \n",
      "Procesando: Shanghai_Composite (index_pricing)\n",
      "2025-03-27 18:40:33,086 [INFO] - Archivo: Shanghai_Composite\n",
      "2025-03-27 18:40:33,086 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-27 18:40:33,088 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\Shanghai_Composite.csv\n",
      "2025-03-27 18:40:33,097 [INFO] - Filas encontradas: 2731\n",
      "2025-03-27 18:40:33,098 [INFO] - Columna de fecha identificada: Date\n",
      "2025-03-27 18:40:33,100 [WARNING] - AVISO: No se encontró columna 'PRICE', usando 'Price'\n",
      "2025-03-27 18:40:34,120 [INFO] - Valores no nulos en TARGET: 2731\n",
      "2025-03-27 18:40:34,121 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:34,121 [INFO] - Periodo: 2014-01-02 a 2025-03-27\n",
      "2025-03-27 18:40:34,123 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:34,126 [INFO] \n",
      "Procesando: VIX_VolatilityIndex (index_pricing)\n",
      "2025-03-27 18:40:34,128 [INFO] - Archivo: VIX_VolatilityIndex\n",
      "2025-03-27 18:40:34,129 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-27 18:40:34,129 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\VIX_VolatilityIndex.csv\n",
      "2025-03-27 18:40:34,141 [INFO] - Filas encontradas: 2860\n",
      "2025-03-27 18:40:34,146 [INFO] - Columna de fecha identificada: Fecha\n",
      "2025-03-27 18:40:34,152 [WARNING] - AVISO: No se encontró columna 'ULTIMO', usando 'Último'\n",
      "2025-03-27 18:40:35,362 [INFO] - Valores no nulos en TARGET: 2860\n",
      "2025-03-27 18:40:35,363 [INFO] - Cobertura: 100.00%\n",
      "2025-03-27 18:40:35,363 [INFO] - Periodo: 2014-01-04 a 2025-12-03\n",
      "2025-03-27 18:40:35,365 [INFO] - Estado: OK\n",
      "2025-03-27 18:40:35,366 [INFO] \n",
      "Generando índice temporal diario...\n",
      "2025-03-27 18:40:35,366 [INFO] - Rango de fechas global: 2014-01-01 a 2025-12-03\n",
      "2025-03-27 18:40:35,368 [INFO] - Total de fechas diarias generadas: 4355\n",
      "2025-03-27 18:40:35,369 [INFO] \n",
      "Combinando datos con índice diario...\n",
      "2025-03-27 18:40:35,369 [INFO] - Combinando: PRICE_Australia_10Y_Bond_bond\n",
      "2025-03-27 18:40:35,372 [INFO] - Combinando: PRICE_Italy_10Y_Bond_bond\n",
      "2025-03-27 18:40:35,375 [INFO] - Combinando: PRICE_Japan_10Y_Bond_bond\n",
      "2025-03-27 18:40:35,379 [INFO] - Combinando: PRICE_UK_10Y_Bond_bond\n",
      "2025-03-27 18:40:35,384 [INFO] - Combinando: PRICE_Germany_10Y_Bond_bond\n",
      "2025-03-27 18:40:35,390 [INFO] - Combinando: PRICE_Canada_10Y_Bond_bond\n",
      "2025-03-27 18:40:35,393 [INFO] - Combinando: PRICE_China_10Y_Bond_bond\n",
      "2025-03-27 18:40:35,398 [INFO] - Combinando: PRICE_CrudeOil_WTI_commodities\n",
      "2025-03-27 18:40:35,403 [INFO] - Combinando: PRICE_Gold_Spot_commodities\n",
      "2025-03-27 18:40:35,407 [INFO] - Combinando: PRICE_Silver_Spot_commodities\n",
      "2025-03-27 18:40:35,412 [INFO] - Combinando: PRICE_Copper_Futures_commodities\n",
      "2025-03-27 18:40:35,417 [INFO] - Combinando: PRICE_Platinum_Spot_commodities\n",
      "2025-03-27 18:40:35,419 [INFO] - Combinando: PRICE_EUR_USD_Spot_exchange_rate\n",
      "2025-03-27 18:40:35,424 [INFO] - Combinando: PRICE_GBP_USD_Spot_exchange_rate\n",
      "2025-03-27 18:40:35,427 [INFO] - Combinando: PRICE_JPY_USD_Spot_exchange_rate\n",
      "2025-03-27 18:40:35,431 [INFO] - Combinando: PRICE_CNY_USD_Spot_exchange_rate\n",
      "2025-03-27 18:40:35,434 [INFO] - Combinando: PRICE_AUD_USD_Spot_exchange_rate\n",
      "2025-03-27 18:40:35,437 [INFO] - Combinando: PRICE_CAD_USD_Spot_exchange_rate\n",
      "2025-03-27 18:40:35,440 [INFO] - Combinando: PRICE_MXN_USD_Spot_exchange_rate\n",
      "2025-03-27 18:40:35,444 [INFO] - Combinando: PRICE_EUR_GBP_Cross_exchange_rate\n",
      "2025-03-27 18:40:35,448 [INFO] - Combinando: ULTIMO_S&P500_Index_index_pricing\n",
      "2025-03-27 18:40:35,452 [INFO] - Combinando: ULTIMO_NASDAQ_Composite_index_pricing\n",
      "2025-03-27 18:40:35,456 [INFO] - Combinando: ULTIMO_Russell_2000_index_pricing\n",
      "2025-03-27 18:40:35,461 [INFO] - Combinando: ULTIMO_FTSE_100_index_pricing\n",
      "2025-03-27 18:40:35,465 [INFO] - Combinando: ULTIMO_Nikkei_225_index_pricing\n",
      "2025-03-27 18:40:35,468 [INFO] - Combinando: ULTIMO_DAX_30_index_pricing\n",
      "2025-03-27 18:40:35,472 [INFO] - Combinando: PRICE_Shanghai_Composite_index_pricing\n",
      "2025-03-27 18:40:35,476 [INFO] - Combinando: ULTIMO_VIX_VolatilityIndex_index_pricing\n",
      "2025-03-27 18:40:35,479 [INFO] - DataFrame combinado: 4355 filas, 29 columnas\n",
      "2025-03-27 18:40:35,481 [INFO] \n",
      "==================================================\n",
      "2025-03-27 18:40:35,481 [INFO] RESUMEN DE COBERTURA FINAL\n",
      "2025-03-27 18:40:35,482 [INFO] ==================================================\n",
      "2025-03-27 18:40:35,482 [INFO] Total indicadores procesados: 28\n",
      "2025-03-27 18:40:35,482 [INFO] Rango de fechas: 2014-01-01 a 2025-12-03\n",
      "2025-03-27 18:40:35,484 [INFO] Total días en la serie: 4355\n",
      "2025-03-27 18:40:35,485 [INFO] \n",
      "Cobertura por indicador:\n",
      "2025-03-27 18:40:35,485 [INFO] - Australia_10Y_Bond (PRICE_Australia_10Y_Bond_bond): 100.00% [EXCELENTE]\n",
      "2025-03-27 18:40:35,488 [INFO] - UK_10Y_Bond (PRICE_UK_10Y_Bond_bond): 100.00% [EXCELENTE]\n",
      "2025-03-27 18:40:35,489 [INFO] - Canada_10Y_Bond (PRICE_Canada_10Y_Bond_bond): 100.00% [EXCELENTE]\n",
      "2025-03-27 18:40:35,489 [INFO] - CrudeOil_WTI (PRICE_CrudeOil_WTI_commodities): 100.00% [EXCELENTE]\n",
      "2025-03-27 18:40:35,489 [INFO] - Platinum_Spot (PRICE_Platinum_Spot_commodities): 100.00% [EXCELENTE]\n",
      "2025-03-27 18:40:35,490 [INFO] - EUR_USD_Spot (PRICE_EUR_USD_Spot_exchange_rate): 100.00% [EXCELENTE]\n",
      "2025-03-27 18:40:35,492 [INFO] - GBP_USD_Spot (PRICE_GBP_USD_Spot_exchange_rate): 100.00% [EXCELENTE]\n",
      "2025-03-27 18:40:35,493 [INFO] - JPY_USD_Spot (PRICE_JPY_USD_Spot_exchange_rate): 100.00% [EXCELENTE]\n",
      "2025-03-27 18:40:35,495 [INFO] - CNY_USD_Spot (PRICE_CNY_USD_Spot_exchange_rate): 100.00% [EXCELENTE]\n",
      "2025-03-27 18:40:35,496 [INFO] - AUD_USD_Spot (PRICE_AUD_USD_Spot_exchange_rate): 100.00% [EXCELENTE]\n",
      "2025-03-27 18:40:35,496 [INFO] - CAD_USD_Spot (PRICE_CAD_USD_Spot_exchange_rate): 100.00% [EXCELENTE]\n",
      "2025-03-27 18:40:35,496 [INFO] - MXN_USD_Spot (PRICE_MXN_USD_Spot_exchange_rate): 100.00% [EXCELENTE]\n",
      "2025-03-27 18:40:35,499 [INFO] - EUR_GBP_Cross (PRICE_EUR_GBP_Cross_exchange_rate): 100.00% [EXCELENTE]\n",
      "2025-03-27 18:40:35,499 [INFO] - Italy_10Y_Bond (PRICE_Italy_10Y_Bond_bond): 99.98% [EXCELENTE]\n",
      "2025-03-27 18:40:35,500 [INFO] - Germany_10Y_Bond (PRICE_Germany_10Y_Bond_bond): 99.98% [EXCELENTE]\n",
      "2025-03-27 18:40:35,502 [INFO] - China_10Y_Bond (PRICE_China_10Y_Bond_bond): 99.98% [EXCELENTE]\n",
      "2025-03-27 18:40:35,502 [INFO] - Gold_Spot (PRICE_Gold_Spot_commodities): 99.98% [EXCELENTE]\n",
      "2025-03-27 18:40:35,503 [INFO] - Silver_Spot (PRICE_Silver_Spot_commodities): 99.98% [EXCELENTE]\n",
      "2025-03-27 18:40:35,505 [INFO] - Copper_Futures (PRICE_Copper_Futures_commodities): 99.98% [EXCELENTE]\n",
      "2025-03-27 18:40:35,506 [INFO] - FTSE_100 (ULTIMO_FTSE_100_index_pricing): 99.98% [EXCELENTE]\n",
      "2025-03-27 18:40:35,506 [INFO] - Shanghai_Composite (PRICE_Shanghai_Composite_index_pricing): 99.98% [EXCELENTE]\n",
      "2025-03-27 18:40:35,508 [INFO] - S&P500_Index (ULTIMO_S&P500_Index_index_pricing): 99.93% [EXCELENTE]\n",
      "2025-03-27 18:40:35,509 [INFO] - NASDAQ_Composite (ULTIMO_NASDAQ_Composite_index_pricing): 99.93% [EXCELENTE]\n",
      "2025-03-27 18:40:35,509 [INFO] - Russell_2000 (ULTIMO_Russell_2000_index_pricing): 99.93% [EXCELENTE]\n",
      "2025-03-27 18:40:35,510 [INFO] - Nikkei_225 (ULTIMO_Nikkei_225_index_pricing): 99.93% [EXCELENTE]\n",
      "2025-03-27 18:40:35,510 [INFO] - DAX_30 (ULTIMO_DAX_30_index_pricing): 99.93% [EXCELENTE]\n",
      "2025-03-27 18:40:35,510 [INFO] - VIX_VolatilityIndex (ULTIMO_VIX_VolatilityIndex_index_pricing): 99.93% [EXCELENTE]\n",
      "2025-03-27 18:40:35,512 [INFO] - Japan_10Y_Bond (PRICE_Japan_10Y_Bond_bond): 99.89% [EXCELENTE]\n",
      "2025-03-27 18:40:35,513 [INFO] \n",
      "Distribución de cobertura:\n",
      "2025-03-27 18:40:35,513 [INFO] - Excelente (>90%): 28 indicadores\n",
      "2025-03-27 18:40:35,514 [INFO] - Buena (75-90%): 0 indicadores\n",
      "2025-03-27 18:40:35,514 [INFO] - Regular (50-75%): 0 indicadores\n",
      "2025-03-27 18:40:35,516 [INFO] - Baja (25-50%): 0 indicadores\n",
      "2025-03-27 18:40:35,518 [INFO] - Crítica (<25%): 0 indicadores\n",
      "2025-03-27 18:40:35,519 [INFO] \n",
      "Imputación de datos:\n",
      "2025-03-27 18:40:35,519 [INFO] - Valores originales: 83710 (68.65%)\n",
      "2025-03-27 18:40:35,521 [INFO] - Valores imputados: 38199 (31.33%)\n",
      "2025-03-27 18:40:35,522 [INFO] \n",
      "==================================================\n",
      "2025-03-27 18:40:35,522 [INFO] ESTADÍSTICAS DE VALORES\n",
      "2025-03-27 18:40:35,522 [INFO] ==================================================\n",
      "2025-03-27 18:40:35,525 [INFO] \n",
      "Estadísticas para PRICE_Australia_10Y_Bond_bond:\n",
      "2025-03-27 18:40:35,525 [INFO] - Min: 0.6010\n",
      "2025-03-27 18:40:35,526 [INFO] - Max: 4.9680\n",
      "2025-03-27 18:40:35,526 [INFO] - Media: 2.8148\n",
      "2025-03-27 18:40:35,528 [INFO] - Mediana: 2.7360\n",
      "2025-03-27 18:40:35,529 [INFO] - Desv. Estándar: 1.1353\n",
      "2025-03-27 18:40:35,531 [INFO] \n",
      "Estadísticas para PRICE_Italy_10Y_Bond_bond:\n",
      "2025-03-27 18:40:35,532 [INFO] - Min: 0.4610\n",
      "2025-03-27 18:40:35,534 [INFO] - Max: 4.9880\n",
      "2025-03-27 18:40:35,534 [INFO] - Media: 2.4497\n",
      "2025-03-27 18:40:35,535 [INFO] - Mediana: 2.2340\n",
      "2025-03-27 18:40:35,535 [INFO] - Desv. Estándar: 1.1741\n",
      "2025-03-27 18:40:35,537 [INFO] \n",
      "Estadísticas para PRICE_Japan_10Y_Bond_bond:\n",
      "2025-03-27 18:40:35,537 [INFO] - Min: -0.2910\n",
      "2025-03-27 18:40:35,538 [INFO] - Max: 1.5610\n",
      "2025-03-27 18:40:35,538 [INFO] - Media: 0.3365\n",
      "2025-03-27 18:40:35,540 [INFO] - Mediana: 0.1440\n",
      "2025-03-27 18:40:35,541 [INFO] - Desv. Estándar: 0.4522\n",
      "2025-03-27 18:40:35,543 [INFO] \n",
      "Estadísticas para PRICE_UK_10Y_Bond_bond:\n",
      "2025-03-27 18:40:35,544 [INFO] - Min: 0.0750\n",
      "2025-03-27 18:40:35,544 [INFO] - Max: 4.8850\n",
      "2025-03-27 18:40:35,546 [INFO] - Media: 2.0940\n",
      "2025-03-27 18:40:35,547 [INFO] - Mediana: 1.5370\n",
      "2025-03-27 18:40:35,548 [INFO] - Desv. Estándar: 1.4305\n",
      "2025-03-27 18:40:35,551 [INFO] \n",
      "Estadísticas para PRICE_Germany_10Y_Bond_bond:\n",
      "2025-03-27 18:40:35,551 [INFO] - Min: -0.8540\n",
      "2025-03-27 18:40:35,552 [INFO] - Max: 2.9680\n",
      "2025-03-27 18:40:35,554 [INFO] - Media: 0.8585\n",
      "2025-03-27 18:40:35,554 [INFO] - Mediana: 0.4745\n",
      "2025-03-27 18:40:35,555 [INFO] - Desv. Estándar: 1.1030\n",
      "2025-03-27 18:40:35,557 [INFO] \n",
      "Estadísticas para PRICE_Canada_10Y_Bond_bond:\n",
      "2025-03-27 18:40:35,557 [INFO] - Min: 0.4350\n",
      "2025-03-27 18:40:35,558 [INFO] - Max: 4.2750\n",
      "2025-03-27 18:40:35,559 [INFO] - Media: 2.1122\n",
      "2025-03-27 18:40:35,559 [INFO] - Mediana: 1.9400\n",
      "2025-03-27 18:40:35,561 [INFO] - Desv. Estándar: 0.8838\n",
      "2025-03-27 18:40:35,562 [INFO] \n",
      "Estadísticas para PRICE_China_10Y_Bond_bond:\n",
      "2025-03-27 18:40:35,562 [INFO] - Min: 1.6070\n",
      "2025-03-27 18:40:35,564 [INFO] - Max: 4.7100\n",
      "2025-03-27 18:40:35,564 [INFO] - Media: 3.0515\n",
      "2025-03-27 18:40:35,565 [INFO] - Mediana: 3.0400\n",
      "2025-03-27 18:40:35,565 [INFO] - Desv. Estándar: 0.6276\n",
      "2025-03-27 18:40:35,568 [INFO] \n",
      "Estadísticas para PRICE_CrudeOil_WTI_commodities:\n",
      "2025-03-27 18:40:35,568 [INFO] - Min: 11.5700\n",
      "2025-03-27 18:40:35,570 [INFO] - Max: 119.7800\n",
      "2025-03-27 18:40:35,570 [INFO] - Media: 65.1191\n",
      "2025-03-27 18:40:35,571 [INFO] - Mediana: 65.7900\n",
      "2025-03-27 18:40:35,571 [INFO] - Desv. Estándar: 18.6422\n",
      "2025-03-27 18:40:35,573 [INFO] \n",
      "Estadísticas para PRICE_Gold_Spot_commodities:\n",
      "2025-03-27 18:40:35,574 [INFO] - Min: 1049.6000\n",
      "2025-03-27 18:40:35,576 [INFO] - Max: 3071.3000\n",
      "2025-03-27 18:40:35,576 [INFO] - Media: 1685.2010\n",
      "2025-03-27 18:40:35,577 [INFO] - Mediana: 1516.7000\n",
      "2025-03-27 18:40:35,577 [INFO] - Desv. Estándar: 535.0435\n",
      "2025-03-27 18:40:35,579 [INFO] \n",
      "Estadísticas para PRICE_Silver_Spot_commodities:\n",
      "2025-03-27 18:40:35,580 [INFO] - Min: 11.7720\n",
      "2025-03-27 18:40:35,580 [INFO] - Max: 35.0410\n",
      "2025-03-27 18:40:35,582 [INFO] - Media: 21.1188\n",
      "2025-03-27 18:40:35,582 [INFO] - Mediana: 19.3035\n",
      "2025-03-27 18:40:35,583 [INFO] - Desv. Estándar: 5.7532\n",
      "2025-03-27 18:40:35,585 [INFO] \n",
      "Estadísticas para PRICE_Copper_Futures_commodities:\n",
      "2025-03-27 18:40:35,586 [INFO] - Min: 1.9435\n",
      "2025-03-27 18:40:35,586 [INFO] - Max: 5.2430\n",
      "2025-03-27 18:40:35,588 [INFO] - Media: 3.3639\n",
      "2025-03-27 18:40:35,589 [INFO] - Mediana: 3.1130\n",
      "2025-03-27 18:40:35,589 [INFO] - Desv. Estándar: 0.8746\n",
      "2025-03-27 18:40:35,592 [INFO] \n",
      "Estadísticas para PRICE_Platinum_Spot_commodities:\n",
      "2025-03-27 18:40:35,592 [INFO] - Min: 595.2000\n",
      "2025-03-27 18:40:35,592 [INFO] - Max: 1516.2000\n",
      "2025-03-27 18:40:35,594 [INFO] - Media: 1000.0657\n",
      "2025-03-27 18:40:35,594 [INFO] - Mediana: 969.3000\n",
      "2025-03-27 18:40:35,595 [INFO] - Desv. Estándar: 152.6143\n",
      "2025-03-27 18:40:35,597 [INFO] - ALERTA: Se encontraron 97 valores atípicos (2.23%)\n",
      "2025-03-27 18:40:35,597 [INFO]   Umbral inferior: 542.2230, Umbral superior: 1457.9085\n",
      "2025-03-27 18:40:35,598 [INFO] \n",
      "Estadísticas para PRICE_EUR_USD_Spot_exchange_rate:\n",
      "2025-03-27 18:40:35,600 [INFO] - Min: 0.9592\n",
      "2025-03-27 18:40:35,600 [INFO] - Max: 1.3933\n",
      "2025-03-27 18:40:35,600 [INFO] - Media: 1.1327\n",
      "2025-03-27 18:40:35,601 [INFO] - Mediana: 1.1152\n",
      "2025-03-27 18:40:35,603 [INFO] - Desv. Estándar: 0.0788\n",
      "2025-03-27 18:40:35,603 [INFO] - ALERTA: Se encontraron 95 valores atípicos (2.18%)\n",
      "2025-03-27 18:40:35,604 [INFO]   Umbral inferior: 0.8964, Umbral superior: 1.3690\n",
      "2025-03-27 18:40:35,606 [INFO] \n",
      "Estadísticas para PRICE_GBP_USD_Spot_exchange_rate:\n",
      "2025-03-27 18:40:35,607 [INFO] - Min: 1.0684\n",
      "2025-03-27 18:40:35,609 [INFO] - Max: 1.7163\n",
      "2025-03-27 18:40:35,609 [INFO] - Media: 1.3448\n",
      "2025-03-27 18:40:35,610 [INFO] - Mediana: 1.3009\n",
      "2025-03-27 18:40:35,610 [INFO] - Desv. Estándar: 0.1268\n",
      "2025-03-27 18:40:35,612 [INFO] \n",
      "Estadísticas para PRICE_JPY_USD_Spot_exchange_rate:\n",
      "2025-03-27 18:40:35,614 [INFO] - Min: 99.8700\n",
      "2025-03-27 18:40:35,614 [INFO] - Max: 161.6800\n",
      "2025-03-27 18:40:35,615 [INFO] - Media: 121.3544\n",
      "2025-03-27 18:40:35,617 [INFO] - Mediana: 113.1900\n",
      "2025-03-27 18:40:35,619 [INFO] - Desv. Estándar: 17.3450\n",
      "2025-03-27 18:40:35,621 [INFO] \n",
      "Estadísticas para PRICE_CNY_USD_Spot_exchange_rate:\n",
      "2025-03-27 18:40:35,622 [INFO] - Min: 6.0402\n",
      "2025-03-27 18:40:35,624 [INFO] - Max: 7.3430\n",
      "2025-03-27 18:40:35,624 [INFO] - Media: 6.7456\n",
      "2025-03-27 18:40:35,625 [INFO] - Mediana: 6.7655\n",
      "2025-03-27 18:40:35,625 [INFO] - Desv. Estándar: 0.3652\n",
      "2025-03-27 18:40:35,628 [INFO] \n",
      "Estadísticas para PRICE_AUD_USD_Spot_exchange_rate:\n",
      "2025-03-27 18:40:35,629 [INFO] - Min: 0.5741\n",
      "2025-03-27 18:40:35,631 [INFO] - Max: 0.9496\n",
      "2025-03-27 18:40:35,631 [INFO] - Media: 0.7253\n",
      "2025-03-27 18:40:35,632 [INFO] - Mediana: 0.7182\n",
      "2025-03-27 18:40:35,632 [INFO] - Desv. Estándar: 0.0724\n",
      "2025-03-27 18:40:35,633 [INFO] - ALERTA: Se encontraron 4 valores atípicos (0.09%)\n",
      "2025-03-27 18:40:35,633 [INFO]   Umbral inferior: 0.5079, Umbral superior: 0.9426\n",
      "2025-03-27 18:40:35,635 [INFO] \n",
      "Estadísticas para PRICE_CAD_USD_Spot_exchange_rate:\n",
      "2025-03-27 18:40:35,636 [INFO] - Min: 1.0631\n",
      "2025-03-27 18:40:35,638 [INFO] - Max: 1.4576\n",
      "2025-03-27 18:40:35,639 [INFO] - Media: 1.3056\n",
      "2025-03-27 18:40:35,639 [INFO] - Mediana: 1.3170\n",
      "2025-03-27 18:40:35,639 [INFO] - Desv. Estándar: 0.0815\n",
      "2025-03-27 18:40:35,642 [INFO] \n",
      "Estadísticas para PRICE_MXN_USD_Spot_exchange_rate:\n",
      "2025-03-27 18:40:35,642 [INFO] - Min: 12.8375\n",
      "2025-03-27 18:40:35,644 [INFO] - Max: 25.3380\n",
      "2025-03-27 18:40:35,645 [INFO] - Media: 18.6078\n",
      "2025-03-27 18:40:35,645 [INFO] - Mediana: 19.0530\n",
      "2025-03-27 18:40:35,647 [INFO] - Desv. Estándar: 2.2887\n",
      "2025-03-27 18:40:35,649 [INFO] \n",
      "Estadísticas para PRICE_EUR_GBP_Cross_exchange_rate:\n",
      "2025-03-27 18:40:35,649 [INFO] - Min: 0.6937\n",
      "2025-03-27 18:40:35,649 [INFO] - Max: 0.9396\n",
      "2025-03-27 18:40:35,651 [INFO] - Media: 0.8451\n",
      "2025-03-27 18:40:35,651 [INFO] - Mediana: 0.8550\n",
      "2025-03-27 18:40:35,652 [INFO] - Desv. Estándar: 0.0480\n",
      "2025-03-27 18:40:35,652 [INFO] - ALERTA: Se encontraron 15 valores atípicos (0.34%)\n",
      "2025-03-27 18:40:35,652 [INFO]   Umbral inferior: 0.7011, Umbral superior: 0.9890\n",
      "2025-03-27 18:40:35,655 [INFO] \n",
      "Estadísticas para ULTIMO_S&P500_Index_index_pricing:\n",
      "2025-03-27 18:40:35,656 [INFO] - Min: 1.7419\n",
      "2025-03-27 18:40:35,656 [INFO] - Max: 6.1441\n",
      "2025-03-27 18:40:35,657 [INFO] - Media: 3.4281\n",
      "2025-03-27 18:40:35,658 [INFO] - Mediana: 2.9980\n",
      "2025-03-27 18:40:35,658 [INFO] - Desv. Estándar: 1.2732\n",
      "2025-03-27 18:40:35,660 [INFO] \n",
      "Estadísticas para ULTIMO_NASDAQ_Composite_index_pricing:\n",
      "2025-03-27 18:40:35,661 [INFO] - Min: 3.9970\n",
      "2025-03-27 18:40:35,661 [INFO] - Max: 20.1739\n",
      "2025-03-27 18:40:35,663 [INFO] - Media: 10.0734\n",
      "2025-03-27 18:40:35,663 [INFO] - Mediana: 8.4698\n",
      "2025-03-27 18:40:35,665 [INFO] - Desv. Estándar: 4.7617\n",
      "2025-03-27 18:40:35,666 [INFO] \n",
      "Estadísticas para ULTIMO_Russell_2000_index_pricing:\n",
      "2025-03-27 18:40:35,668 [INFO] - Min: 1.0024\n",
      "2025-03-27 18:40:35,669 [INFO] - Max: 99931.0000\n",
      "2025-03-27 18:40:35,669 [INFO] - Media: 317.3993\n",
      "2025-03-27 18:40:35,669 [INFO] - Mediana: 1.5918\n",
      "2025-03-27 18:40:35,671 [INFO] - Desv. Estándar: 5559.2784\n",
      "2025-03-27 18:40:35,671 [INFO] - ALERTA: Se encontraron 14 valores atípicos (0.32%)\n",
      "2025-03-27 18:40:35,672 [INFO]   Umbral inferior: -16360.4359, Umbral superior: 16995.2345\n",
      "2025-03-27 18:40:35,674 [INFO] \n",
      "Estadísticas para ULTIMO_FTSE_100_index_pricing:\n",
      "2025-03-27 18:40:35,674 [INFO] - Min: 4993.8900\n",
      "2025-03-27 18:40:35,675 [INFO] - Max: 8871.3100\n",
      "2025-03-27 18:40:35,675 [INFO] - Media: 7218.3913\n",
      "2025-03-27 18:40:35,675 [INFO] - Mediana: 7250.4750\n",
      "2025-03-27 18:40:35,677 [INFO] - Desv. Estándar: 711.0503\n",
      "2025-03-27 18:40:35,677 [INFO] - ALERTA: Se encontraron 2 valores atípicos (0.05%)\n",
      "2025-03-27 18:40:35,678 [INFO]   Umbral inferior: 5085.2405, Umbral superior: 9351.5422\n",
      "2025-03-27 18:40:35,681 [INFO] \n",
      "Estadísticas para ULTIMO_Nikkei_225_index_pricing:\n",
      "2025-03-27 18:40:35,681 [INFO] - Min: 13.9102\n",
      "2025-03-27 18:40:35,683 [INFO] - Max: 42.2240\n",
      "2025-03-27 18:40:35,684 [INFO] - Media: 25.0691\n",
      "2025-03-27 18:40:35,684 [INFO] - Mediana: 22.7997\n",
      "2025-03-27 18:40:35,686 [INFO] - Desv. Estándar: 7.3789\n",
      "2025-03-27 18:40:35,688 [INFO] \n",
      "Estadísticas para ULTIMO_DAX_30_index_pricing:\n",
      "2025-03-27 18:40:35,688 [INFO] - Min: 8.4417\n",
      "2025-03-27 18:40:35,689 [INFO] - Max: 23.4195\n",
      "2025-03-27 18:40:35,689 [INFO] - Media: 13.7002\n",
      "2025-03-27 18:40:35,691 [INFO] - Mediana: 12.8101\n",
      "2025-03-27 18:40:35,691 [INFO] - Desv. Estándar: 3.4835\n",
      "2025-03-27 18:40:35,694 [INFO] \n",
      "Estadísticas para PRICE_Shanghai_Composite_index_pricing:\n",
      "2025-03-27 18:40:35,694 [INFO] - Min: 1991.2500\n",
      "2025-03-27 18:40:35,696 [INFO] - Max: 5166.3500\n",
      "2025-03-27 18:40:35,696 [INFO] - Media: 3124.8512\n",
      "2025-03-27 18:40:35,697 [INFO] - Mediana: 3163.2600\n",
      "2025-03-27 18:40:35,697 [INFO] - Desv. Estándar: 419.9750\n",
      "2025-03-27 18:40:35,699 [INFO] - ALERTA: Se encontraron 52 valores atípicos (1.19%)\n",
      "2025-03-27 18:40:35,700 [INFO]   Umbral inferior: 1864.9261, Umbral superior: 4384.7762\n",
      "2025-03-27 18:40:35,703 [INFO] \n",
      "Estadísticas para ULTIMO_VIX_VolatilityIndex_index_pricing:\n",
      "2025-03-27 18:40:35,703 [INFO] - Min: 914.0000\n",
      "2025-03-27 18:40:35,704 [INFO] - Max: 8269.0000\n",
      "2025-03-27 18:40:35,706 [INFO] - Media: 1814.1507\n",
      "2025-03-27 18:40:35,706 [INFO] - Mediana: 1631.0000\n",
      "2025-03-27 18:40:35,708 [INFO] - Desv. Estándar: 698.5623\n",
      "2025-03-27 18:40:35,709 [INFO] - ALERTA: Se encontraron 55 valores atípicos (1.26%)\n",
      "2025-03-27 18:40:35,709 [INFO]   Umbral inferior: -281.5361, Umbral superior: 3909.8375\n",
      "2025-03-27 18:40:35,709 [INFO] \n",
      "==================================================\n",
      "2025-03-27 18:40:35,709 [INFO] GUARDANDO RESULTADOS\n",
      "2025-03-27 18:40:35,711 [INFO] ==================================================\n",
      "2025-03-27 18:40:35,711 [INFO] Guardando resultados en: datos_economicos_normales_procesados.xlsx\n",
      "2025-03-27 18:40:35,754 [INFO] Guardando DataFrame combinado en 'datos_economicos_normales_procesados.xlsx'...\n",
      "2025-03-27 18:40:36,942 [INFO] Guardando estadísticas de los indicadores...\n",
      "2025-03-27 18:40:37,504 [INFO] Archivo guardado exitosamente: datos_economicos_normales_procesados.xlsx\n",
      "2025-03-27 18:40:37,506 [INFO] \n",
      "==================================================\n",
      "2025-03-27 18:40:37,507 [INFO] RESUMEN DE EJECUCIÓN\n",
      "2025-03-27 18:40:37,508 [INFO] ==================================================\n",
      "2025-03-27 18:40:37,509 [INFO] Proceso: MyinvestingreportNormal\n",
      "2025-03-27 18:40:37,510 [INFO] Tiempo de ejecución: 34.15 segundos\n",
      "2025-03-27 18:40:37,512 [INFO] Archivos procesados: 28\n",
      "2025-03-27 18:40:37,513 [INFO] Archivos con error: 0\n",
      "2025-03-27 18:40:37,515 [INFO] Archivos procesados correctamente: 28\n",
      "2025-03-27 18:40:37,516 [INFO] Periodo de datos: 2014-01-01 a 2025-12-03\n",
      "2025-03-27 18:40:37,517 [INFO] Datos combinados: 4355 filas, 29 columnas\n",
      "2025-03-27 18:40:37,518 [INFO] Archivo de salida: datos_economicos_normales_procesados.xlsx\n",
      "2025-03-27 18:40:37,519 [INFO] Estado: COMPLETADO\n",
      "2025-03-27 18:40:37,520 [INFO] ==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado exitosamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar logging\n",
    "def configurar_logging(log_file='myinvestingreportnormal.log'):\n",
    "    \"\"\"Configura el sistema de logging\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger('MyinvestingreportNormal')\n",
    "\n",
    "class MyinvestingreportNormal:\n",
    "    \"\"\"\n",
    "    Clase para implementar el procesamiento de datos económicos de Investing\n",
    "    con método Normal para datos de frecuencia diaria\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_file, data_root='data/Macro/raw', log_file='myinvestingreportnormal.log'):\n",
    "        \"\"\"\n",
    "        Inicializa el procesador\n",
    "        \n",
    "        Args:\n",
    "            config_file (str): Ruta al archivo de configuración (Data Engineering.xlsx)\n",
    "            data_root (str): Directorio raíz donde se encuentran los subdirectorios de datos\n",
    "            log_file (str): Ruta al archivo de log\n",
    "        \"\"\"\n",
    "        self.config_file = config_file\n",
    "        self.data_root = data_root\n",
    "        self.logger = configurar_logging(log_file)\n",
    "        self.config_data = None\n",
    "        self.fecha_min_global = None\n",
    "        self.fecha_max_global = None\n",
    "        self.indice_diario = None\n",
    "        self.datos_procesados = {}\n",
    "        self.df_combinado = None\n",
    "        self.estadisticas = {}\n",
    "        \n",
    "        self.logger.info(\"=\" * 80)\n",
    "        self.logger.info(\"INICIANDO PROCESO: MyinvestingreportNormal\")\n",
    "        self.logger.info(f\"Archivo de configuración: {config_file}\")\n",
    "        self.logger.info(f\"Directorio raíz de datos: {data_root}\")\n",
    "        self.logger.info(f\"Fecha y hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        self.logger.info(\"=\" * 80)\n",
    "    \n",
    "    def leer_configuracion(self):\n",
    "        \"\"\"\n",
    "        Lee y filtra la configuración del archivo Excel\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Configuraciones filtradas\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.logger.info(\"Leyendo archivo de configuración...\")\n",
    "            # Leer archivo de configuración\n",
    "            df_config = pd.read_excel(self.config_file)\n",
    "            \n",
    "            # Filtrar por tipo de preprocesamiento y fuente\n",
    "            self.config_data = df_config[\n",
    "                (df_config['Fuente'] == 'Investing Data') & \n",
    "                (df_config['Tipo de Preprocesamiento Según la Fuente'] == 'Normal')\n",
    "            ].copy()\n",
    "            \n",
    "            num_configs = len(self.config_data)\n",
    "            self.logger.info(f\"Se encontraron {num_configs} configuraciones para procesar\")\n",
    "            \n",
    "            if num_configs == 0:\n",
    "                self.logger.warning(\"No se encontraron configuraciones que cumplan los criterios\")\n",
    "                return None\n",
    "                \n",
    "            return self.config_data\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al leer configuración: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def extraer_fecha(self, texto_fecha):\n",
    "        \"\"\"\n",
    "        Extrae una fecha del formato \"Apr 01, 2025 (Mar)\" o similar\n",
    "        \n",
    "        Args:\n",
    "            texto_fecha: Texto con la fecha a extraer\n",
    "            \n",
    "        Returns:\n",
    "            pd.Timestamp: Fecha extraída o None si no se pudo procesar\n",
    "        \"\"\"\n",
    "        if not isinstance(texto_fecha, str):\n",
    "            # Si ya es un objeto datetime, convertirlo a pd.Timestamp\n",
    "            if isinstance(texto_fecha, (datetime, pd.Timestamp)):\n",
    "                return pd.Timestamp(texto_fecha)\n",
    "            return None\n",
    "        \n",
    "        # Buscar formato \"Apr 01, 2025 (Mar)\"\n",
    "        match = re.search(r'([A-Za-z]+\\s+\\d+,\\s+\\d{4})', texto_fecha)\n",
    "        if match:\n",
    "            try:\n",
    "                return pd.to_datetime(match.group(1))\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Intentar parsear directamente\n",
    "        try:\n",
    "            return pd.to_datetime(texto_fecha)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def encontrar_ruta_archivo(self, variable, tipo_macro):\n",
    "        \"\"\"\n",
    "        Encuentra la ruta completa del archivo basado en la variable y tipo_macro\n",
    "        \n",
    "        Args:\n",
    "            variable (str): Nombre de la variable (archivo sin extensión)\n",
    "            tipo_macro (str): Tipo de indicador macroeconómico\n",
    "            \n",
    "        Returns:\n",
    "            str: Ruta completa del archivo o None si no se encuentra\n",
    "        \"\"\"\n",
    "        # Construir ruta basada en la estructura de directorios\n",
    "        ruta_base = os.path.join(self.data_root, tipo_macro)\n",
    "        nombre_archivo = f\"{variable}.csv\"  # Para datos normales suelen ser CSV\n",
    "        ruta_completa = os.path.join(ruta_base, nombre_archivo)\n",
    "        \n",
    "        if os.path.exists(ruta_completa):\n",
    "            return ruta_completa\n",
    "        \n",
    "        # Intentar con extensión xlsx por si acaso\n",
    "        nombre_archivo_alt = f\"{variable}.xlsx\"\n",
    "        ruta_completa_alt = os.path.join(ruta_base, nombre_archivo_alt)\n",
    "        \n",
    "        if os.path.exists(ruta_completa_alt):\n",
    "            return ruta_completa_alt\n",
    "        \n",
    "        # Si no se encuentra, intentar buscar en todos los subdirectorios\n",
    "        for root, dirs, files in os.walk(self.data_root):\n",
    "            if nombre_archivo in files:\n",
    "                return os.path.join(root, nombre_archivo)\n",
    "            if nombre_archivo_alt in files:\n",
    "                return os.path.join(root, nombre_archivo_alt)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def limpiar_valor_porcentaje(self, valor):\n",
    "        \"\"\"\n",
    "        Limpia y convierte valores con formato de porcentaje, millones, billones, etc.\n",
    "        \n",
    "        Args:\n",
    "            valor: Valor a limpiar, puede ser string o número\n",
    "            \n",
    "        Returns:\n",
    "            float: Valor numérico limpio o None si no se puede convertir\n",
    "        \"\"\"\n",
    "        # Si ya es un número, retornarlo directamente\n",
    "        if isinstance(valor, (int, float)):\n",
    "            return float(valor)\n",
    "        \n",
    "        # Si es None o no es string, retornar None\n",
    "        if not isinstance(valor, str) or valor is None:\n",
    "            return None\n",
    "        \n",
    "        # Eliminar espacios\n",
    "        valor_limpio = valor.strip()\n",
    "        \n",
    "        # Si está vacío después de quitar espacios, retornar None\n",
    "        if not valor_limpio:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Casos según el formato\n",
    "            \n",
    "            # Caso 1: Porcentaje (ej: \"7.5%\")\n",
    "            if \"%\" in valor_limpio:\n",
    "                return float(valor_limpio.replace(\"%\", \"\").strip())\n",
    "                \n",
    "            # Caso 2: Millones (ej: \"2.95M\")\n",
    "            if \"M\" in valor_limpio:\n",
    "                return float(valor_limpio.replace(\"M\", \"\").strip())\n",
    "                \n",
    "            # Caso 3: Billones (ej: \"269.80B\")\n",
    "            if \"B\" in valor_limpio:\n",
    "                return float(valor_limpio.replace(\"B\", \"\").strip())\n",
    "                \n",
    "            # Caso 4: Miles (ej: \"1.5K\")\n",
    "            if \"K\" in valor_limpio:\n",
    "                return float(valor_limpio.replace(\"K\", \"\").strip())\n",
    "                \n",
    "            # Caso 5: Trillones (ej: \"1.2T\")\n",
    "            if \"T\" in valor_limpio:\n",
    "                return float(valor_limpio.replace(\"T\", \"\").strip())\n",
    "                \n",
    "            # Caso 6: Valores con comas como separadores de miles (ej: \"1,234.56\")\n",
    "            if \",\" in valor_limpio:\n",
    "                return float(valor_limpio.replace(\",\", \"\").strip())\n",
    "            \n",
    "            # Caso por defecto: intentar convertir directamente\n",
    "            return float(valor_limpio)\n",
    "            \n",
    "        except (ValueError, TypeError):\n",
    "            # Si no se puede convertir, retornar None\n",
    "            return None\n",
    "    \n",
    "    def detectar_columna_fecha(self, df):\n",
    "        \"\"\"\n",
    "        Detecta la columna de fecha en el DataFrame\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame con los datos\n",
    "            \n",
    "        Returns:\n",
    "            str: Nombre de la columna de fecha detectada o None si no se encontró\n",
    "        \"\"\"\n",
    "        columnas = df.columns.tolist()\n",
    "        \n",
    "        # Buscar columnas que contengan palabras relacionadas con fechas\n",
    "        candidatos_fecha = [\n",
    "            col for col in columnas if any(\n",
    "                palabra in col.lower() \n",
    "                for palabra in ['date', 'fecha', 'time', 'día', 'day', 'periodo']\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        if candidatos_fecha:\n",
    "            # Intentar convertir cada columna candidata a fecha\n",
    "            for col in candidatos_fecha:\n",
    "                muestra = df[col].dropna().head(5)\n",
    "                if len(muestra) > 0:\n",
    "                    # Intentar convertir a fecha\n",
    "                    try:\n",
    "                        pd.to_datetime(muestra)\n",
    "                        return col\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # Si no se encuentra una columna explícita, verificar todas las columnas\n",
    "        for col in columnas:\n",
    "            muestra = df[col].dropna().head(5)\n",
    "            if len(muestra) > 0:\n",
    "                # Verificar si la columna ya es de tipo datetime\n",
    "                if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "                    return col\n",
    "                \n",
    "                # Intentar convertir a fecha\n",
    "                try:\n",
    "                    pd.to_datetime(muestra)\n",
    "                    return col\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def detectar_columna_target(self, df, target_especificado):\n",
    "        \"\"\"\n",
    "        Detecta la columna target en el DataFrame\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame con los datos\n",
    "            target_especificado (str): Nombre de la columna TARGET especificada\n",
    "            \n",
    "        Returns:\n",
    "            str: Nombre de la columna target detectada o None si no se encontró\n",
    "        \"\"\"\n",
    "        # Comprobar si existe la columna target especificada (insensible a mayúsculas/minúsculas)\n",
    "        columnas = df.columns.tolist()\n",
    "        for col in columnas:\n",
    "            if col.upper() == target_especificado.upper():\n",
    "                return col\n",
    "        \n",
    "        # Si no existe la columna target, buscar columnas alternativas comunes\n",
    "        candidatos_valor = [\n",
    "            'Price', 'Close', 'PRICE', 'Adj Close', 'Cierre', 'Value', 'Valor',\n",
    "            'Data', 'Rate', 'Tasa', 'Actual', 'ACTUAL', 'Last'\n",
    "        ]\n",
    "        \n",
    "        for candidato in candidatos_valor:\n",
    "            if candidato in columnas:\n",
    "                return candidato\n",
    "        \n",
    "        # Si no se encuentra ningún candidato obvio, buscar columnas con valores numéricos\n",
    "        columnas_numericas = []\n",
    "        \n",
    "        for col in columnas:\n",
    "            # Evitar columnas que probablemente no son valores\n",
    "            if col in ['Date', 'Fecha', 'Time', 'Hora', 'Symbol', 'Ticker', 'Volume', 'Open', 'High', 'Low']:\n",
    "                continue\n",
    "                \n",
    "            # Contar valores numéricos\n",
    "            valores_numericos = 0\n",
    "            for i in range(min(10, len(df))):\n",
    "                if i < len(df):\n",
    "                    valor = df.iloc[i].get(col)\n",
    "                    if valor is not None:\n",
    "                        valor_limpio = self.limpiar_valor_porcentaje(valor)\n",
    "                        if valor_limpio is not None:\n",
    "                            valores_numericos += 1\n",
    "            \n",
    "            if valores_numericos > 0:\n",
    "                columnas_numericas.append((col, valores_numericos))\n",
    "        \n",
    "        # Ordenar por número de valores numéricos, descendente\n",
    "        columnas_numericas.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Retornar la columna con más valores numéricos\n",
    "        if columnas_numericas:\n",
    "            return columnas_numericas[0][0]\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def procesar_archivo(self, config_row):\n",
    "        \"\"\"\n",
    "        Procesa un archivo individual según la configuración\n",
    "        \n",
    "        Args:\n",
    "            config_row (pd.Series): Fila de configuración del archivo\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (nombre_indicador, pd.DataFrame procesado) o (nombre_indicador, None) si hay error\n",
    "        \"\"\"\n",
    "        variable = config_row['Variable']\n",
    "        tipo_macro = config_row['Tipo Macro']\n",
    "        target_col = config_row['TARGET']\n",
    "        \n",
    "        # Buscar la ruta completa del archivo\n",
    "        ruta_archivo = self.encontrar_ruta_archivo(variable, tipo_macro)\n",
    "        \n",
    "        self.logger.info(f\"\\nProcesando: {variable} ({tipo_macro})\")\n",
    "        self.logger.info(f\"- Archivo: {variable}\")\n",
    "        self.logger.info(f\"- Columna TARGET: {target_col}\")\n",
    "        \n",
    "        if ruta_archivo is None:\n",
    "            self.logger.error(f\"- ERROR: Archivo no encontrado: {variable}\")\n",
    "            return variable, None\n",
    "        \n",
    "        self.logger.info(f\"- Ruta encontrada: {ruta_archivo}\")\n",
    "        \n",
    "        try:\n",
    "            # Determinar la extensión del archivo\n",
    "            _, extension = os.path.splitext(ruta_archivo)\n",
    "            extension = extension.lower()\n",
    "            \n",
    "            # Leer el archivo según su extensión\n",
    "            if extension == '.csv':\n",
    "                # Probar diferentes separadores\n",
    "                try:\n",
    "                    df = pd.read_csv(ruta_archivo, sep=',')\n",
    "                except:\n",
    "                    try:\n",
    "                        df = pd.read_csv(ruta_archivo, sep=';')\n",
    "                    except:\n",
    "                        try:\n",
    "                            df = pd.read_csv(ruta_archivo, sep='\\t')\n",
    "                        except Exception as e:\n",
    "                            self.logger.error(f\"- ERROR: No se pudo leer el archivo CSV: {str(e)}\")\n",
    "                            return variable, None\n",
    "            elif extension in ['.xlsx', '.xls']:\n",
    "                try:\n",
    "                    # Método 1: Usando pandas directamente\n",
    "                    df = pd.read_excel(ruta_archivo)\n",
    "                except Exception as e:\n",
    "                    self.logger.warning(f\"- AVISO: Error al leer con pandas: {str(e)}\")\n",
    "                    try:\n",
    "                        # Método 2: Usando openpyxl como motor\n",
    "                        df = pd.read_excel(ruta_archivo, engine='openpyxl')\n",
    "                    except Exception as e2:\n",
    "                        self.logger.warning(f\"- AVISO: Error al leer con openpyxl: {str(e2)}\")\n",
    "                        try:\n",
    "                            # Método 3: Usando xlrd como motor\n",
    "                            df = pd.read_excel(ruta_archivo, engine='xlrd')\n",
    "                        except Exception as e3:\n",
    "                            self.logger.error(f\"- ERROR: Todos los métodos de lectura fallaron: {str(e3)}\")\n",
    "                            return variable, None\n",
    "            else:\n",
    "                self.logger.error(f\"- ERROR: Formato de archivo no soportado: {extension}\")\n",
    "                return variable, None\n",
    "            \n",
    "            total_filas = len(df)\n",
    "            self.logger.info(f\"- Filas encontradas: {total_filas}\")\n",
    "            \n",
    "            if total_filas == 0:\n",
    "                self.logger.error(f\"- ERROR: El archivo está vacío\")\n",
    "                return variable, None\n",
    "            \n",
    "            # Detectar columna de fecha\n",
    "            columna_fecha = self.detectar_columna_fecha(df)\n",
    "            if columna_fecha is None:\n",
    "                self.logger.error(f\"- ERROR: No se encontró columna de fecha en {ruta_archivo}\")\n",
    "                return variable, None\n",
    "            \n",
    "            self.logger.info(f\"- Columna de fecha identificada: {columna_fecha}\")\n",
    "                \n",
    "            # Detectar la columna TARGET\n",
    "            columna_encontrada = self.detectar_columna_target(df, target_col)\n",
    "            \n",
    "            if columna_encontrada is None:\n",
    "                self.logger.error(f\"- ERROR: No se encontró columna TARGET ni alternativas en {ruta_archivo}\")\n",
    "                return variable, None\n",
    "                \n",
    "            if columna_encontrada != target_col:\n",
    "                self.logger.warning(f\"- AVISO: No se encontró columna '{target_col}', usando '{columna_encontrada}'\")\n",
    "            \n",
    "            # Procesar fechas\n",
    "            df['fecha'] = df[columna_fecha].apply(self.extraer_fecha)\n",
    "            df = df.dropna(subset=['fecha'])\n",
    "            \n",
    "            # Contar fechas procesadas correctamente\n",
    "            fechas_procesadas = len(df)\n",
    "            if fechas_procesadas < total_filas:\n",
    "                self.logger.warning(f\"- AVISO: {total_filas - fechas_procesadas} fechas no pudieron ser procesadas\")\n",
    "            \n",
    "            # Extraer valores de TARGET, limpiando porcentajes, millones, billones, etc.\n",
    "            df['valor'] = df[columna_encontrada].apply(self.limpiar_valor_porcentaje)\n",
    "            \n",
    "            # Verificar si hay valores válidos\n",
    "            df = df.dropna(subset=['valor'])\n",
    "            \n",
    "            valores_validos = len(df)\n",
    "            if valores_validos == 0:\n",
    "                self.logger.error(f\"- ERROR: No se encontraron valores válidos para '{columna_encontrada}' en {ruta_archivo}\")\n",
    "                return variable, None\n",
    "                \n",
    "            cobertura = (valores_validos / total_filas) * 100\n",
    "            \n",
    "            # Renombrar columna según el patrón\n",
    "            nuevo_nombre = f\"{target_col}_{variable}_{tipo_macro}\"\n",
    "            df.rename(columns={'valor': nuevo_nombre}, inplace=True)\n",
    "            \n",
    "            # Seleccionar solo las columnas relevantes\n",
    "            df_procesado = df[['fecha', nuevo_nombre]].copy()\n",
    "            \n",
    "            # Ordenar por fecha\n",
    "            df_procesado = df_procesado.sort_values('fecha')\n",
    "            \n",
    "            # Calcular fechas mínima y máxima\n",
    "            fecha_min = df_procesado['fecha'].min()\n",
    "            fecha_max = df_procesado['fecha'].max()\n",
    "            \n",
    "            # Actualizar fechas mínima y máxima globales\n",
    "            if self.fecha_min_global is None or fecha_min < self.fecha_min_global:\n",
    "                self.fecha_min_global = fecha_min\n",
    "                \n",
    "            if self.fecha_max_global is None or fecha_max > self.fecha_max_global:\n",
    "                self.fecha_max_global = fecha_max\n",
    "            \n",
    "            # Registrar estadísticas\n",
    "            self.estadisticas[variable] = {\n",
    "                'tipo_macro': tipo_macro,\n",
    "                'columna_target': columna_encontrada,\n",
    "                'total_filas': total_filas,\n",
    "                'valores_validos': valores_validos,\n",
    "                'cobertura': cobertura,\n",
    "                'fecha_min': fecha_min,\n",
    "                'fecha_max': fecha_max,\n",
    "                'nuevo_nombre': nuevo_nombre\n",
    "            }\n",
    "            \n",
    "            estado = \"OK\" if cobertura >= 75 else \"ALERTA\"\n",
    "            \n",
    "            self.logger.info(f\"- Valores no nulos en TARGET: {valores_validos}\")\n",
    "            self.logger.info(f\"- Cobertura: {cobertura:.2f}%\")\n",
    "            self.logger.info(f\"- Periodo: {fecha_min.strftime('%Y-%m-%d')} a {fecha_max.strftime('%Y-%m-%d')}\")\n",
    "            self.logger.info(f\"- Estado: {estado}\")\n",
    "            \n",
    "            return variable, df_procesado\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"- ERROR al procesar {ruta_archivo}: {str(e)}\")\n",
    "            return variable, None\n",
    "    \n",
    "    def generar_indice_diario(self):\n",
    "        \"\"\"\n",
    "        Genera un DataFrame con índice diario entre fechas mínima y máxima globales\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame con índice diario\n",
    "        \"\"\"\n",
    "        if self.fecha_min_global is None or self.fecha_max_global is None:\n",
    "            self.logger.error(\"No se pudieron determinar fechas mínima y máxima globales\")\n",
    "            return None\n",
    "            \n",
    "        self.logger.info(\"\\nGenerando índice temporal diario...\")\n",
    "        self.logger.info(f\"- Rango de fechas global: {self.fecha_min_global.strftime('%Y-%m-%d')} a {self.fecha_max_global.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        # Generar todas las fechas diarias\n",
    "        todas_fechas = pd.date_range(start=self.fecha_min_global, end=self.fecha_max_global, freq='D')\n",
    "        self.indice_diario = pd.DataFrame({'fecha': todas_fechas})\n",
    "        \n",
    "        self.logger.info(f\"- Total de fechas diarias generadas: {len(self.indice_diario)}\")\n",
    "        return self.indice_diario\n",
    "    \n",
    "    def combinar_datos(self):\n",
    "        \"\"\"\n",
    "        Combina todos los indicadores procesados con el índice diario\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame combinado con todos los indicadores\n",
    "        \"\"\"\n",
    "        if not self.datos_procesados:\n",
    "            self.logger.error(\"No hay datos procesados para combinar\")\n",
    "            return None\n",
    "            \n",
    "        if self.indice_diario is None:\n",
    "            self.logger.error(\"No se ha generado el índice diario\")\n",
    "            return None\n",
    "            \n",
    "        self.logger.info(\"\\nCombinando datos con índice diario...\")\n",
    "        \n",
    "        # Comenzar con el índice diario\n",
    "        df_combinado = self.indice_diario.copy()\n",
    "        \n",
    "        # Para cada indicador, realizar el merge y aplicar ffill\n",
    "        for variable, df in self.datos_procesados.items():\n",
    "            if df is None:\n",
    "                self.logger.warning(f\"Omitiendo {variable} por errores de procesamiento\")\n",
    "                continue\n",
    "                \n",
    "            nombre_col = df.columns[1]  # La columna de valores (después de 'fecha')\n",
    "            \n",
    "            self.logger.info(f\"- Combinando: {nombre_col}\")\n",
    "            \n",
    "            # Realizar merge\n",
    "            df_combinado = pd.merge(df_combinado, df, on='fecha', how='left')\n",
    "            \n",
    "            # Aplicar forward fill (ffill)\n",
    "            df_combinado[nombre_col] = df_combinado[nombre_col].ffill()\n",
    "            \n",
    "            # Calcular métricas después de ffill\n",
    "            valores_antes = self.estadisticas[variable]['valores_validos']\n",
    "            valores_despues = df_combinado[nombre_col].notna().sum()\n",
    "            valores_imputados = valores_despues - valores_antes\n",
    "            cobertura_final = (valores_despues / len(df_combinado)) * 100\n",
    "            \n",
    "            # Actualizar estadísticas\n",
    "            self.estadisticas[variable].update({\n",
    "                'valores_despues_ffill': valores_despues,\n",
    "                'valores_imputados': valores_imputados,\n",
    "                'cobertura_final': cobertura_final\n",
    "            })\n",
    "        \n",
    "        self.df_combinado = df_combinado\n",
    "        self.logger.info(f\"- DataFrame combinado: {len(df_combinado)} filas, {len(df_combinado.columns)} columnas\")\n",
    "        \n",
    "        return self.df_combinado\n",
    "    \n",
    "    def analizar_cobertura_final(self):\n",
    "        \"\"\"\n",
    "        Genera un informe detallado de cobertura final\n",
    "        \"\"\"\n",
    "        if self.df_combinado is None or not self.estadisticas:\n",
    "            self.logger.error(\"No hay datos combinados o estadísticas para analizar\")\n",
    "            return\n",
    "            \n",
    "        self.logger.info(\"\\n\" + \"=\" * 50)\n",
    "        self.logger.info(\"RESUMEN DE COBERTURA FINAL\")\n",
    "        self.logger.info(\"=\" * 50)\n",
    "        \n",
    "        total_indicadores = len(self.estadisticas)\n",
    "        total_dias = len(self.indice_diario)\n",
    "        \n",
    "        self.logger.info(f\"Total indicadores procesados: {total_indicadores}\")\n",
    "        self.logger.info(f\"Rango de fechas: {self.fecha_min_global.strftime('%Y-%m-%d')} a {self.fecha_max_global.strftime('%Y-%m-%d')}\")\n",
    "        self.logger.info(f\"Total días en la serie: {total_dias}\")\n",
    "        self.logger.info(\"\\nCobertura por indicador:\")\n",
    "        \n",
    "        # Contadores por nivel de cobertura\n",
    "        coberturas = {\n",
    "            \"Excelente (>90%)\": 0,\n",
    "            \"Buena (75-90%)\": 0,\n",
    "            \"Regular (50-75%)\": 0,\n",
    "            \"Baja (25-50%)\": 0,\n",
    "            \"Crítica (<25%)\": 0\n",
    "        }\n",
    "        \n",
    "        # Ordenar por cobertura final descendente\n",
    "        indicadores_ordenados = sorted(\n",
    "            self.estadisticas.items(), \n",
    "            key=lambda x: x[1].get('cobertura_final', 0), \n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        for variable, stats in indicadores_ordenados:\n",
    "            cobertura = stats.get('cobertura_final', 0)\n",
    "            estado = self._obtener_estado_cobertura(cobertura)\n",
    "            \n",
    "            self.logger.info(f\"- {variable} ({stats['nuevo_nombre']}): {cobertura:.2f}% [{estado}]\")\n",
    "            \n",
    "            # Incrementar contador correspondiente\n",
    "            if cobertura > 90:\n",
    "                coberturas[\"Excelente (>90%)\"] += 1\n",
    "            elif cobertura > 75:\n",
    "                coberturas[\"Buena (75-90%)\"] += 1\n",
    "            elif cobertura > 50:\n",
    "                coberturas[\"Regular (50-75%)\"] += 1\n",
    "            elif cobertura > 25:\n",
    "                coberturas[\"Baja (25-50%)\"] += 1\n",
    "            else:\n",
    "                coberturas[\"Crítica (<25%)\"] += 1\n",
    "        \n",
    "        self.logger.info(\"\\nDistribución de cobertura:\")\n",
    "        for rango, num in coberturas.items():\n",
    "            self.logger.info(f\"- {rango}: {num} indicadores\")\n",
    "        \n",
    "        # Añadir información sobre valores imputados\n",
    "        self.logger.info(\"\\nImputación de datos:\")\n",
    "        total_valores = total_dias * total_indicadores\n",
    "        total_originales = sum(s['valores_validos'] for s in self.estadisticas.values())\n",
    "        total_imputados = sum(s.get('valores_imputados', 0) for s in self.estadisticas.values())\n",
    "        \n",
    "        self.logger.info(f\"- Valores originales: {total_originales} ({total_originales/total_valores*100:.2f}%)\")\n",
    "        self.logger.info(f\"- Valores imputados: {total_imputados} ({total_imputados/total_valores*100:.2f}%)\")\n",
    "    \n",
    "    def _obtener_estado_cobertura(self, cobertura):\n",
    "        \"\"\"Determina el estado según el porcentaje de cobertura\"\"\"\n",
    "        if cobertura > 90:\n",
    "            return \"EXCELENTE\"\n",
    "        elif cobertura > 75:\n",
    "            return \"BUENO\"\n",
    "        elif cobertura > 50:\n",
    "            return \"REGULAR\"\n",
    "        elif cobertura > 25:\n",
    "            return \"BAJO\"\n",
    "        else:\n",
    "            return \"CRÍTICO\"\n",
    "    \n",
    "    def generar_estadisticas_valores(self):\n",
    "        \"\"\"\n",
    "        Genera estadísticas descriptivas de los valores para cada indicador\n",
    "        \"\"\"\n",
    "        if self.df_combinado is None:\n",
    "            self.logger.error(\"No hay datos combinados para analizar\")\n",
    "            return\n",
    "            \n",
    "        self.logger.info(\"\\n\" + \"=\" * 50)\n",
    "        self.logger.info(\"ESTADÍSTICAS DE VALORES\")\n",
    "        self.logger.info(\"=\" * 50)\n",
    "        \n",
    "        for col in self.df_combinado.columns:\n",
    "            if col == 'fecha':\n",
    "                continue\n",
    "                \n",
    "            serie = self.df_combinado[col].dropna()\n",
    "            \n",
    "            if len(serie) == 0:\n",
    "                self.logger.warning(f\"La columna {col} no tiene valores\")\n",
    "                continue\n",
    "            \n",
    "            # Calcular estadísticas básicas\n",
    "            stats = {\n",
    "                'min': serie.min(),\n",
    "                'max': serie.max(),\n",
    "                'mean': serie.mean(),\n",
    "                'median': serie.median(),\n",
    "                'std': serie.std()\n",
    "            }\n",
    "            \n",
    "            # Identificar valores atípicos (más de 3 desviaciones estándar)\n",
    "            umbral_superior = stats['mean'] + 3 * stats['std']\n",
    "            umbral_inferior = stats['mean'] - 3 * stats['std']\n",
    "            valores_atipicos = serie[(serie > umbral_superior) | (serie < umbral_inferior)]\n",
    "            \n",
    "            self.logger.info(f\"\\nEstadísticas para {col}:\")\n",
    "            self.logger.info(f\"- Min: {stats['min']:.4f}\")\n",
    "            self.logger.info(f\"- Max: {stats['max']:.4f}\")\n",
    "            self.logger.info(f\"- Media: {stats['mean']:.4f}\")\n",
    "            self.logger.info(f\"- Mediana: {stats['median']:.4f}\")\n",
    "            self.logger.info(f\"- Desv. Estándar: {stats['std']:.4f}\")\n",
    "            \n",
    "            if len(valores_atipicos) > 0:\n",
    "                pct_atipicos = (len(valores_atipicos) / len(serie)) * 100\n",
    "                self.logger.info(f\"- ALERTA: Se encontraron {len(valores_atipicos)} valores atípicos ({pct_atipicos:.2f}%)\")\n",
    "                self.logger.info(f\"  Umbral inferior: {umbral_inferior:.4f}, Umbral superior: {umbral_superior:.4f}\")\n",
    "            \n",
    "            # Guardar estadísticas en el diccionario\n",
    "            for var, stats_dict in self.estadisticas.items():\n",
    "                if stats_dict.get('nuevo_nombre') == col:\n",
    "                    stats_dict.update(stats)\n",
    "                    stats_dict['valores_atipicos'] = len(valores_atipicos)\n",
    "    \n",
    "    def guardar_resultados(self, output_file='datos_economicos_normales_procesados.xlsx'):\n",
    "        \"\"\"\n",
    "        Guarda los resultados procesados en un archivo Excel\n",
    "        \n",
    "        Args:\n",
    "            output_file (str): Ruta del archivo de salida\n",
    "            \n",
    "        Returns:\n",
    "            bool: True si se guardó correctamente, False en caso contrario\n",
    "        \"\"\"\n",
    "        if self.df_combinado is None:\n",
    "            self.logger.error(\"No hay datos para guardar\")\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            self.logger.info(\"\\n\" + \"=\" * 50)\n",
    "            self.logger.info(\"GUARDANDO RESULTADOS\")\n",
    "            self.logger.info(\"=\" * 50)\n",
    "            \n",
    "            self.logger.info(f\"Guardando resultados en: {output_file}\")\n",
    "            \n",
    "            # Crear un writer de Excel\n",
    "            with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "                # Guardar el DataFrame combinado en la primera hoja\n",
    "                self.logger.info(f\"Guardando DataFrame combinado en '{output_file}'...\")\n",
    "                self.df_combinado.to_excel(writer, sheet_name='Datos_Combinados', index=False)\n",
    "                \n",
    "                # Guardar estadísticas en una segunda hoja\n",
    "                self.logger.info(\"Guardando estadísticas de los indicadores...\")\n",
    "                \n",
    "                # Convertir diccionario de estadísticas a DataFrame\n",
    "                stats_data = []\n",
    "                for variable, stats in self.estadisticas.items():\n",
    "                    row = {\n",
    "                        'Variable': variable,\n",
    "                        'Tipo_Macro': stats.get('tipo_macro', ''),\n",
    "                        'Columna_TARGET': stats.get('columna_target', ''),\n",
    "                        'Nombre_Columna': stats.get('nuevo_nombre', ''),\n",
    "                        'Total_Filas_Original': stats.get('total_filas', 0),\n",
    "                        'Valores_Validos_Original': stats.get('valores_validos', 0),\n",
    "                        'Cobertura_Original_%': stats.get('cobertura', 0),\n",
    "                        'Valores_Despues_FFill': stats.get('valores_despues_ffill', 0),\n",
    "                        'Valores_Imputados': stats.get('valores_imputados', 0),\n",
    "                        'Cobertura_Final_%': stats.get('cobertura_final', 0),\n",
    "                        'Fecha_Min': stats.get('fecha_min', ''),\n",
    "                        'Fecha_Max': stats.get('fecha_max', ''),\n",
    "                        'Valor_Min': stats.get('min', ''),\n",
    "                        'Valor_Max': stats.get('max', ''),\n",
    "                        'Valor_Media': stats.get('mean', ''),\n",
    "                        'Valor_Mediana': stats.get('median', ''),\n",
    "                        'Desviacion_Estandar': stats.get('std', ''),\n",
    "                        'Valores_Atipicos': stats.get('valores_atipicos', 0)\n",
    "                    }\n",
    "                    stats_data.append(row)\n",
    "                    \n",
    "                df_stats = pd.DataFrame(stats_data)\n",
    "                df_stats.to_excel(writer, sheet_name='Estadisticas', index=False)\n",
    "                \n",
    "                # Guardar metadatos\n",
    "                metadata = {\n",
    "                    'Proceso': ['MyinvestingreportNormal'],\n",
    "                    'Fecha de proceso': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                    'Total indicadores': [len(self.estadisticas)],\n",
    "                    'Periodo': [f\"{self.fecha_min_global.strftime('%Y-%m-%d')} a {self.fecha_max_global.strftime('%Y-%m-%d')}\"],\n",
    "                    'Total días': [len(self.indice_diario)]\n",
    "                }\n",
    "                pd.DataFrame(metadata).to_excel(writer, sheet_name='Metadatos')\n",
    "            \n",
    "            self.logger.info(f\"Archivo guardado exitosamente: {output_file}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al guardar resultados: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def ejecutar_proceso_completo(self, output_file='datos_economicos_normales_procesados.xlsx'):\n",
    "        \"\"\"\n",
    "        Ejecuta el proceso completo de preprocesamiento\n",
    "        \n",
    "        Args:\n",
    "            output_file (str): Ruta del archivo de salida\n",
    "            \n",
    "        Returns:\n",
    "            bool: True si el proceso se completó exitosamente, False en caso contrario\n",
    "        \"\"\"\n",
    "        inicio = time.time()\n",
    "        self.logger.info(\"Iniciando proceso completo MyinvestingreportNormal...\")\n",
    "        \n",
    "        # 1. Leer configuración\n",
    "        self.leer_configuracion()\n",
    "        if self.config_data is None or len(self.config_data) == 0:\n",
    "            return False\n",
    "        \n",
    "        # 2. Procesar cada archivo\n",
    "        for _, config_row in self.config_data.iterrows():\n",
    "            variable, df_procesado = self.procesar_archivo(config_row)\n",
    "            self.datos_procesados[variable] = df_procesado\n",
    "        \n",
    "        # Verificar si se procesó al menos un archivo correctamente\n",
    "        archivos_correctos = sum(1 for df in self.datos_procesados.values() if df is not None)\n",
    "        if archivos_correctos == 0:\n",
    "            self.logger.error(\"No se pudo procesar correctamente ningún archivo\")\n",
    "            return False\n",
    "        \n",
    "        # 3. Generar índice diario\n",
    "        self.generar_indice_diario()\n",
    "        if self.indice_diario is None:\n",
    "            return False\n",
    "        \n",
    "        # 4. Combinar datos\n",
    "        self.combinar_datos()\n",
    "        if self.df_combinado is None:\n",
    "            return False\n",
    "        \n",
    "        # 5. Analizar cobertura final\n",
    "        self.analizar_cobertura_final()\n",
    "        \n",
    "        # 6. Generar estadísticas de valores\n",
    "        self.generar_estadisticas_valores()\n",
    "        \n",
    "        # 7. Guardar resultados\n",
    "        resultado = self.guardar_resultados(output_file)\n",
    "        \n",
    "        # 8. Mostrar resumen final\n",
    "        fin = time.time()\n",
    "        tiempo_ejecucion = fin - inicio\n",
    "        \n",
    "        self.logger.info(\"\\n\" + \"=\" * 50)\n",
    "        self.logger.info(\"RESUMEN DE EJECUCIÓN\")\n",
    "        self.logger.info(\"=\" * 50)\n",
    "        self.logger.info(f\"Proceso: MyinvestingreportNormal\")\n",
    "        self.logger.info(f\"Tiempo de ejecución: {tiempo_ejecucion:.2f} segundos\")\n",
    "        self.logger.info(f\"Archivos procesados: {len(self.datos_procesados)}\")\n",
    "        self.logger.info(f\"Archivos con error: {sum(1 for df in self.datos_procesados.values() if df is None)}\")\n",
    "        self.logger.info(f\"Archivos procesados correctamente: {archivos_correctos}\")\n",
    "        self.logger.info(f\"Periodo de datos: {self.fecha_min_global.strftime('%Y-%m-%d')} a {self.fecha_max_global.strftime('%Y-%m-%d')}\")\n",
    "        self.logger.info(f\"Datos combinados: {len(self.df_combinado)} filas, {len(self.df_combinado.columns)} columnas\")\n",
    "        self.logger.info(f\"Archivo de salida: {output_file}\")\n",
    "        self.logger.info(f\"Estado: {'COMPLETADO' if resultado else 'ERROR'}\")\n",
    "        self.logger.info(\"=\" * 50)\n",
    "        \n",
    "        return resultado\n",
    "\n",
    "\n",
    "# Función principal para ejecutar el proceso\n",
    "def ejecutar_myinvestingreportnormal(config_file='Data Engineering.xlsx',\n",
    "                                    output_file='datos_economicos_normales_procesados.xlsx',\n",
    "                                    data_root='data/Macro/raw',\n",
    "                                    log_file='myinvestingreportnormal.log'):\n",
    "    \"\"\"\n",
    "    Ejecuta el proceso MyinvestingreportNormal\n",
    "    \n",
    "    Args:\n",
    "        config_file (str): Ruta al archivo de configuración\n",
    "        output_file (str): Ruta al archivo de salida\n",
    "        data_root (str): Directorio raíz donde se encuentran los subdirectorios de datos\n",
    "        log_file (str): Ruta al archivo de log\n",
    "        \n",
    "    Returns:\n",
    "        bool: True si el proceso se completó exitosamente, False en caso contrario\n",
    "    \"\"\"\n",
    "    procesador = MyinvestingreportNormal(config_file, data_root, log_file)\n",
    "    return procesador.ejecutar_proceso_completo(output_file)\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    resultado = ejecutar_myinvestingreportnormal()\n",
    "    print(f\"Proceso {'completado exitosamente' if resultado else 'finalizado con errores'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 12:09:03,542 [INFO] ================================================================================\n",
      "2025-03-28 12:09:03,549 [INFO] INICIANDO PROCESO: MyinvestingreportNormal\n",
      "2025-03-28 12:09:03,552 [INFO] Archivo de configuración: Data Engineering.xlsx\n",
      "2025-03-28 12:09:03,556 [INFO] Directorio raíz de datos: data/Macro/raw\n",
      "2025-03-28 12:09:03,558 [INFO] Fecha y hora: 2025-03-28 12:09:03\n",
      "2025-03-28 12:09:03,560 [INFO] ================================================================================\n",
      "2025-03-28 12:09:03,561 [INFO] Iniciando proceso completo MyinvestingreportNormal...\n",
      "2025-03-28 12:09:03,564 [INFO] Leyendo archivo de configuración...\n",
      "2025-03-28 12:09:03,731 [INFO] Se encontraron 28 configuraciones para procesar\n",
      "2025-03-28 12:09:03,739 [INFO] \n",
      "Procesando: Australia_10Y_Bond (bond)\n",
      "2025-03-28 12:09:03,740 [INFO] - Archivo: Australia_10Y_Bond\n",
      "2025-03-28 12:09:03,742 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:03,746 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Australia_10Y_Bond.csv\n",
      "2025-03-28 12:09:04,320 [INFO] Formato numérico detectado para Australia_10Y_Bond: americano\n",
      "2025-03-28 12:09:04,332 [INFO] - Australia_10Y_Bond: 3810 filas procesadas, periodo: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:04,333 [INFO] \n",
      "Procesando: Italy_10Y_Bond (bond)\n",
      "2025-03-28 12:09:04,335 [INFO] - Archivo: Italy_10Y_Bond\n",
      "2025-03-28 12:09:04,335 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:04,336 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Italy_10Y_Bond.csv\n",
      "2025-03-28 12:09:04,815 [INFO] Formato numérico detectado para Italy_10Y_Bond: americano\n",
      "2025-03-28 12:09:04,821 [INFO] - Italy_10Y_Bond: 3238 filas procesadas, periodo: 2014-01-02 a 2025-12-03\n",
      "2025-03-28 12:09:04,822 [INFO] \n",
      "Procesando: Japan_10Y_Bond (bond)\n",
      "2025-03-28 12:09:04,824 [INFO] - Archivo: Japan_10Y_Bond\n",
      "2025-03-28 12:09:04,825 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:04,827 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Japan_10Y_Bond.csv\n",
      "2025-03-28 12:09:05,315 [INFO] Formato numérico detectado para Japan_10Y_Bond: americano\n",
      "2025-03-28 12:09:05,321 [INFO] - Japan_10Y_Bond: 3203 filas procesadas, periodo: 2014-01-04 a 2025-12-03\n",
      "2025-03-28 12:09:05,321 [INFO] \n",
      "Procesando: UK_10Y_Bond (bond)\n",
      "2025-03-28 12:09:05,323 [INFO] - Archivo: UK_10Y_Bond\n",
      "2025-03-28 12:09:05,324 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:05,326 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\UK_10Y_Bond.csv\n",
      "2025-03-28 12:09:05,833 [INFO] Formato numérico detectado para UK_10Y_Bond: americano\n",
      "2025-03-28 12:09:05,840 [INFO] - UK_10Y_Bond: 3424 filas procesadas, periodo: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:05,841 [INFO] \n",
      "Procesando: Germany_10Y_Bond (bond)\n",
      "2025-03-28 12:09:05,841 [INFO] - Archivo: Germany_10Y_Bond\n",
      "2025-03-28 12:09:05,841 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:05,843 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Germany_10Y_Bond.csv\n",
      "2025-03-28 12:09:06,280 [INFO] Formato numérico detectado para Germany_10Y_Bond: americano\n",
      "2025-03-28 12:09:06,286 [INFO] - Germany_10Y_Bond: 3075 filas procesadas, periodo: 2014-01-04 a 2025-12-03\n",
      "2025-03-28 12:09:06,287 [INFO] \n",
      "Procesando: Canada_10Y_Bond (bond)\n",
      "2025-03-28 12:09:06,288 [INFO] - Archivo: Canada_10Y_Bond\n",
      "2025-03-28 12:09:06,289 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:06,291 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Canada_10Y_Bond.csv\n",
      "2025-03-28 12:09:06,702 [INFO] Formato numérico detectado para Canada_10Y_Bond: americano\n",
      "2025-03-28 12:09:06,708 [INFO] - Canada_10Y_Bond: 2965 filas procesadas, periodo: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:06,710 [INFO] \n",
      "Procesando: China_10Y_Bond (bond)\n",
      "2025-03-28 12:09:06,711 [INFO] - Archivo: China_10Y_Bond\n",
      "2025-03-28 12:09:06,711 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:06,713 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\China_10Y_Bond.csv\n",
      "2025-03-28 12:09:07,153 [INFO] Formato numérico detectado para China_10Y_Bond: americano\n",
      "2025-03-28 12:09:07,161 [INFO] - China_10Y_Bond: 2914 filas procesadas, periodo: 2014-01-04 a 2025-12-03\n",
      "2025-03-28 12:09:07,166 [INFO] \n",
      "Procesando: CrudeOil_WTI (commodities)\n",
      "2025-03-28 12:09:07,166 [INFO] - Archivo: CrudeOil_WTI\n",
      "2025-03-28 12:09:07,166 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:07,167 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\CrudeOil_WTI.csv\n",
      "2025-03-28 12:09:07,558 [INFO] Formato numérico detectado para CrudeOil_WTI: americano\n",
      "2025-03-28 12:09:07,568 [INFO] - CrudeOil_WTI: 2953 filas procesadas, periodo: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:07,570 [INFO] \n",
      "Procesando: Gold_Spot (commodities)\n",
      "2025-03-28 12:09:07,572 [INFO] - Archivo: Gold_Spot\n",
      "2025-03-28 12:09:07,575 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:07,576 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\Gold_Spot.csv\n",
      "2025-03-28 12:09:07,977 [INFO] Formato numérico detectado para Gold_Spot: americano\n",
      "2025-03-28 12:09:07,984 [INFO] - Gold_Spot: 2874 filas procesadas, periodo: 2014-01-04 a 2025-12-03\n",
      "2025-03-28 12:09:07,986 [INFO] \n",
      "Procesando: Silver_Spot (commodities)\n",
      "2025-03-28 12:09:07,988 [INFO] - Archivo: Silver_Spot\n",
      "2025-03-28 12:09:07,989 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:07,989 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\Silver_Spot.csv\n",
      "2025-03-28 12:09:08,343 [INFO] Formato numérico detectado para Silver_Spot: americano\n",
      "2025-03-28 12:09:08,347 [INFO] - Silver_Spot: 2911 filas procesadas, periodo: 2014-01-04 a 2025-12-03\n",
      "2025-03-28 12:09:08,349 [INFO] \n",
      "Procesando: Copper_Futures (commodities)\n",
      "2025-03-28 12:09:08,350 [INFO] - Archivo: Copper_Futures\n",
      "2025-03-28 12:09:08,350 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:08,350 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\Copper_Futures.csv\n",
      "2025-03-28 12:09:08,775 [INFO] Formato numérico detectado para Copper_Futures: americano\n",
      "2025-03-28 12:09:08,783 [INFO] - Copper_Futures: 2908 filas procesadas, periodo: 2014-01-04 a 2025-12-03\n",
      "2025-03-28 12:09:08,784 [INFO] \n",
      "Procesando: Platinum_Spot (commodities)\n",
      "2025-03-28 12:09:08,785 [INFO] - Archivo: Platinum_Spot\n",
      "2025-03-28 12:09:08,786 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:08,789 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\Platinum_Spot.csv\n",
      "2025-03-28 12:09:09,233 [INFO] Formato numérico detectado para Platinum_Spot: americano\n",
      "2025-03-28 12:09:09,248 [INFO] - Platinum_Spot: 3463 filas procesadas, periodo: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:09,249 [INFO] \n",
      "Procesando: EUR_USD_Spot (exchange_rate)\n",
      "2025-03-28 12:09:09,251 [INFO] - Archivo: EUR_USD_Spot\n",
      "2025-03-28 12:09:09,253 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:09,254 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\EUR_USD_Spot.csv\n",
      "2025-03-28 12:09:09,653 [INFO] Formato numérico detectado para EUR_USD_Spot: americano\n",
      "2025-03-28 12:09:09,658 [INFO] - EUR_USD_Spot: 2932 filas procesadas, periodo: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:09,660 [INFO] \n",
      "Procesando: GBP_USD_Spot (exchange_rate)\n",
      "2025-03-28 12:09:09,662 [INFO] - Archivo: GBP_USD_Spot\n",
      "2025-03-28 12:09:09,663 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:09,663 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\GBP_USD_Spot.csv\n",
      "2025-03-28 12:09:10,070 [INFO] Formato numérico detectado para GBP_USD_Spot: americano\n",
      "2025-03-28 12:09:10,080 [INFO] - GBP_USD_Spot: 2932 filas procesadas, periodo: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:10,083 [INFO] \n",
      "Procesando: JPY_USD_Spot (exchange_rate)\n",
      "2025-03-28 12:09:10,084 [INFO] - Archivo: JPY_USD_Spot\n",
      "2025-03-28 12:09:10,086 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:10,088 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\JPY_USD_Spot.csv\n",
      "2025-03-28 12:09:10,575 [INFO] Formato numérico detectado para JPY_USD_Spot: americano\n",
      "2025-03-28 12:09:10,581 [INFO] - JPY_USD_Spot: 2932 filas procesadas, periodo: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:10,583 [INFO] \n",
      "Procesando: CNY_USD_Spot (exchange_rate)\n",
      "2025-03-28 12:09:10,584 [INFO] - Archivo: CNY_USD_Spot\n",
      "2025-03-28 12:09:10,586 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:10,586 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\CNY_USD_Spot.csv\n",
      "2025-03-28 12:09:11,042 [INFO] Formato numérico detectado para CNY_USD_Spot: americano\n",
      "2025-03-28 12:09:11,051 [INFO] - CNY_USD_Spot: 2933 filas procesadas, periodo: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:11,054 [INFO] \n",
      "Procesando: AUD_USD_Spot (exchange_rate)\n",
      "2025-03-28 12:09:11,055 [INFO] - Archivo: AUD_USD_Spot\n",
      "2025-03-28 12:09:11,057 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:11,059 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\AUD_USD_Spot.csv\n",
      "2025-03-28 12:09:11,521 [INFO] Formato numérico detectado para AUD_USD_Spot: americano\n",
      "2025-03-28 12:09:11,527 [INFO] - AUD_USD_Spot: 2932 filas procesadas, periodo: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:11,530 [INFO] \n",
      "Procesando: CAD_USD_Spot (exchange_rate)\n",
      "2025-03-28 12:09:11,532 [INFO] - Archivo: CAD_USD_Spot\n",
      "2025-03-28 12:09:11,532 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:11,533 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\CAD_USD_Spot.csv\n",
      "2025-03-28 12:09:11,926 [INFO] Formato numérico detectado para CAD_USD_Spot: americano\n",
      "2025-03-28 12:09:11,932 [INFO] - CAD_USD_Spot: 2932 filas procesadas, periodo: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:11,932 [INFO] \n",
      "Procesando: MXN_USD_Spot (exchange_rate)\n",
      "2025-03-28 12:09:11,934 [INFO] - Archivo: MXN_USD_Spot\n",
      "2025-03-28 12:09:11,934 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:11,935 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\MXN_USD_Spot.csv\n",
      "2025-03-28 12:09:12,401 [INFO] Formato numérico detectado para MXN_USD_Spot: americano\n",
      "2025-03-28 12:09:12,410 [INFO] - MXN_USD_Spot: 2932 filas procesadas, periodo: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:12,412 [INFO] \n",
      "Procesando: EUR_GBP_Cross (exchange_rate)\n",
      "2025-03-28 12:09:12,414 [INFO] - Archivo: EUR_GBP_Cross\n",
      "2025-03-28 12:09:12,414 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:12,417 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\EUR_GBP_Cross.csv\n",
      "2025-03-28 12:09:13,405 [INFO] Formato numérico detectado para EUR_GBP_Cross: americano\n",
      "2025-03-28 12:09:13,414 [INFO] - EUR_GBP_Cross: 2932 filas procesadas, periodo: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:13,417 [INFO] \n",
      "Procesando: S&P500_Index (index_pricing)\n",
      "2025-03-28 12:09:13,419 [INFO] - Archivo: S&P500_Index\n",
      "2025-03-28 12:09:13,420 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-28 12:09:13,423 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\S&P500_Index.csv\n",
      "2025-03-28 12:09:14,344 [INFO] Formato numérico detectado para S&P500_Index: europeo\n",
      "2025-03-28 12:09:14,381 [INFO] - S&P500_Index: 2826 filas procesadas, periodo: 2014-01-02 a 2025-03-27\n",
      "2025-03-28 12:09:14,382 [INFO] \n",
      "Procesando: NASDAQ_Composite (index_pricing)\n",
      "2025-03-28 12:09:14,384 [INFO] - Archivo: NASDAQ_Composite\n",
      "2025-03-28 12:09:14,387 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-28 12:09:14,388 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\NASDAQ_Composite.csv\n",
      "2025-03-28 12:09:15,346 [INFO] Formato numérico detectado para NASDAQ_Composite: europeo\n",
      "2025-03-28 12:09:15,382 [INFO] - NASDAQ_Composite: 2826 filas procesadas, periodo: 2014-01-02 a 2025-03-27\n",
      "2025-03-28 12:09:15,386 [INFO] \n",
      "Procesando: Russell_2000 (index_pricing)\n",
      "2025-03-28 12:09:15,387 [INFO] - Archivo: Russell_2000\n",
      "2025-03-28 12:09:15,389 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-28 12:09:15,391 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\Russell_2000.csv\n",
      "2025-03-28 12:09:16,327 [INFO] Formato numérico detectado para Russell_2000: europeo\n",
      "2025-03-28 12:09:16,354 [INFO] - Russell_2000: 2840 filas procesadas, periodo: 2014-01-02 a 2025-03-27\n",
      "2025-03-28 12:09:16,358 [INFO] \n",
      "Procesando: FTSE_100 (index_pricing)\n",
      "2025-03-28 12:09:16,360 [INFO] - Archivo: FTSE_100\n",
      "2025-03-28 12:09:16,363 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-28 12:09:16,366 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\FTSE_100.csv\n",
      "2025-03-28 12:09:17,925 [INFO] Formato numérico detectado para FTSE_100: americano\n",
      "2025-03-28 12:09:17,954 [INFO] - FTSE_100: 2840 filas procesadas, periodo: 2014-01-04 a 2025-12-03\n",
      "2025-03-28 12:09:17,959 [INFO] \n",
      "Procesando: Nikkei_225 (index_pricing)\n",
      "2025-03-28 12:09:17,960 [INFO] - Archivo: Nikkei_225\n",
      "2025-03-28 12:09:17,962 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-28 12:09:17,963 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\Nikkei_225.csv\n",
      "2025-03-28 12:09:18,800 [INFO] Formato numérico detectado para Nikkei_225: europeo\n",
      "2025-03-28 12:09:18,818 [INFO] - Nikkei_225: 2741 filas procesadas, periodo: 2014-01-06 a 2025-03-27\n",
      "2025-03-28 12:09:18,820 [INFO] \n",
      "Procesando: DAX_30 (index_pricing)\n",
      "2025-03-28 12:09:18,821 [INFO] - Archivo: DAX_30\n",
      "2025-03-28 12:09:18,823 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-28 12:09:18,824 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\DAX_30.csv\n",
      "2025-03-28 12:09:19,081 [INFO] Formato numérico detectado para DAX_30: europeo\n",
      "2025-03-28 12:09:19,091 [INFO] - DAX_30: 2851 filas procesadas, periodo: 2014-01-02 a 2025-03-27\n",
      "2025-03-28 12:09:19,092 [INFO] \n",
      "Procesando: Shanghai_Composite (index_pricing)\n",
      "2025-03-28 12:09:19,094 [INFO] - Archivo: Shanghai_Composite\n",
      "2025-03-28 12:09:19,094 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 12:09:19,095 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\Shanghai_Composite.csv\n",
      "2025-03-28 12:09:19,480 [INFO] Formato numérico detectado para Shanghai_Composite: americano\n",
      "2025-03-28 12:09:19,492 [INFO] - Shanghai_Composite: 2731 filas procesadas, periodo: 2014-01-04 a 2025-12-03\n",
      "2025-03-28 12:09:19,495 [INFO] \n",
      "Procesando: VIX_VolatilityIndex (index_pricing)\n",
      "2025-03-28 12:09:19,498 [INFO] - Archivo: VIX_VolatilityIndex\n",
      "2025-03-28 12:09:19,500 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-28 12:09:19,500 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\VIX_VolatilityIndex.csv\n",
      "2025-03-28 12:09:19,743 [INFO] Formato numérico detectado para VIX_VolatilityIndex: europeo\n",
      "2025-03-28 12:09:19,750 [INFO] - VIX_VolatilityIndex: 2860 filas procesadas, periodo: 2014-01-02 a 2025-03-27\n",
      "2025-03-28 12:09:19,752 [INFO] \n",
      "Generando índice temporal diario...\n",
      "2025-03-28 12:09:19,773 [INFO] - Total de fechas diarias generadas: 4355\n",
      "2025-03-28 12:09:19,777 [INFO] \n",
      "Combinando datos con índice diario...\n",
      "2025-03-28 12:09:19,778 [INFO] - Combinando: PRICE_Australia_10Y_Bond_bond\n",
      "2025-03-28 12:09:19,834 [INFO] - Combinando: PRICE_Italy_10Y_Bond_bond\n",
      "2025-03-28 12:09:19,847 [INFO] - Combinando: PRICE_Japan_10Y_Bond_bond\n",
      "2025-03-28 12:09:19,854 [INFO] - Combinando: PRICE_UK_10Y_Bond_bond\n",
      "2025-03-28 12:09:19,861 [INFO] - Combinando: PRICE_Germany_10Y_Bond_bond\n",
      "2025-03-28 12:09:19,874 [INFO] - Combinando: PRICE_Canada_10Y_Bond_bond\n",
      "2025-03-28 12:09:19,880 [INFO] - Combinando: PRICE_China_10Y_Bond_bond\n",
      "2025-03-28 12:09:19,891 [INFO] - Combinando: PRICE_CrudeOil_WTI_commodities\n",
      "2025-03-28 12:09:19,900 [INFO] - Combinando: PRICE_Gold_Spot_commodities\n",
      "2025-03-28 12:09:19,909 [INFO] - Combinando: PRICE_Silver_Spot_commodities\n",
      "2025-03-28 12:09:19,918 [INFO] - Combinando: PRICE_Copper_Futures_commodities\n",
      "2025-03-28 12:09:19,926 [INFO] - Combinando: PRICE_Platinum_Spot_commodities\n",
      "2025-03-28 12:09:19,934 [INFO] - Combinando: PRICE_EUR_USD_Spot_exchange_rate\n",
      "2025-03-28 12:09:19,940 [INFO] - Combinando: PRICE_GBP_USD_Spot_exchange_rate\n",
      "2025-03-28 12:09:19,944 [INFO] - Combinando: PRICE_JPY_USD_Spot_exchange_rate\n",
      "2025-03-28 12:09:19,950 [INFO] - Combinando: PRICE_CNY_USD_Spot_exchange_rate\n",
      "2025-03-28 12:09:19,957 [INFO] - Combinando: PRICE_AUD_USD_Spot_exchange_rate\n",
      "2025-03-28 12:09:19,963 [INFO] - Combinando: PRICE_CAD_USD_Spot_exchange_rate\n",
      "2025-03-28 12:09:19,969 [INFO] - Combinando: PRICE_MXN_USD_Spot_exchange_rate\n",
      "2025-03-28 12:09:20,315 [INFO] - Combinando: PRICE_EUR_GBP_Cross_exchange_rate\n",
      "2025-03-28 12:09:20,323 [INFO] - Combinando: ULTIMO_S&P500_Index_index_pricing\n",
      "2025-03-28 12:09:20,329 [INFO] - Combinando: ULTIMO_NASDAQ_Composite_index_pricing\n",
      "2025-03-28 12:09:20,337 [INFO] - Combinando: ULTIMO_Russell_2000_index_pricing\n",
      "2025-03-28 12:09:20,343 [INFO] - Combinando: ULTIMO_FTSE_100_index_pricing\n",
      "2025-03-28 12:09:20,349 [INFO] - Combinando: ULTIMO_Nikkei_225_index_pricing\n",
      "2025-03-28 12:09:20,356 [INFO] - Combinando: ULTIMO_DAX_30_index_pricing\n",
      "2025-03-28 12:09:20,363 [INFO] - Combinando: PRICE_Shanghai_Composite_index_pricing\n",
      "2025-03-28 12:09:20,371 [INFO] - Combinando: ULTIMO_VIX_VolatilityIndex_index_pricing\n",
      "2025-03-28 12:09:20,382 [INFO] - DataFrame combinado: 4355 filas, 29 columnas\n",
      "2025-03-28 12:09:20,384 [INFO] \n",
      "==================================================\n",
      "2025-03-28 12:09:20,384 [INFO] RESUMEN DE COBERTURA FINAL\n",
      "2025-03-28 12:09:20,385 [INFO] ==================================================\n",
      "2025-03-28 12:09:20,388 [INFO] Total indicadores procesados: 28\n",
      "2025-03-28 12:09:20,390 [INFO] Rango de fechas: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:20,390 [INFO] Total días en la serie: 4355\n",
      "2025-03-28 12:09:20,391 [INFO] - Australia_10Y_Bond (PRICE_Australia_10Y_Bond_bond): Cobertura aproximada 87.49%\n",
      "2025-03-28 12:09:20,393 [INFO] - Italy_10Y_Bond (PRICE_Italy_10Y_Bond_bond): Cobertura aproximada 74.35%\n",
      "2025-03-28 12:09:20,393 [INFO] - Japan_10Y_Bond (PRICE_Japan_10Y_Bond_bond): Cobertura aproximada 73.55%\n",
      "2025-03-28 12:09:20,393 [INFO] - UK_10Y_Bond (PRICE_UK_10Y_Bond_bond): Cobertura aproximada 78.62%\n",
      "2025-03-28 12:09:20,394 [INFO] - Germany_10Y_Bond (PRICE_Germany_10Y_Bond_bond): Cobertura aproximada 70.61%\n",
      "2025-03-28 12:09:20,394 [INFO] - Canada_10Y_Bond (PRICE_Canada_10Y_Bond_bond): Cobertura aproximada 68.08%\n",
      "2025-03-28 12:09:20,396 [INFO] - China_10Y_Bond (PRICE_China_10Y_Bond_bond): Cobertura aproximada 66.91%\n",
      "2025-03-28 12:09:20,399 [INFO] - CrudeOil_WTI (PRICE_CrudeOil_WTI_commodities): Cobertura aproximada 67.81%\n",
      "2025-03-28 12:09:20,401 [INFO] - Gold_Spot (PRICE_Gold_Spot_commodities): Cobertura aproximada 65.99%\n",
      "2025-03-28 12:09:20,402 [INFO] - Silver_Spot (PRICE_Silver_Spot_commodities): Cobertura aproximada 66.84%\n",
      "2025-03-28 12:09:20,404 [INFO] - Copper_Futures (PRICE_Copper_Futures_commodities): Cobertura aproximada 66.77%\n",
      "2025-03-28 12:09:20,407 [INFO] - Platinum_Spot (PRICE_Platinum_Spot_commodities): Cobertura aproximada 79.52%\n",
      "2025-03-28 12:09:20,408 [INFO] - EUR_USD_Spot (PRICE_EUR_USD_Spot_exchange_rate): Cobertura aproximada 67.32%\n",
      "2025-03-28 12:09:20,410 [INFO] - GBP_USD_Spot (PRICE_GBP_USD_Spot_exchange_rate): Cobertura aproximada 67.32%\n",
      "2025-03-28 12:09:20,411 [INFO] - JPY_USD_Spot (PRICE_JPY_USD_Spot_exchange_rate): Cobertura aproximada 67.32%\n",
      "2025-03-28 12:09:20,413 [INFO] - CNY_USD_Spot (PRICE_CNY_USD_Spot_exchange_rate): Cobertura aproximada 67.35%\n",
      "2025-03-28 12:09:20,415 [INFO] - AUD_USD_Spot (PRICE_AUD_USD_Spot_exchange_rate): Cobertura aproximada 67.32%\n",
      "2025-03-28 12:09:20,416 [INFO] - CAD_USD_Spot (PRICE_CAD_USD_Spot_exchange_rate): Cobertura aproximada 67.32%\n",
      "2025-03-28 12:09:20,418 [INFO] - MXN_USD_Spot (PRICE_MXN_USD_Spot_exchange_rate): Cobertura aproximada 67.32%\n",
      "2025-03-28 12:09:20,419 [INFO] - EUR_GBP_Cross (PRICE_EUR_GBP_Cross_exchange_rate): Cobertura aproximada 67.32%\n",
      "2025-03-28 12:09:20,421 [INFO] - S&P500_Index (ULTIMO_S&P500_Index_index_pricing): Cobertura aproximada 64.89%\n",
      "2025-03-28 12:09:20,422 [INFO] - NASDAQ_Composite (ULTIMO_NASDAQ_Composite_index_pricing): Cobertura aproximada 64.89%\n",
      "2025-03-28 12:09:20,424 [INFO] - Russell_2000 (ULTIMO_Russell_2000_index_pricing): Cobertura aproximada 65.21%\n",
      "2025-03-28 12:09:20,427 [INFO] - FTSE_100 (ULTIMO_FTSE_100_index_pricing): Cobertura aproximada 65.21%\n",
      "2025-03-28 12:09:20,428 [INFO] - Nikkei_225 (ULTIMO_Nikkei_225_index_pricing): Cobertura aproximada 62.94%\n",
      "2025-03-28 12:09:20,430 [INFO] - DAX_30 (ULTIMO_DAX_30_index_pricing): Cobertura aproximada 65.46%\n",
      "2025-03-28 12:09:20,432 [INFO] - Shanghai_Composite (PRICE_Shanghai_Composite_index_pricing): Cobertura aproximada 62.71%\n",
      "2025-03-28 12:09:20,435 [INFO] - VIX_VolatilityIndex (ULTIMO_VIX_VolatilityIndex_index_pricing): Cobertura aproximada 65.67%\n",
      "2025-03-28 12:09:20,436 [INFO] \n",
      "==================================================\n",
      "2025-03-28 12:09:20,436 [INFO] ESTADÍSTICAS DE VALORES\n",
      "2025-03-28 12:09:20,438 [INFO] ==================================================\n",
      "2025-03-28 12:09:20,444 [INFO] \n",
      "Estadísticas para PRICE_Australia_10Y_Bond_bond:\n",
      "2025-03-28 12:09:20,444 [INFO] - Min: 0.6010\n",
      "2025-03-28 12:09:20,445 [INFO] - Max: 4.9680\n",
      "2025-03-28 12:09:20,447 [INFO] - Media: 2.8083\n",
      "2025-03-28 12:09:20,448 [INFO] - Mediana: 2.7360\n",
      "2025-03-28 12:09:20,448 [INFO] - Desv. Estándar: 1.1255\n",
      "2025-03-28 12:09:20,451 [INFO] \n",
      "Estadísticas para PRICE_Italy_10Y_Bond_bond:\n",
      "2025-03-28 12:09:20,451 [INFO] - Min: 0.4610\n",
      "2025-03-28 12:09:20,453 [INFO] - Max: 4.9880\n",
      "2025-03-28 12:09:20,453 [INFO] - Media: 2.4441\n",
      "2025-03-28 12:09:20,454 [INFO] - Mediana: 2.2330\n",
      "2025-03-28 12:09:20,456 [INFO] - Desv. Estándar: 1.1677\n",
      "2025-03-28 12:09:20,458 [INFO] \n",
      "Estadísticas para PRICE_Japan_10Y_Bond_bond:\n",
      "2025-03-28 12:09:20,460 [INFO] - Min: -0.2910\n",
      "2025-03-28 12:09:20,460 [INFO] - Max: 1.5610\n",
      "2025-03-28 12:09:20,461 [INFO] - Media: 0.3267\n",
      "2025-03-28 12:09:20,463 [INFO] - Mediana: 0.1405\n",
      "2025-03-28 12:09:20,465 [INFO] - Desv. Estándar: 0.4281\n",
      "2025-03-28 12:09:20,466 [INFO] \n",
      "Estadísticas para PRICE_UK_10Y_Bond_bond:\n",
      "2025-03-28 12:09:20,468 [INFO] - Min: 0.0750\n",
      "2025-03-28 12:09:20,468 [INFO] - Max: 4.8850\n",
      "2025-03-28 12:09:20,469 [INFO] - Media: 2.0911\n",
      "2025-03-28 12:09:20,471 [INFO] - Mediana: 1.5320\n",
      "2025-03-28 12:09:20,472 [INFO] - Desv. Estándar: 1.4254\n",
      "2025-03-28 12:09:20,474 [INFO] \n",
      "Estadísticas para PRICE_Germany_10Y_Bond_bond:\n",
      "2025-03-28 12:09:20,475 [INFO] - Min: -0.8540\n",
      "2025-03-28 12:09:20,475 [INFO] - Max: 2.9680\n",
      "2025-03-28 12:09:20,477 [INFO] - Media: 0.8521\n",
      "2025-03-28 12:09:20,478 [INFO] - Mediana: 0.4722\n",
      "2025-03-28 12:09:20,478 [INFO] - Desv. Estándar: 1.0957\n",
      "2025-03-28 12:09:20,481 [INFO] \n",
      "Estadísticas para PRICE_Canada_10Y_Bond_bond:\n",
      "2025-03-28 12:09:20,483 [INFO] - Min: 0.4350\n",
      "2025-03-28 12:09:20,485 [INFO] - Max: 4.2750\n",
      "2025-03-28 12:09:20,485 [INFO] - Media: 2.1081\n",
      "2025-03-28 12:09:20,486 [INFO] - Mediana: 1.9390\n",
      "2025-03-28 12:09:20,486 [INFO] - Desv. Estándar: 0.8808\n",
      "2025-03-28 12:09:20,488 [INFO] \n",
      "Estadísticas para PRICE_China_10Y_Bond_bond:\n",
      "2025-03-28 12:09:20,491 [INFO] - Min: 1.6070\n",
      "2025-03-28 12:09:20,492 [INFO] - Max: 4.7100\n",
      "2025-03-28 12:09:20,492 [INFO] - Media: 3.0418\n",
      "2025-03-28 12:09:20,494 [INFO] - Mediana: 3.0350\n",
      "2025-03-28 12:09:20,495 [INFO] - Desv. Estándar: 0.6442\n",
      "2025-03-28 12:09:20,497 [INFO] \n",
      "Estadísticas para PRICE_CrudeOil_WTI_commodities:\n",
      "2025-03-28 12:09:20,498 [INFO] - Min: 11.5700\n",
      "2025-03-28 12:09:20,500 [INFO] - Max: 119.7800\n",
      "2025-03-28 12:09:20,500 [INFO] - Media: 64.9986\n",
      "2025-03-28 12:09:20,502 [INFO] - Mediana: 65.6800\n",
      "2025-03-28 12:09:20,502 [INFO] - Desv. Estándar: 18.5899\n",
      "2025-03-28 12:09:20,505 [INFO] \n",
      "Estadísticas para PRICE_Gold_Spot_commodities:\n",
      "2025-03-28 12:09:20,506 [INFO] - Min: 1049.6000\n",
      "2025-03-28 12:09:20,506 [INFO] - Max: 3071.3000\n",
      "2025-03-28 12:09:20,506 [INFO] - Media: 1673.4516\n",
      "2025-03-28 12:09:20,508 [INFO] - Mediana: 1516.7000\n",
      "2025-03-28 12:09:20,508 [INFO] - Desv. Estándar: 507.3299\n",
      "2025-03-28 12:09:20,511 [INFO] \n",
      "Estadísticas para PRICE_Silver_Spot_commodities:\n",
      "2025-03-28 12:09:20,512 [INFO] - Min: 11.7720\n",
      "2025-03-28 12:09:20,512 [INFO] - Max: 35.0410\n",
      "2025-03-28 12:09:20,514 [INFO] - Media: 20.9993\n",
      "2025-03-28 12:09:20,515 [INFO] - Mediana: 19.2315\n",
      "2025-03-28 12:09:20,515 [INFO] - Desv. Estándar: 5.5114\n",
      "2025-03-28 12:09:20,518 [INFO] \n",
      "Estadísticas para PRICE_Copper_Futures_commodities:\n",
      "2025-03-28 12:09:20,522 [INFO] - Min: 1.9435\n",
      "2025-03-28 12:09:20,525 [INFO] - Max: 5.2430\n",
      "2025-03-28 12:09:20,526 [INFO] - Media: 3.3246\n",
      "2025-03-28 12:09:20,528 [INFO] - Mediana: 3.1122\n",
      "2025-03-28 12:09:20,529 [INFO] - Desv. Estándar: 0.8049\n",
      "2025-03-28 12:09:20,532 [INFO] \n",
      "Estadísticas para PRICE_Platinum_Spot_commodities:\n",
      "2025-03-28 12:09:20,534 [INFO] - Min: 595.2000\n",
      "2025-03-28 12:09:20,536 [INFO] - Max: 1516.2000\n",
      "2025-03-28 12:09:20,536 [INFO] - Media: 1000.0674\n",
      "2025-03-28 12:09:20,537 [INFO] - Mediana: 969.5500\n",
      "2025-03-28 12:09:20,539 [INFO] - Desv. Estándar: 152.6605\n",
      "2025-03-28 12:09:20,540 [INFO] \n",
      "Estadísticas para PRICE_EUR_USD_Spot_exchange_rate:\n",
      "2025-03-28 12:09:20,542 [INFO] - Min: 0.9592\n",
      "2025-03-28 12:09:20,543 [INFO] - Max: 1.3933\n",
      "2025-03-28 12:09:20,546 [INFO] - Media: 1.1316\n",
      "2025-03-28 12:09:20,548 [INFO] - Mediana: 1.1150\n",
      "2025-03-28 12:09:20,548 [INFO] - Desv. Estándar: 0.0796\n",
      "2025-03-28 12:09:20,553 [INFO] \n",
      "Estadísticas para PRICE_GBP_USD_Spot_exchange_rate:\n",
      "2025-03-28 12:09:20,554 [INFO] - Min: 1.0684\n",
      "2025-03-28 12:09:20,554 [INFO] - Max: 1.7163\n",
      "2025-03-28 12:09:20,556 [INFO] - Media: 1.3432\n",
      "2025-03-28 12:09:20,557 [INFO] - Mediana: 1.3008\n",
      "2025-03-28 12:09:20,559 [INFO] - Desv. Estándar: 0.1275\n",
      "2025-03-28 12:09:20,562 [INFO] \n",
      "Estadísticas para PRICE_JPY_USD_Spot_exchange_rate:\n",
      "2025-03-28 12:09:20,563 [INFO] - Min: 99.8700\n",
      "2025-03-28 12:09:20,565 [INFO] - Max: 161.6800\n",
      "2025-03-28 12:09:20,566 [INFO] - Media: 121.4077\n",
      "2025-03-28 12:09:20,566 [INFO] - Mediana: 113.2000\n",
      "2025-03-28 12:09:20,568 [INFO] - Desv. Estándar: 17.4185\n",
      "2025-03-28 12:09:20,570 [INFO] \n",
      "Estadísticas para PRICE_CNY_USD_Spot_exchange_rate:\n",
      "2025-03-28 12:09:20,571 [INFO] - Min: 6.0402\n",
      "2025-03-28 12:09:20,571 [INFO] - Max: 7.3430\n",
      "2025-03-28 12:09:20,573 [INFO] - Media: 6.7468\n",
      "2025-03-28 12:09:20,574 [INFO] - Mediana: 6.7663\n",
      "2025-03-28 12:09:20,574 [INFO] - Desv. Estándar: 0.3656\n",
      "2025-03-28 12:09:20,576 [INFO] \n",
      "Estadísticas para PRICE_AUD_USD_Spot_exchange_rate:\n",
      "2025-03-28 12:09:20,577 [INFO] - Min: 0.5741\n",
      "2025-03-28 12:09:20,577 [INFO] - Max: 0.9496\n",
      "2025-03-28 12:09:20,579 [INFO] - Media: 0.7250\n",
      "2025-03-28 12:09:20,579 [INFO] - Mediana: 0.7182\n",
      "2025-03-28 12:09:20,580 [INFO] - Desv. Estándar: 0.0726\n",
      "2025-03-28 12:09:20,583 [INFO] \n",
      "Estadísticas para PRICE_CAD_USD_Spot_exchange_rate:\n",
      "2025-03-28 12:09:20,583 [INFO] - Min: 1.0631\n",
      "2025-03-28 12:09:20,585 [INFO] - Max: 1.4576\n",
      "2025-03-28 12:09:20,586 [INFO] - Media: 1.3060\n",
      "2025-03-28 12:09:20,588 [INFO] - Mediana: 1.3170\n",
      "2025-03-28 12:09:20,588 [INFO] - Desv. Estándar: 0.0821\n",
      "2025-03-28 12:09:20,591 [INFO] \n",
      "Estadísticas para PRICE_MXN_USD_Spot_exchange_rate:\n",
      "2025-03-28 12:09:20,591 [INFO] - Min: 12.8375\n",
      "2025-03-28 12:09:20,593 [INFO] - Max: 25.3380\n",
      "2025-03-28 12:09:20,594 [INFO] - Media: 18.6237\n",
      "2025-03-28 12:09:20,596 [INFO] - Mediana: 19.0703\n",
      "2025-03-28 12:09:20,597 [INFO] - Desv. Estándar: 2.2955\n",
      "2025-03-28 12:09:20,600 [INFO] \n",
      "Estadísticas para PRICE_EUR_GBP_Cross_exchange_rate:\n",
      "2025-03-28 12:09:20,602 [INFO] - Min: 0.6937\n",
      "2025-03-28 12:09:20,603 [INFO] - Max: 0.9396\n",
      "2025-03-28 12:09:20,603 [INFO] - Media: 0.8452\n",
      "2025-03-28 12:09:20,605 [INFO] - Mediana: 0.8550\n",
      "2025-03-28 12:09:20,606 [INFO] - Desv. Estándar: 0.0480\n",
      "2025-03-28 12:09:20,608 [INFO] \n",
      "Estadísticas para ULTIMO_S&P500_Index_index_pricing:\n",
      "2025-03-28 12:09:20,609 [INFO] - Min: 1741.9000\n",
      "2025-03-28 12:09:20,611 [INFO] - Max: 6144.1500\n",
      "2025-03-28 12:09:20,611 [INFO] - Media: 3423.6247\n",
      "2025-03-28 12:09:20,612 [INFO] - Mediana: 2995.4000\n",
      "2025-03-28 12:09:20,612 [INFO] - Desv. Estándar: 1265.8021\n",
      "2025-03-28 12:09:20,616 [INFO] \n",
      "Estadísticas para ULTIMO_NASDAQ_Composite_index_pricing:\n",
      "2025-03-28 12:09:20,617 [INFO] - Min: 3996.9600\n",
      "2025-03-28 12:09:20,617 [INFO] - Max: 20173.8900\n",
      "2025-03-28 12:09:20,619 [INFO] - Media: 10044.6835\n",
      "2025-03-28 12:09:20,619 [INFO] - Mediana: 8475.3100\n",
      "2025-03-28 12:09:20,620 [INFO] - Desv. Estándar: 4710.2897\n",
      "2025-03-28 12:09:20,623 [INFO] \n",
      "Estadísticas para ULTIMO_Russell_2000_index_pricing:\n",
      "2025-03-28 12:09:20,623 [INFO] - Min: 953.7200\n",
      "2025-03-28 12:09:20,625 [INFO] - Max: 2442.7400\n",
      "2025-03-28 12:09:20,625 [INFO] - Media: 1648.6844\n",
      "2025-03-28 12:09:20,626 [INFO] - Mediana: 1589.4350\n",
      "2025-03-28 12:09:20,628 [INFO] - Desv. Estándar: 383.5475\n",
      "2025-03-28 12:09:20,629 [INFO] \n",
      "Estadísticas para ULTIMO_FTSE_100_index_pricing:\n",
      "2025-03-28 12:09:20,631 [INFO] - Min: 4993.8900\n",
      "2025-03-28 12:09:20,631 [INFO] - Max: 8871.3100\n",
      "2025-03-28 12:09:20,633 [INFO] - Media: 7212.8819\n",
      "2025-03-28 12:09:20,633 [INFO] - Mediana: 7253.1350\n",
      "2025-03-28 12:09:20,634 [INFO] - Desv. Estándar: 701.0206\n",
      "2025-03-28 12:09:20,636 [INFO] \n",
      "Estadísticas para ULTIMO_Nikkei_225_index_pricing:\n",
      "2025-03-28 12:09:20,637 [INFO] - Min: 13910.1600\n",
      "2025-03-28 12:09:20,639 [INFO] - Max: 42224.0200\n",
      "2025-03-28 12:09:20,639 [INFO] - Media: 25056.3002\n",
      "2025-03-28 12:09:20,640 [INFO] - Mediana: 22796.9150\n",
      "2025-03-28 12:09:20,640 [INFO] - Desv. Estándar: 7348.3297\n",
      "2025-03-28 12:09:20,643 [INFO] \n",
      "Estadísticas para ULTIMO_DAX_30_index_pricing:\n",
      "2025-03-28 12:09:20,645 [INFO] - Min: 8441.7100\n",
      "2025-03-28 12:09:20,645 [INFO] - Max: 23419.4800\n",
      "2025-03-28 12:09:20,646 [INFO] - Media: 13736.2718\n",
      "2025-03-28 12:09:20,648 [INFO] - Mediana: 12806.4950\n",
      "2025-03-28 12:09:20,649 [INFO] - Desv. Estándar: 3561.0220\n",
      "2025-03-28 12:09:20,651 [INFO] \n",
      "Estadísticas para PRICE_Shanghai_Composite_index_pricing:\n",
      "2025-03-28 12:09:20,652 [INFO] - Min: 1991.2500\n",
      "2025-03-28 12:09:20,652 [INFO] - Max: 5166.3500\n",
      "2025-03-28 12:09:20,654 [INFO] - Media: 3125.0421\n",
      "2025-03-28 12:09:20,656 [INFO] - Mediana: 3168.7750\n",
      "2025-03-28 12:09:20,657 [INFO] - Desv. Estándar: 418.0282\n",
      "2025-03-28 12:09:20,659 [INFO] \n",
      "Estadísticas para ULTIMO_VIX_VolatilityIndex_index_pricing:\n",
      "2025-03-28 12:09:20,659 [INFO] - Min: 9.1400\n",
      "2025-03-28 12:09:20,660 [INFO] - Max: 82.6900\n",
      "2025-03-28 12:09:20,660 [INFO] - Media: 17.8315\n",
      "2025-03-28 12:09:20,662 [INFO] - Mediana: 16.3000\n",
      "2025-03-28 12:09:20,662 [INFO] - Desv. Estándar: 6.7398\n",
      "2025-03-28 12:09:20,663 [INFO] \n",
      "==================================================\n",
      "2025-03-28 12:09:20,663 [INFO] GUARDANDO RESULTADOS\n",
      "2025-03-28 12:09:20,665 [INFO] ==================================================\n",
      "2025-03-28 12:09:20,666 [INFO] Guardando resultados en: datos_economicos_normales_procesados.xlsx\n",
      "2025-03-28 12:09:22,899 [INFO] Archivo guardado exitosamente: datos_economicos_normales_procesados.xlsx\n",
      "2025-03-28 12:09:22,900 [INFO] \n",
      "==================================================\n",
      "2025-03-28 12:09:22,900 [INFO] RESUMEN DE EJECUCIÓN\n",
      "2025-03-28 12:09:22,902 [INFO] ==================================================\n",
      "2025-03-28 12:09:22,902 [INFO] Proceso: MyinvestingreportNormal\n",
      "2025-03-28 12:09:22,902 [INFO] Tiempo de ejecución: 19.34 segundos\n",
      "2025-03-28 12:09:22,903 [INFO] Archivos procesados: 28\n",
      "2025-03-28 12:09:22,905 [INFO] Archivos con error: 0\n",
      "2025-03-28 12:09:22,905 [INFO] Archivos procesados correctamente: 28\n",
      "2025-03-28 12:09:22,905 [INFO] Periodo de datos: 2014-01-01 a 2025-12-03\n",
      "2025-03-28 12:09:22,906 [INFO] Datos combinados: 4355 filas, 29 columnas\n",
      "2025-03-28 12:09:22,906 [INFO] Archivo de salida: datos_economicos_normales_procesados.xlsx\n",
      "2025-03-28 12:09:22,908 [INFO] Estado: COMPLETADO\n",
      "2025-03-28 12:09:22,908 [INFO] ==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado exitosamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Configuración de logging\n",
    "# ---------------------------------------------------\n",
    "def configurar_logging(log_file='myinvestingreportnormal.log'):\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger('MyinvestingreportNormal')\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Función central para conversión de valores numéricos\n",
    "# ---------------------------------------------------\n",
    "def convertir_valor(valor, variable=None, formatos_conocidos=None):\n",
    "    \"\"\"\n",
    "    Convierte cualquier representación de valor numérico a float.\n",
    "\n",
    "    Args:\n",
    "        valor: Valor a convertir (string, int, float)\n",
    "        variable: Nombre de la variable (opcional, para formatos específicos)\n",
    "        formatos_conocidos: Diccionario {variable: formato} para optimizar conversiones\n",
    "\n",
    "    Returns:\n",
    "        float: Valor numérico convertido o None si no es posible\n",
    "    \"\"\"\n",
    "    # Si ya es numérico, retornarlo directamente\n",
    "    if isinstance(valor, (int, float)):\n",
    "        return float(valor)\n",
    "    \n",
    "    # Si es None o no es string, retornar None\n",
    "    if not isinstance(valor, str) or valor is None:\n",
    "        return None\n",
    "\n",
    "    valor_limpio = valor.strip()\n",
    "    if not valor_limpio:\n",
    "        return None\n",
    "\n",
    "    # Si tenemos un formato conocido para la variable, aplicarlo\n",
    "    if variable and formatos_conocidos and variable in formatos_conocidos:\n",
    "        formato = formatos_conocidos[variable]\n",
    "        if formato == 'europeo':\n",
    "            # En formato europeo, el punto es separador de miles y la coma decimal\n",
    "            valor_limpio = valor_limpio.replace('.', '')\n",
    "            valor_limpio = valor_limpio.replace(',', '.')\n",
    "    # Determinar multiplicador basado en sufijos\n",
    "    multiplicadores = {\n",
    "        '%': 1,      # Si se requiere convertir a proporción se puede dividir por 100\n",
    "        'K': 1e3,    # Miles\n",
    "        'M': 1e6,    # Millones\n",
    "        'B': 1e9,    # Billones\n",
    "        'T': 1e12    # Trillones\n",
    "    }\n",
    "    multiplicador = 1\n",
    "    for sufijo, mult in multiplicadores.items():\n",
    "        if valor_limpio.endswith(sufijo):\n",
    "            valor_limpio = valor_limpio.replace(sufijo, '')\n",
    "            multiplicador = mult\n",
    "            break\n",
    "\n",
    "    # Detectar formato basado en separadores\n",
    "    if ',' in valor_limpio and '.' in valor_limpio:\n",
    "        if valor_limpio.rfind(',') > valor_limpio.rfind('.'):\n",
    "            # Formato europeo: \"1.234,56\"\n",
    "            valor_limpio = valor_limpio.replace('.', '')\n",
    "            valor_limpio = valor_limpio.replace(',', '.')\n",
    "        else:\n",
    "            # Formato americano: \"1,234.56\"\n",
    "            valor_limpio = valor_limpio.replace(',', '')\n",
    "    elif ',' in valor_limpio:\n",
    "        partes = valor_limpio.split(',')\n",
    "        if len(partes) == 2 and len(partes[1]) <= 2:\n",
    "            # Probable decimal\n",
    "            valor_limpio = valor_limpio.replace(',', '.')\n",
    "        else:\n",
    "            valor_limpio = valor_limpio.replace(',', '')\n",
    "    # En caso de que solo haya puntos se asume que es formato americano\n",
    "\n",
    "    try:\n",
    "        return float(valor_limpio) * multiplicador\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Clase para detección y cacheo de formatos numéricos\n",
    "# ---------------------------------------------------\n",
    "class FormatosNumericos:\n",
    "    \"\"\"Clase para detectar y cachear formatos numéricos\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.formatos_cache = {}  # {variable: formato}\n",
    "\n",
    "    def detectar_formato(self, valores, variable=None):\n",
    "        \"\"\"\n",
    "        Detecta el formato numérico predominante en una lista de valores.\n",
    "\n",
    "        Args:\n",
    "            valores: Lista de valores para analizar.\n",
    "            variable: Nombre de la variable (opcional).\n",
    "\n",
    "        Returns:\n",
    "            str: Formato detectado ('europeo' o 'americano').\n",
    "        \"\"\"\n",
    "        conteo = {\n",
    "            'europeo': 0,   # Ejemplo: 1.234,56\n",
    "            'americano': 0  # Ejemplo: 1,234.56\n",
    "        }\n",
    "        for valor in valores:\n",
    "            if not isinstance(valor, str):\n",
    "                continue\n",
    "            valor = valor.strip()\n",
    "            if ',' in valor and '.' in valor:\n",
    "                if valor.rfind(',') > valor.rfind('.'):\n",
    "                    conteo['europeo'] += 1\n",
    "                else:\n",
    "                    conteo['americano'] += 1\n",
    "            elif ',' in valor:\n",
    "                partes = valor.split(',')\n",
    "                if len(partes) == 2 and len(partes[1]) <= 2:\n",
    "                    conteo['europeo'] += 1\n",
    "                else:\n",
    "                    conteo['americano'] += 1\n",
    "            elif '.' in valor:\n",
    "                conteo['americano'] += 1\n",
    "\n",
    "        formato = 'americano'  # Valor por defecto\n",
    "        if conteo['europeo'] > conteo['americano']:\n",
    "            formato = 'europeo'\n",
    "        if variable:\n",
    "            self.formatos_cache[variable] = formato\n",
    "        return formato\n",
    "\n",
    "    def obtener_formato(self, variable):\n",
    "        \"\"\"Obtiene el formato conocido para una variable\"\"\"\n",
    "        return self.formatos_cache.get(variable)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Función para convertir fechas en diversos formatos\n",
    "# ---------------------------------------------------\n",
    "def convertir_fecha(fecha_str):\n",
    "    \"\"\"\n",
    "    Convierte diversos formatos de fecha a pd.Timestamp.\n",
    "\n",
    "    Args:\n",
    "        fecha_str: Fecha en cualquier formato\n",
    "\n",
    "    Returns:\n",
    "        pd.Timestamp o None si no es posible la conversión.\n",
    "    \"\"\"\n",
    "    # Si ya es datetime o Timestamp\n",
    "    if isinstance(fecha_str, (pd.Timestamp, datetime)):\n",
    "        return pd.Timestamp(fecha_str)\n",
    "    \n",
    "    if pd.isna(fecha_str):\n",
    "        return None\n",
    "\n",
    "    # Si es numérico, intentar formato compacto DDMMYYYY\n",
    "    if isinstance(fecha_str, (int, float)):\n",
    "        fecha_str = str(int(fecha_str))\n",
    "        if len(fecha_str) == 8:\n",
    "            try:\n",
    "                dia = int(fecha_str[:2])\n",
    "                mes = int(fecha_str[2:4])\n",
    "                anio = int(fecha_str[4:])\n",
    "                return pd.Timestamp(year=anio, month=mes, day=dia)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    if isinstance(fecha_str, str):\n",
    "        fecha_str = fecha_str.strip()\n",
    "        formatos = [\n",
    "            '%d.%m.%Y', '%d/%m/%Y', '%d-%m-%Y',\n",
    "            '%m/%d/%Y', '%Y-%m-%d',\n",
    "            '%Y%m%d', '%d%m%Y'\n",
    "        ]\n",
    "        for fmt in formatos:\n",
    "            try:\n",
    "                return pd.to_datetime(fecha_str, format=fmt)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        # Intentar detectar patrones como \"Apr 01, 2025\" o meses en español\n",
    "        try:\n",
    "            if re.search(r'([A-Za-z]+\\s+\\d+,\\s+\\d{4})', fecha_str):\n",
    "                match = re.search(r'([A-Za-z]+\\s+\\d+,\\s+\\d{4})', fecha_str)\n",
    "                return pd.to_datetime(match.group(1))\n",
    "            # Reemplazar meses en español por inglés\n",
    "            meses_es = {\n",
    "                'ene': 'Jan', 'feb': 'Feb', 'mar': 'Mar', 'abr': 'Apr',\n",
    "                'may': 'May', 'jun': 'Jun', 'jul': 'Jul', 'ago': 'Aug',\n",
    "                'sep': 'Sep', 'oct': 'Oct', 'nov': 'Nov', 'dic': 'Dec'\n",
    "            }\n",
    "            texto_procesado = fecha_str.lower()\n",
    "            for mes_es, mes_en in meses_es.items():\n",
    "                if mes_es in texto_procesado:\n",
    "                    texto_procesado = texto_procesado.replace(mes_es, mes_en)\n",
    "            return pd.to_datetime(texto_procesado)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Clase principal: MyinvestingreportNormal\n",
    "# ---------------------------------------------------\n",
    "class MyinvestingreportNormal:\n",
    "    \"\"\"\n",
    "    Clase mejorada para el procesamiento de datos económicos.\n",
    "    Integra funciones centralizadas para conversión numérica y de fechas,\n",
    "    detección automática de columnas y lectura adaptativa de CSV.\n",
    "    \"\"\"\n",
    "    def __init__(self, config_file, data_root='data/Macro/raw', log_file='myinvestingreportnormal.log'):\n",
    "        self.config_file = config_file\n",
    "        self.data_root = data_root\n",
    "        self.logger = configurar_logging(log_file)\n",
    "        self.config_data = None\n",
    "        self.fecha_min_global = None\n",
    "        self.fecha_max_global = None\n",
    "        self.indice_diario = None\n",
    "        self.datos_procesados = {}\n",
    "        self.df_combinado = None\n",
    "        self.estadisticas = {}\n",
    "\n",
    "        # Nuevos atributos para manejo de formatos\n",
    "        self.formatos_numericos = FormatosNumericos()\n",
    "        self.formatos_conocidos = {}  # Para guardar configuraciones de CSV exitosas\n",
    "\n",
    "        self.inicializar_formatos_conocidos()\n",
    "\n",
    "        self.logger.info(\"=\" * 80)\n",
    "        self.logger.info(\"INICIANDO PROCESO: MyinvestingreportNormal\")\n",
    "        self.logger.info(f\"Archivo de configuración: {config_file}\")\n",
    "        self.logger.info(f\"Directorio raíz de datos: {data_root}\")\n",
    "        self.logger.info(f\"Fecha y hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        self.logger.info(\"=\" * 80)\n",
    "\n",
    "    def inicializar_formatos_conocidos(self):\n",
    "        \"\"\"Inicializa formatos conocidos para variables específicas (por ejemplo, índices europeos)\"\"\"\n",
    "        indices_europeos = [\n",
    "            'Russell_2000', 'NASDAQ_Composite', 'S&P500_Index',\n",
    "            'Nikkei_225', 'DAX_30', 'VIX_VolatilityIndex'\n",
    "        ]\n",
    "        for indice in indices_europeos:\n",
    "            self.formatos_numericos.formatos_cache[indice] = 'europeo'\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Métodos para leer configuración y archivos\n",
    "    # ---------------------------------------------------\n",
    "    def leer_configuracion(self):\n",
    "        self.logger.info(\"Leyendo archivo de configuración...\")\n",
    "        try:\n",
    "            df_config = pd.read_excel(self.config_file)\n",
    "            self.config_data = df_config[\n",
    "                (df_config['Fuente'] == 'Investing Data') &\n",
    "                (df_config['Tipo de Preprocesamiento Según la Fuente'] == 'Normal')\n",
    "            ].copy()\n",
    "            num_configs = len(self.config_data)\n",
    "            self.logger.info(f\"Se encontraron {num_configs} configuraciones para procesar\")\n",
    "            if num_configs == 0:\n",
    "                self.logger.warning(\"No se encontraron configuraciones que cumplan los criterios\")\n",
    "                return None\n",
    "            return self.config_data\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al leer configuración: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def encontrar_ruta_archivo(self, variable, tipo_macro):\n",
    "        ruta_base = os.path.join(self.data_root, tipo_macro)\n",
    "        nombre_archivo = f\"{variable}.csv\"\n",
    "        ruta_completa = os.path.join(ruta_base, nombre_archivo)\n",
    "        if os.path.exists(ruta_completa):\n",
    "            return ruta_completa\n",
    "        nombre_archivo_alt = f\"{variable}.xlsx\"\n",
    "        ruta_completa_alt = os.path.join(ruta_base, nombre_archivo_alt)\n",
    "        if os.path.exists(ruta_completa_alt):\n",
    "            return ruta_completa_alt\n",
    "        for root, dirs, files in os.walk(self.data_root):\n",
    "            if nombre_archivo in files:\n",
    "                return os.path.join(root, nombre_archivo)\n",
    "            if nombre_archivo_alt in files:\n",
    "                return os.path.join(root, nombre_archivo_alt)\n",
    "        return None\n",
    "\n",
    "    def leer_csv_adaptativo(self, ruta_archivo, variable):\n",
    "        \"\"\"\n",
    "        Lee un archivo CSV adaptándose a diferentes configuraciones de separadores,\n",
    "        codificaciones y formatos decimales.\n",
    "        \"\"\"\n",
    "        configuraciones = [\n",
    "            # Formato americano\n",
    "            {'sep': ',', 'decimal': '.', 'encoding': 'utf-8'},\n",
    "            {'sep': ',', 'decimal': '.', 'encoding': 'latin1'},\n",
    "            # Formato europeo\n",
    "            {'sep': ';', 'decimal': ',', 'thousands': '.', 'encoding': 'utf-8'},\n",
    "            {'sep': ';', 'decimal': ',', 'thousands': '.', 'encoding': 'latin1'},\n",
    "            {'sep': ',', 'decimal': ',', 'thousands': '.', 'encoding': 'utf-8'},\n",
    "            # Otros comunes\n",
    "            {'sep': '\\t', 'encoding': 'utf-8'},\n",
    "            {'sep': ' ', 'encoding': 'utf-8'}\n",
    "        ]\n",
    "        # Si ya se conoce una configuración para esta variable, intentarla primero\n",
    "        if variable in self.formatos_conocidos:\n",
    "            config_conocida = self.formatos_conocidos[variable]\n",
    "            try:\n",
    "                df = pd.read_csv(ruta_archivo, **config_conocida)\n",
    "                if len(df) > 0:\n",
    "                    return df\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        errores = []\n",
    "        for idx, config in enumerate(configuraciones):\n",
    "            try:\n",
    "                df = pd.read_csv(ruta_archivo, **config)\n",
    "                if len(df) > 0:\n",
    "                    self.formatos_conocidos[variable] = config\n",
    "                    return df\n",
    "            except Exception as e:\n",
    "                errores.append(f\"Config {idx}: {str(e)}\")\n",
    "        self.logger.error(f\"No se pudo leer {ruta_archivo} con ninguna configuración\")\n",
    "        for error in errores:\n",
    "            self.logger.debug(f\"- {error}\")\n",
    "        return None\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Detección automática de columnas de fecha y valor\n",
    "    # ---------------------------------------------------\n",
    "    def detectar_columnas(self, df):\n",
    "        \"\"\"\n",
    "        Detecta automáticamente las columnas de fecha y valor en un DataFrame.\n",
    "        Returns:\n",
    "            tuple: (columna_fecha, columna_valor) o (None, None)\n",
    "        \"\"\"\n",
    "        candidatos_fecha = [col for col in df.columns if any(\n",
    "            palabra in col.lower() for palabra in ['date', 'fecha', 'time', 'día', 'day', 'periodo']\n",
    "        )]\n",
    "        candidatos_valor = [col for col in df.columns if any(\n",
    "            palabra in col.lower() for palabra in ['price', 'precio', 'close', 'cierre', 'último', 'ultimo', 'valor', 'value']\n",
    "        )]\n",
    "\n",
    "        columnas_datetime = [col for col in df.columns if pd.api.types.is_datetime64_any_dtype(df[col])]\n",
    "        columna_fecha = None\n",
    "        if columnas_datetime:\n",
    "            columna_fecha = columnas_datetime[0]\n",
    "        elif candidatos_fecha:\n",
    "            for col in candidatos_fecha:\n",
    "                try:\n",
    "                    pd.to_datetime(df[col].iloc[:5])\n",
    "                    columna_fecha = col\n",
    "                    break\n",
    "                except Exception:\n",
    "                    continue\n",
    "        if columna_fecha is None and len(df.columns) > 0:\n",
    "            try:\n",
    "                pd.to_datetime(df[df.columns[0]].iloc[:5])\n",
    "                columna_fecha = df.columns[0]\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        columna_valor = None\n",
    "        if candidatos_valor:\n",
    "            columna_valor = candidatos_valor[0]\n",
    "        elif len(df.columns) > 1:\n",
    "            columna_valor = df.columns[1]\n",
    "        return columna_fecha, columna_valor\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Conversión de fechas\n",
    "    # ---------------------------------------------------\n",
    "    def convertir_fecha(self, fecha_str):\n",
    "        return convertir_fecha(fecha_str)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Versión optimizada de limpiar_valor_porcentaje\n",
    "    # ---------------------------------------------------\n",
    "    def limpiar_valor_porcentaje(self, valor, variable=None):\n",
    "        return convertir_valor(valor, variable, self.formatos_numericos.formatos_cache)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Procesar archivo individual\n",
    "    # ---------------------------------------------------\n",
    "    def procesar_archivo(self, config_row):\n",
    "        variable = config_row['Variable']\n",
    "        tipo_macro = config_row['Tipo Macro']\n",
    "        target_col = config_row['TARGET']\n",
    "\n",
    "        ruta_archivo = self.encontrar_ruta_archivo(variable, tipo_macro)\n",
    "        self.logger.info(f\"\\nProcesando: {variable} ({tipo_macro})\")\n",
    "        self.logger.info(f\"- Archivo: {variable}\")\n",
    "        self.logger.info(f\"- Columna TARGET: {target_col}\")\n",
    "        if ruta_archivo is None:\n",
    "            self.logger.error(f\"- ERROR: Archivo no encontrado: {variable}\")\n",
    "            return variable, None\n",
    "        self.logger.info(f\"- Ruta encontrada: {ruta_archivo}\")\n",
    "\n",
    "        try:\n",
    "            _, extension = os.path.splitext(ruta_archivo)\n",
    "            extension = extension.lower()\n",
    "            if extension == '.csv':\n",
    "                df = self.leer_csv_adaptativo(ruta_archivo, variable)\n",
    "            elif extension in ['.xlsx', '.xls']:\n",
    "                df = pd.read_excel(ruta_archivo, engine='openpyxl')\n",
    "            else:\n",
    "                self.logger.error(f\"- ERROR: Formato de archivo no soportado: {extension}\")\n",
    "                return variable, None\n",
    "            if df is None or len(df) == 0:\n",
    "                self.logger.error(\"- ERROR: El archivo está vacío o no se pudo leer\")\n",
    "                return variable, None\n",
    "\n",
    "            col_fecha, col_valor = self.detectar_columnas(df)\n",
    "            if col_fecha is None or col_valor is None:\n",
    "                self.logger.error(\"- ERROR: No se pudieron detectar columnas necesarias (fecha o valor)\")\n",
    "                return variable, None\n",
    "\n",
    "            # Procesar fechas\n",
    "            df['fecha'] = df[col_fecha].apply(self.convertir_fecha)\n",
    "            df = df.dropna(subset=['fecha'])\n",
    "            # Detectar formato numérico en una muestra\n",
    "            muestra_valores = df[col_valor].astype(str).head(20).tolist()\n",
    "            formato_detectado = self.formatos_numericos.detectar_formato(muestra_valores, variable)\n",
    "            self.logger.info(f\"Formato numérico detectado para {variable}: {formato_detectado}\")\n",
    "\n",
    "            # Procesar valores con la función central\n",
    "            df['valor'] = df[col_valor].apply(lambda x: self.limpiar_valor_porcentaje(x, variable))\n",
    "            df = df.dropna(subset=['valor'])\n",
    "\n",
    "            total_filas = len(df)\n",
    "            if total_filas == 0:\n",
    "                self.logger.error(f\"- ERROR: No se encontraron valores válidos en {variable}\")\n",
    "                return variable, None\n",
    "\n",
    "            # Renombrar la columna de valor según el patrón\n",
    "            nuevo_nombre = f\"{target_col}_{variable}_{tipo_macro}\"\n",
    "            df.rename(columns={'valor': nuevo_nombre}, inplace=True)\n",
    "\n",
    "            # Seleccionar solo las columnas relevantes y ordenar por fecha\n",
    "            df_procesado = df[['fecha', nuevo_nombre]].copy()\n",
    "            df_procesado = df_procesado.sort_values('fecha')\n",
    "\n",
    "            # Actualizar fechas globales\n",
    "            fecha_min = df_procesado['fecha'].min()\n",
    "            fecha_max = df_procesado['fecha'].max()\n",
    "            if self.fecha_min_global is None or fecha_min < self.fecha_min_global:\n",
    "                self.fecha_min_global = fecha_min\n",
    "            if self.fecha_max_global is None or fecha_max > self.fecha_max_global:\n",
    "                self.fecha_max_global = fecha_max\n",
    "\n",
    "            # Registrar estadísticas\n",
    "            self.estadisticas[variable] = {\n",
    "                'tipo_macro': tipo_macro,\n",
    "                'columna_target': target_col,\n",
    "                'total_filas': total_filas,\n",
    "                'valores_validos': df_procesado[nuevo_nombre].count(),\n",
    "                'fecha_min': fecha_min,\n",
    "                'fecha_max': fecha_max,\n",
    "                'nuevo_nombre': nuevo_nombre\n",
    "            }\n",
    "            self.logger.info(f\"- {variable}: {total_filas} filas procesadas, periodo: {fecha_min.strftime('%Y-%m-%d')} a {fecha_max.strftime('%Y-%m-%d')}\")\n",
    "            return variable, df_procesado\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"- ERROR al procesar {ruta_archivo}: {str(e)}\")\n",
    "            return variable, None\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Generar índice diario y combinar datos\n",
    "    # ---------------------------------------------------\n",
    "    def generar_indice_diario(self):\n",
    "        if self.fecha_min_global is None or self.fecha_max_global is None:\n",
    "            self.logger.error(\"No se pudieron determinar fechas mínima y máxima globales\")\n",
    "            return None\n",
    "        self.logger.info(\"\\nGenerando índice temporal diario...\")\n",
    "        todas_fechas = pd.date_range(start=self.fecha_min_global, end=self.fecha_max_global, freq='D')\n",
    "        self.indice_diario = pd.DataFrame({'fecha': todas_fechas})\n",
    "        self.logger.info(f\"- Total de fechas diarias generadas: {len(self.indice_diario)}\")\n",
    "        return self.indice_diario\n",
    "\n",
    "    def combinar_datos(self):\n",
    "        if not self.datos_procesados:\n",
    "            self.logger.error(\"No hay datos procesados para combinar\")\n",
    "            return None\n",
    "        if self.indice_diario is None:\n",
    "            self.logger.error(\"No se ha generado el índice diario\")\n",
    "            return None\n",
    "        self.logger.info(\"\\nCombinando datos con índice diario...\")\n",
    "        df_combinado = self.indice_diario.copy()\n",
    "        for variable, df in self.datos_procesados.items():\n",
    "            if df is None:\n",
    "                self.logger.warning(f\"Omitiendo {variable} por errores de procesamiento\")\n",
    "                continue\n",
    "            nombre_col = df.columns[1]\n",
    "            self.logger.info(f\"- Combinando: {nombre_col}\")\n",
    "            df['fecha'] = pd.to_datetime(df['fecha']).dt.normalize()\n",
    "            filas_antes = len(df_combinado)\n",
    "            df_combinado = pd.merge(df_combinado, df, on='fecha', how='left')\n",
    "            filas_despues = len(df_combinado)\n",
    "            if filas_antes != filas_despues:\n",
    "                self.logger.error(f\"- ERROR: Cambio en número de filas después del merge de {nombre_col}: {filas_antes} -> {filas_despues}\")\n",
    "            df_combinado[nombre_col] = df_combinado[nombre_col].ffill()\n",
    "        self.df_combinado = df_combinado\n",
    "        self.logger.info(f\"- DataFrame combinado: {len(df_combinado)} filas, {len(df_combinado.columns)} columnas\")\n",
    "        return self.df_combinado\n",
    "\n",
    "    def analizar_cobertura_final(self):\n",
    "        if self.df_combinado is None or not self.estadisticas:\n",
    "            self.logger.error(\"No hay datos combinados o estadísticas para analizar\")\n",
    "            return\n",
    "        self.logger.info(\"\\n\" + \"=\" * 50)\n",
    "        self.logger.info(\"RESUMEN DE COBERTURA FINAL\")\n",
    "        self.logger.info(\"=\" * 50)\n",
    "        total_indicadores = len(self.estadisticas)\n",
    "        total_dias = len(self.indice_diario)\n",
    "        self.logger.info(f\"Total indicadores procesados: {total_indicadores}\")\n",
    "        self.logger.info(f\"Rango de fechas: {self.fecha_min_global.strftime('%Y-%m-%d')} a {self.fecha_max_global.strftime('%Y-%m-%d')}\")\n",
    "        self.logger.info(f\"Total días en la serie: {total_dias}\")\n",
    "        for variable, stats in self.estadisticas.items():\n",
    "            cobertura = (stats['valores_validos'] / total_dias) * 100\n",
    "            self.logger.info(f\"- {variable} ({stats['nuevo_nombre']}): Cobertura aproximada {cobertura:.2f}%\")\n",
    "\n",
    "    def generar_estadisticas_valores(self):\n",
    "        if self.df_combinado is None:\n",
    "            self.logger.error(\"No hay datos combinados para analizar\")\n",
    "            return\n",
    "        self.logger.info(\"\\n\" + \"=\" * 50)\n",
    "        self.logger.info(\"ESTADÍSTICAS DE VALORES\")\n",
    "        self.logger.info(\"=\" * 50)\n",
    "        for col in self.df_combinado.columns:\n",
    "            if col == 'fecha':\n",
    "                continue\n",
    "            serie = self.df_combinado[col].dropna()\n",
    "            if len(serie) == 0:\n",
    "                self.logger.warning(f\"La columna {col} no tiene valores\")\n",
    "                continue\n",
    "            stats = {\n",
    "                'min': serie.min(),\n",
    "                'max': serie.max(),\n",
    "                'mean': serie.mean(),\n",
    "                'median': serie.median(),\n",
    "                'std': serie.std()\n",
    "            }\n",
    "            self.logger.info(f\"\\nEstadísticas para {col}:\")\n",
    "            self.logger.info(f\"- Min: {stats['min']:.4f}\")\n",
    "            self.logger.info(f\"- Max: {stats['max']:.4f}\")\n",
    "            self.logger.info(f\"- Media: {stats['mean']:.4f}\")\n",
    "            self.logger.info(f\"- Mediana: {stats['median']:.4f}\")\n",
    "            self.logger.info(f\"- Desv. Estándar: {stats['std']:.4f}\")\n",
    "            if col in self.estadisticas:\n",
    "                self.estadisticas[col] = {**self.estadisticas.get(col, {}), **stats}\n",
    "\n",
    "    def guardar_resultados(self, output_file='datos_economicos_procesados.xlsx'):\n",
    "        if self.df_combinado is None:\n",
    "            self.logger.error(\"No hay datos para guardar\")\n",
    "            return False\n",
    "        try:\n",
    "            self.logger.info(\"\\n\" + \"=\" * 50)\n",
    "            self.logger.info(\"GUARDANDO RESULTADOS\")\n",
    "            self.logger.info(\"=\" * 50)\n",
    "            self.logger.info(f\"Guardando resultados en: {output_file}\")\n",
    "            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "                self.df_combinado.to_excel(writer, sheet_name='Datos Diarios', index=False)\n",
    "                df_stats = pd.DataFrame()\n",
    "                for var, stats in self.estadisticas.items():\n",
    "                    serie = pd.Series(stats, name=var)\n",
    "                    df_temp = pd.DataFrame(serie).transpose()\n",
    "                    df_stats = pd.concat([df_stats, df_temp])\n",
    "                df_stats.to_excel(writer, sheet_name='Estadisticas')\n",
    "                metadata = {\n",
    "                    'Proceso': ['MyinvestingreportNormal'],\n",
    "                    'Fecha de proceso': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                    'Total indicadores': [len(self.estadisticas)],\n",
    "                    'Periodo': [f\"{self.fecha_min_global.strftime('%Y-%m-%d')} a {self.fecha_max_global.strftime('%Y-%m-%d')}\"],\n",
    "                    'Total días': [len(self.indice_diario)]\n",
    "                }\n",
    "                pd.DataFrame(metadata).to_excel(writer, sheet_name='Metadatos')\n",
    "            self.logger.info(f\"Archivo guardado exitosamente: {output_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al guardar resultados: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def ejecutar_proceso_completo(self, output_file='datos_economicos_normales_procesados.xlsx'):\n",
    "        inicio = time.time()\n",
    "        self.logger.info(\"Iniciando proceso completo MyinvestingreportNormal...\")\n",
    "        self.leer_configuracion()\n",
    "        if self.config_data is None or len(self.config_data) == 0:\n",
    "            return False\n",
    "        for _, config_row in self.config_data.iterrows():\n",
    "            variable, df_procesado = self.procesar_archivo(config_row)\n",
    "            self.datos_procesados[variable] = df_procesado\n",
    "        archivos_correctos = sum(1 for df in self.datos_procesados.values() if df is not None)\n",
    "        if archivos_correctos == 0:\n",
    "            self.logger.error(\"No se pudo procesar correctamente ningún archivo\")\n",
    "            return False\n",
    "        self.generar_indice_diario()\n",
    "        if self.indice_diario is None:\n",
    "            return False\n",
    "        self.combinar_datos()\n",
    "        if self.df_combinado is None:\n",
    "            return False\n",
    "        self.analizar_cobertura_final()\n",
    "        self.generar_estadisticas_valores()\n",
    "        resultado = self.guardar_resultados(output_file)\n",
    "        fin = time.time()\n",
    "        tiempo_ejecucion = fin - inicio\n",
    "        self.logger.info(\"\\n\" + \"=\" * 50)\n",
    "        self.logger.info(\"RESUMEN DE EJECUCIÓN\")\n",
    "        self.logger.info(\"=\" * 50)\n",
    "        self.logger.info(f\"Proceso: MyinvestingreportNormal\")\n",
    "        self.logger.info(f\"Tiempo de ejecución: {tiempo_ejecucion:.2f} segundos\")\n",
    "        self.logger.info(f\"Archivos procesados: {len(self.datos_procesados)}\")\n",
    "        self.logger.info(f\"Archivos con error: {sum(1 for df in self.datos_procesados.values() if df is None)}\")\n",
    "        self.logger.info(f\"Archivos procesados correctamente: {archivos_correctos}\")\n",
    "        self.logger.info(f\"Periodo de datos: {self.fecha_min_global.strftime('%Y-%m-%d')} a {self.fecha_max_global.strftime('%Y-%m-%d')}\")\n",
    "        self.logger.info(f\"Datos combinados: {len(self.df_combinado)} filas, {len(self.df_combinado.columns)} columnas\")\n",
    "        self.logger.info(f\"Archivo de salida: {output_file}\")\n",
    "        self.logger.info(f\"Estado: {'COMPLETADO' if resultado else 'ERROR'}\")\n",
    "        self.logger.info(\"=\" * 50)\n",
    "        return resultado\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Función principal para ejecutar el proceso\n",
    "# ---------------------------------------------------\n",
    "def ejecutar_myinvestingreportnormal(config_file='Data Engineering.xlsx',\n",
    "                                    output_file='datos_economicos_normales_procesados.xlsx',\n",
    "                                    data_root='data/Macro/raw',\n",
    "                                    log_file='myinvestingreportnormal.log'):\n",
    "    procesador = MyinvestingreportNormal(config_file, data_root, log_file)\n",
    "    return procesador.ejecutar_proceso_completo(output_file)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Ejecución principal\n",
    "# ---------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    resultado = ejecutar_myinvestingreportnormal()\n",
    "    print(f\"Proceso {'completado exitosamente' if resultado else 'finalizado con errores'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:55:59,723 [INFO] ================================================================================\n",
      "2025-03-28 15:55:59,727 [INFO] INICIANDO PROCESO: MyinvestingreportNormal\n",
      "2025-03-28 15:55:59,727 [INFO] Archivo de configuración: Data Engineering.xlsx\n",
      "2025-03-28 15:55:59,729 [INFO] Directorio raíz de datos: data/Macro/raw\n",
      "2025-03-28 15:55:59,731 [INFO] Fecha y hora: 2025-03-28 15:55:59\n",
      "2025-03-28 15:55:59,732 [INFO] ================================================================================\n",
      "2025-03-28 15:55:59,734 [INFO] Iniciando proceso completo MyinvestingreportNormal...\n",
      "2025-03-28 15:55:59,735 [INFO] Leyendo archivo de configuración...\n",
      "2025-03-28 15:55:59,806 [INFO] Se encontraron 28 configuraciones para procesar\n",
      "2025-03-28 15:55:59,809 [INFO] \n",
      "Procesando: Australia_10Y_Bond (bond)\n",
      "2025-03-28 15:55:59,810 [INFO] - Archivo: Australia_10Y_Bond\n",
      "2025-03-28 15:55:59,810 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:55:59,812 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Australia_10Y_Bond.csv\n",
      "2025-03-28 15:55:59,826 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:55:59,842 [INFO] Formato de fecha detectado para Australia_10Y_Bond: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:01,277 [INFO] Ejemplos de fechas convertidas para Australia_10Y_Bond: [Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00'), Timestamp('2025-03-20 00:00:00')]\n",
      "2025-03-28 15:56:01,283 [INFO] Formato numérico detectado para Australia_10Y_Bond: americano\n",
      "2025-03-28 15:56:01,290 [INFO] Para Australia_10Y_Bond (columna Date), la fecha mínima es 2014-01-01 00:00:00 y la fecha máxima es 2025-03-26 00:00:00\n",
      "2025-03-28 15:56:01,292 [INFO] - Australia_10Y_Bond: 3810 filas procesadas, periodo: 2014-01-01 a 2025-03-26\n",
      "2025-03-28 15:56:01,294 [INFO] \n",
      "Procesando: Italy_10Y_Bond (bond)\n",
      "2025-03-28 15:56:01,295 [INFO] - Archivo: Italy_10Y_Bond\n",
      "2025-03-28 15:56:01,296 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:01,297 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Italy_10Y_Bond.csv\n",
      "2025-03-28 15:56:01,308 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:01,329 [INFO] Formato de fecha detectado para Italy_10Y_Bond: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:02,425 [INFO] Ejemplos de fechas convertidas para Italy_10Y_Bond: [Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00'), Timestamp('2025-03-20 00:00:00')]\n",
      "2025-03-28 15:56:02,429 [INFO] Formato numérico detectado para Italy_10Y_Bond: americano\n",
      "2025-03-28 15:56:02,438 [INFO] Para Italy_10Y_Bond (columna Date), la fecha mínima es 2014-01-02 00:00:00 y la fecha máxima es 2025-03-26 00:00:00\n",
      "2025-03-28 15:56:02,440 [INFO] - Italy_10Y_Bond: 3238 filas procesadas, periodo: 2014-01-02 a 2025-03-26\n",
      "2025-03-28 15:56:02,443 [INFO] \n",
      "Procesando: Japan_10Y_Bond (bond)\n",
      "2025-03-28 15:56:02,445 [INFO] - Archivo: Japan_10Y_Bond\n",
      "2025-03-28 15:56:02,448 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:02,451 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Japan_10Y_Bond.csv\n",
      "2025-03-28 15:56:02,470 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:02,485 [INFO] Formato de fecha detectado para Japan_10Y_Bond: dayfirst=False (confianza: 0.15)\n",
      "2025-03-28 15:56:03,725 [INFO] Ejemplos de fechas convertidas para Japan_10Y_Bond: [Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00'), Timestamp('2025-03-19 00:00:00')]\n",
      "2025-03-28 15:56:03,727 [INFO] Formato numérico detectado para Japan_10Y_Bond: americano\n",
      "2025-03-28 15:56:03,733 [INFO] Para Japan_10Y_Bond (columna Date), la fecha mínima es 2014-01-06 00:00:00 y la fecha máxima es 2025-03-26 00:00:00\n",
      "2025-03-28 15:56:03,733 [INFO] - Japan_10Y_Bond: 3203 filas procesadas, periodo: 2014-01-06 a 2025-03-26\n",
      "2025-03-28 15:56:03,734 [INFO] \n",
      "Procesando: UK_10Y_Bond (bond)\n",
      "2025-03-28 15:56:03,736 [INFO] - Archivo: UK_10Y_Bond\n",
      "2025-03-28 15:56:03,736 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:03,737 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\UK_10Y_Bond.csv\n",
      "2025-03-28 15:56:03,748 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:03,756 [INFO] Formato de fecha detectado para UK_10Y_Bond: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:04,886 [INFO] Ejemplos de fechas convertidas para UK_10Y_Bond: [Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00'), Timestamp('2025-03-20 00:00:00')]\n",
      "2025-03-28 15:56:04,890 [INFO] Formato numérico detectado para UK_10Y_Bond: americano\n",
      "2025-03-28 15:56:04,894 [INFO] Para UK_10Y_Bond (columna Date), la fecha mínima es 2014-01-01 00:00:00 y la fecha máxima es 2025-03-26 00:00:00\n",
      "2025-03-28 15:56:04,896 [INFO] - UK_10Y_Bond: 3424 filas procesadas, periodo: 2014-01-01 a 2025-03-26\n",
      "2025-03-28 15:56:04,899 [INFO] \n",
      "Procesando: Germany_10Y_Bond (bond)\n",
      "2025-03-28 15:56:04,899 [INFO] - Archivo: Germany_10Y_Bond\n",
      "2025-03-28 15:56:04,901 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:04,902 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Germany_10Y_Bond.csv\n",
      "2025-03-28 15:56:04,918 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:04,927 [INFO] Formato de fecha detectado para Germany_10Y_Bond: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:06,019 [INFO] Ejemplos de fechas convertidas para Germany_10Y_Bond: [Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00'), Timestamp('2025-03-20 00:00:00')]\n",
      "2025-03-28 15:56:06,022 [INFO] Formato numérico detectado para Germany_10Y_Bond: americano\n",
      "2025-03-28 15:56:06,026 [INFO] Para Germany_10Y_Bond (columna Date), la fecha mínima es 2014-01-02 00:00:00 y la fecha máxima es 2025-03-26 00:00:00\n",
      "2025-03-28 15:56:06,028 [INFO] - Germany_10Y_Bond: 3075 filas procesadas, periodo: 2014-01-02 a 2025-03-26\n",
      "2025-03-28 15:56:06,028 [INFO] \n",
      "Procesando: Canada_10Y_Bond (bond)\n",
      "2025-03-28 15:56:06,028 [INFO] - Archivo: Canada_10Y_Bond\n",
      "2025-03-28 15:56:06,029 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:06,029 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Canada_10Y_Bond.csv\n",
      "2025-03-28 15:56:06,035 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:06,046 [INFO] Formato de fecha detectado para Canada_10Y_Bond: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:07,109 [INFO] Ejemplos de fechas convertidas para Canada_10Y_Bond: [Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00'), Timestamp('2025-03-20 00:00:00')]\n",
      "2025-03-28 15:56:07,113 [INFO] Formato numérico detectado para Canada_10Y_Bond: americano\n",
      "2025-03-28 15:56:07,119 [INFO] Para Canada_10Y_Bond (columna Date), la fecha mínima es 2014-01-01 00:00:00 y la fecha máxima es 2025-03-26 00:00:00\n",
      "2025-03-28 15:56:07,120 [INFO] - Canada_10Y_Bond: 2965 filas procesadas, periodo: 2014-01-01 a 2025-03-26\n",
      "2025-03-28 15:56:07,122 [INFO] \n",
      "Procesando: China_10Y_Bond (bond)\n",
      "2025-03-28 15:56:07,123 [INFO] - Archivo: China_10Y_Bond\n",
      "2025-03-28 15:56:07,123 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:07,123 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\China_10Y_Bond.csv\n",
      "2025-03-28 15:56:07,138 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:07,150 [INFO] Formato de fecha detectado para China_10Y_Bond: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:08,377 [INFO] Ejemplos de fechas convertidas para China_10Y_Bond: [Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00'), Timestamp('2025-03-20 00:00:00')]\n",
      "2025-03-28 15:56:08,380 [INFO] Formato numérico detectado para China_10Y_Bond: americano\n",
      "2025-03-28 15:56:08,384 [INFO] Para China_10Y_Bond (columna Date), la fecha mínima es 2014-01-02 00:00:00 y la fecha máxima es 2025-03-26 00:00:00\n",
      "2025-03-28 15:56:08,386 [INFO] - China_10Y_Bond: 2914 filas procesadas, periodo: 2014-01-02 a 2025-03-26\n",
      "2025-03-28 15:56:08,388 [INFO] \n",
      "Procesando: CrudeOil_WTI (commodities)\n",
      "2025-03-28 15:56:08,389 [INFO] - Archivo: CrudeOil_WTI\n",
      "2025-03-28 15:56:08,391 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:08,392 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\CrudeOil_WTI.csv\n",
      "2025-03-28 15:56:08,400 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:08,409 [INFO] Formato de fecha detectado para CrudeOil_WTI: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:09,476 [INFO] Ejemplos de fechas convertidas para CrudeOil_WTI: [Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00'), Timestamp('2025-03-20 00:00:00')]\n",
      "2025-03-28 15:56:09,480 [INFO] Formato numérico detectado para CrudeOil_WTI: americano\n",
      "2025-03-28 15:56:09,486 [INFO] Para CrudeOil_WTI (columna Date), la fecha mínima es 2014-01-01 00:00:00 y la fecha máxima es 2025-03-26 00:00:00\n",
      "2025-03-28 15:56:09,488 [INFO] - CrudeOil_WTI: 2953 filas procesadas, periodo: 2014-01-01 a 2025-03-26\n",
      "2025-03-28 15:56:09,488 [INFO] \n",
      "Procesando: Gold_Spot (commodities)\n",
      "2025-03-28 15:56:09,488 [INFO] - Archivo: Gold_Spot\n",
      "2025-03-28 15:56:09,489 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:09,489 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\Gold_Spot.csv\n",
      "2025-03-28 15:56:09,503 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:09,517 [INFO] Formato de fecha detectado para Gold_Spot: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:10,625 [INFO] Ejemplos de fechas convertidas para Gold_Spot: [Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00'), Timestamp('2025-03-20 00:00:00')]\n",
      "2025-03-28 15:56:10,626 [INFO] Formato numérico detectado para Gold_Spot: americano\n",
      "2025-03-28 15:56:10,634 [INFO] Para Gold_Spot (columna Date), la fecha mínima es 2014-01-02 00:00:00 y la fecha máxima es 2025-03-26 00:00:00\n",
      "2025-03-28 15:56:10,634 [INFO] - Gold_Spot: 2874 filas procesadas, periodo: 2014-01-02 a 2025-03-26\n",
      "2025-03-28 15:56:10,636 [INFO] \n",
      "Procesando: Silver_Spot (commodities)\n",
      "2025-03-28 15:56:10,637 [INFO] - Archivo: Silver_Spot\n",
      "2025-03-28 15:56:10,638 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:10,638 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\Silver_Spot.csv\n",
      "2025-03-28 15:56:10,647 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:10,655 [INFO] Formato de fecha detectado para Silver_Spot: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:11,735 [INFO] Ejemplos de fechas convertidas para Silver_Spot: [Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00'), Timestamp('2025-03-20 00:00:00')]\n",
      "2025-03-28 15:56:11,738 [INFO] Formato numérico detectado para Silver_Spot: americano\n",
      "2025-03-28 15:56:11,745 [INFO] Para Silver_Spot (columna Date), la fecha mínima es 2014-01-02 00:00:00 y la fecha máxima es 2025-03-26 00:00:00\n",
      "2025-03-28 15:56:11,747 [INFO] - Silver_Spot: 2911 filas procesadas, periodo: 2014-01-02 a 2025-03-26\n",
      "2025-03-28 15:56:11,750 [INFO] \n",
      "Procesando: Copper_Futures (commodities)\n",
      "2025-03-28 15:56:11,752 [INFO] - Archivo: Copper_Futures\n",
      "2025-03-28 15:56:11,753 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:11,754 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\Copper_Futures.csv\n",
      "2025-03-28 15:56:11,770 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:11,785 [INFO] Formato de fecha detectado para Copper_Futures: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:12,847 [INFO] Ejemplos de fechas convertidas para Copper_Futures: [Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00'), Timestamp('2025-03-20 00:00:00')]\n",
      "2025-03-28 15:56:12,852 [INFO] Formato numérico detectado para Copper_Futures: americano\n",
      "2025-03-28 15:56:12,858 [INFO] Para Copper_Futures (columna Date), la fecha mínima es 2014-01-02 00:00:00 y la fecha máxima es 2025-03-26 00:00:00\n",
      "2025-03-28 15:56:12,859 [INFO] - Copper_Futures: 2908 filas procesadas, periodo: 2014-01-02 a 2025-03-26\n",
      "2025-03-28 15:56:12,862 [INFO] \n",
      "Procesando: Platinum_Spot (commodities)\n",
      "2025-03-28 15:56:12,862 [INFO] - Archivo: Platinum_Spot\n",
      "2025-03-28 15:56:12,863 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:12,864 [INFO] - Ruta encontrada: data/Macro/raw\\commodities\\Platinum_Spot.csv\n",
      "2025-03-28 15:56:12,877 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:12,888 [INFO] Formato de fecha detectado para Platinum_Spot: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:14,016 [INFO] Ejemplos de fechas convertidas para Platinum_Spot: [Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00'), Timestamp('2025-03-20 00:00:00')]\n",
      "2025-03-28 15:56:14,016 [INFO] Formato numérico detectado para Platinum_Spot: americano\n",
      "2025-03-28 15:56:14,026 [INFO] Para Platinum_Spot (columna Date), la fecha mínima es 2014-01-01 00:00:00 y la fecha máxima es 2025-03-26 00:00:00\n",
      "2025-03-28 15:56:14,028 [INFO] - Platinum_Spot: 3463 filas procesadas, periodo: 2014-01-01 a 2025-03-26\n",
      "2025-03-28 15:56:14,029 [INFO] \n",
      "Procesando: EUR_USD_Spot (exchange_rate)\n",
      "2025-03-28 15:56:14,029 [INFO] - Archivo: EUR_USD_Spot\n",
      "2025-03-28 15:56:14,031 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:14,031 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\EUR_USD_Spot.csv\n",
      "2025-03-28 15:56:14,038 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:14,046 [INFO] Formato de fecha detectado para EUR_USD_Spot: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:15,084 [INFO] Ejemplos de fechas convertidas para EUR_USD_Spot: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:15,088 [INFO] Formato numérico detectado para EUR_USD_Spot: americano\n",
      "2025-03-28 15:56:15,095 [INFO] Para EUR_USD_Spot (columna Date), la fecha mínima es 2014-01-01 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:15,097 [INFO] - EUR_USD_Spot: 2932 filas procesadas, periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-28 15:56:15,100 [INFO] \n",
      "Procesando: GBP_USD_Spot (exchange_rate)\n",
      "2025-03-28 15:56:15,101 [INFO] - Archivo: GBP_USD_Spot\n",
      "2025-03-28 15:56:15,103 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:15,104 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\GBP_USD_Spot.csv\n",
      "2025-03-28 15:56:15,114 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:15,126 [INFO] Formato de fecha detectado para GBP_USD_Spot: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:16,107 [INFO] Ejemplos de fechas convertidas para GBP_USD_Spot: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:16,110 [INFO] Formato numérico detectado para GBP_USD_Spot: americano\n",
      "2025-03-28 15:56:16,120 [INFO] Para GBP_USD_Spot (columna Date), la fecha mínima es 2014-01-01 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:16,122 [INFO] - GBP_USD_Spot: 2932 filas procesadas, periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-28 15:56:16,123 [INFO] \n",
      "Procesando: JPY_USD_Spot (exchange_rate)\n",
      "2025-03-28 15:56:16,125 [INFO] - Archivo: JPY_USD_Spot\n",
      "2025-03-28 15:56:16,126 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:16,128 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\JPY_USD_Spot.csv\n",
      "2025-03-28 15:56:16,143 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:16,155 [INFO] Formato de fecha detectado para JPY_USD_Spot: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:17,327 [INFO] Ejemplos de fechas convertidas para JPY_USD_Spot: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:17,329 [INFO] Formato numérico detectado para JPY_USD_Spot: americano\n",
      "2025-03-28 15:56:17,337 [INFO] Para JPY_USD_Spot (columna Date), la fecha mínima es 2014-01-01 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:17,338 [INFO] - JPY_USD_Spot: 2932 filas procesadas, periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-28 15:56:17,341 [INFO] \n",
      "Procesando: CNY_USD_Spot (exchange_rate)\n",
      "2025-03-28 15:56:17,341 [INFO] - Archivo: CNY_USD_Spot\n",
      "2025-03-28 15:56:17,342 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:17,342 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\CNY_USD_Spot.csv\n",
      "2025-03-28 15:56:17,349 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:17,358 [INFO] Formato de fecha detectado para CNY_USD_Spot: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:18,473 [INFO] Ejemplos de fechas convertidas para CNY_USD_Spot: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:18,478 [INFO] Formato numérico detectado para CNY_USD_Spot: americano\n",
      "2025-03-28 15:56:18,484 [INFO] Para CNY_USD_Spot (columna Date), la fecha mínima es 2014-01-01 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:18,486 [INFO] - CNY_USD_Spot: 2933 filas procesadas, periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-28 15:56:18,486 [INFO] \n",
      "Procesando: AUD_USD_Spot (exchange_rate)\n",
      "2025-03-28 15:56:18,487 [INFO] - Archivo: AUD_USD_Spot\n",
      "2025-03-28 15:56:18,489 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:18,492 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\AUD_USD_Spot.csv\n",
      "2025-03-28 15:56:18,513 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:18,545 [INFO] Formato de fecha detectado para AUD_USD_Spot: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:19,529 [INFO] Ejemplos de fechas convertidas para AUD_USD_Spot: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:19,533 [INFO] Formato numérico detectado para AUD_USD_Spot: americano\n",
      "2025-03-28 15:56:19,537 [INFO] Para AUD_USD_Spot (columna Date), la fecha mínima es 2014-01-01 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:19,539 [INFO] - AUD_USD_Spot: 2932 filas procesadas, periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-28 15:56:19,541 [INFO] \n",
      "Procesando: CAD_USD_Spot (exchange_rate)\n",
      "2025-03-28 15:56:19,541 [INFO] - Archivo: CAD_USD_Spot\n",
      "2025-03-28 15:56:19,541 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:19,542 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\CAD_USD_Spot.csv\n",
      "2025-03-28 15:56:19,550 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:19,560 [INFO] Formato de fecha detectado para CAD_USD_Spot: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:20,471 [INFO] Ejemplos de fechas convertidas para CAD_USD_Spot: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:20,472 [INFO] Formato numérico detectado para CAD_USD_Spot: americano\n",
      "2025-03-28 15:56:20,479 [INFO] Para CAD_USD_Spot (columna Date), la fecha mínima es 2014-01-01 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:20,479 [INFO] - CAD_USD_Spot: 2932 filas procesadas, periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-28 15:56:20,483 [INFO] \n",
      "Procesando: MXN_USD_Spot (exchange_rate)\n",
      "2025-03-28 15:56:20,483 [INFO] - Archivo: MXN_USD_Spot\n",
      "2025-03-28 15:56:20,484 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:20,484 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\MXN_USD_Spot.csv\n",
      "2025-03-28 15:56:20,493 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:20,505 [INFO] Formato de fecha detectado para MXN_USD_Spot: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:21,677 [INFO] Ejemplos de fechas convertidas para MXN_USD_Spot: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:21,680 [INFO] Formato numérico detectado para MXN_USD_Spot: americano\n",
      "2025-03-28 15:56:21,689 [INFO] Para MXN_USD_Spot (columna Date), la fecha mínima es 2014-01-01 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:21,690 [INFO] - MXN_USD_Spot: 2932 filas procesadas, periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-28 15:56:21,692 [INFO] \n",
      "Procesando: EUR_GBP_Cross (exchange_rate)\n",
      "2025-03-28 15:56:21,692 [INFO] - Archivo: EUR_GBP_Cross\n",
      "2025-03-28 15:56:21,692 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:21,693 [INFO] - Ruta encontrada: data/Macro/raw\\exchange_rate\\EUR_GBP_Cross.csv\n",
      "2025-03-28 15:56:21,703 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:21,718 [INFO] Formato de fecha detectado para EUR_GBP_Cross: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:22,828 [INFO] Ejemplos de fechas convertidas para EUR_GBP_Cross: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:22,832 [INFO] Formato numérico detectado para EUR_GBP_Cross: americano\n",
      "2025-03-28 15:56:22,838 [INFO] Para EUR_GBP_Cross (columna Date), la fecha mínima es 2014-01-01 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:22,841 [INFO] - EUR_GBP_Cross: 2932 filas procesadas, periodo: 2014-01-01 a 2025-03-27\n",
      "2025-03-28 15:56:22,843 [INFO] \n",
      "Procesando: S&P500_Index (index_pricing)\n",
      "2025-03-28 15:56:22,844 [INFO] - Archivo: S&P500_Index\n",
      "2025-03-28 15:56:22,847 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-28 15:56:22,849 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\S&P500_Index.csv\n",
      "2025-03-28 15:56:22,862 [INFO] Columna de fecha detectada: Fecha\n",
      "2025-03-28 15:56:22,874 [INFO] Formato de fecha detectado para S&P500_Index: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:23,148 [INFO] Ejemplos de fechas convertidas para S&P500_Index: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:23,150 [INFO] Formato numérico detectado para S&P500_Index: americano\n",
      "2025-03-28 15:56:23,162 [INFO] Para S&P500_Index (columna Fecha), la fecha mínima es 2014-01-02 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:23,164 [INFO] - S&P500_Index: 2826 filas procesadas, periodo: 2014-01-02 a 2025-03-27\n",
      "2025-03-28 15:56:23,165 [INFO] \n",
      "Procesando: NASDAQ_Composite (index_pricing)\n",
      "2025-03-28 15:56:23,167 [INFO] - Archivo: NASDAQ_Composite\n",
      "2025-03-28 15:56:23,168 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-28 15:56:23,170 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\NASDAQ_Composite.csv\n",
      "2025-03-28 15:56:23,181 [INFO] Columna de fecha detectada: Fecha\n",
      "2025-03-28 15:56:23,192 [INFO] Formato de fecha detectado para NASDAQ_Composite: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:23,432 [INFO] Ejemplos de fechas convertidas para NASDAQ_Composite: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:23,434 [INFO] Formato numérico detectado para NASDAQ_Composite: americano\n",
      "2025-03-28 15:56:23,442 [INFO] Para NASDAQ_Composite (columna Fecha), la fecha mínima es 2014-01-02 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:23,445 [INFO] - NASDAQ_Composite: 2826 filas procesadas, periodo: 2014-01-02 a 2025-03-27\n",
      "2025-03-28 15:56:23,447 [INFO] \n",
      "Procesando: Russell_2000 (index_pricing)\n",
      "2025-03-28 15:56:23,448 [INFO] - Archivo: Russell_2000\n",
      "2025-03-28 15:56:23,450 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-28 15:56:23,451 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\Russell_2000.csv\n",
      "2025-03-28 15:56:23,466 [INFO] Columna de fecha detectada: Fecha\n",
      "2025-03-28 15:56:23,483 [INFO] Formato de fecha detectado para Russell_2000: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:23,810 [INFO] Ejemplos de fechas convertidas para Russell_2000: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:23,813 [INFO] Formato numérico detectado para Russell_2000: americano\n",
      "2025-03-28 15:56:23,824 [INFO] Para Russell_2000 (columna Fecha), la fecha mínima es 2014-01-02 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:23,827 [INFO] - Russell_2000: 2840 filas procesadas, periodo: 2014-01-02 a 2025-03-27\n",
      "2025-03-28 15:56:23,830 [INFO] \n",
      "Procesando: FTSE_100 (index_pricing)\n",
      "2025-03-28 15:56:23,831 [INFO] - Archivo: FTSE_100\n",
      "2025-03-28 15:56:23,832 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-28 15:56:23,836 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\FTSE_100.csv\n",
      "2025-03-28 15:56:23,855 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:23,863 [INFO] Formato de fecha detectado para FTSE_100: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:24,847 [INFO] Ejemplos de fechas convertidas para FTSE_100: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:24,849 [INFO] Formato numérico detectado para FTSE_100: americano\n",
      "2025-03-28 15:56:24,857 [INFO] Para FTSE_100 (columna Date), la fecha mínima es 2014-01-02 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:24,859 [INFO] - FTSE_100: 2840 filas procesadas, periodo: 2014-01-02 a 2025-03-27\n",
      "2025-03-28 15:56:24,860 [INFO] \n",
      "Procesando: Nikkei_225 (index_pricing)\n",
      "2025-03-28 15:56:24,862 [INFO] - Archivo: Nikkei_225\n",
      "2025-03-28 15:56:24,862 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-28 15:56:24,864 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\Nikkei_225.csv\n",
      "2025-03-28 15:56:24,875 [INFO] Columna de fecha detectada: Fecha\n",
      "2025-03-28 15:56:24,888 [INFO] Formato de fecha detectado para Nikkei_225: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:25,081 [INFO] Ejemplos de fechas convertidas para Nikkei_225: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:25,083 [INFO] Formato numérico detectado para Nikkei_225: americano\n",
      "2025-03-28 15:56:25,099 [INFO] Para Nikkei_225 (columna Fecha), la fecha mínima es 2014-01-06 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:25,100 [INFO] - Nikkei_225: 2741 filas procesadas, periodo: 2014-01-06 a 2025-03-27\n",
      "2025-03-28 15:56:25,105 [INFO] \n",
      "Procesando: DAX_30 (index_pricing)\n",
      "2025-03-28 15:56:25,105 [INFO] - Archivo: DAX_30\n",
      "2025-03-28 15:56:25,108 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-28 15:56:25,112 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\DAX_30.csv\n",
      "2025-03-28 15:56:25,131 [INFO] Columna de fecha detectada: Fecha\n",
      "2025-03-28 15:56:25,141 [INFO] Formato de fecha detectado para DAX_30: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:25,411 [INFO] Ejemplos de fechas convertidas para DAX_30: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:25,414 [INFO] Formato numérico detectado para DAX_30: americano\n",
      "2025-03-28 15:56:25,431 [INFO] Para DAX_30 (columna Fecha), la fecha mínima es 2014-01-02 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:25,433 [INFO] - DAX_30: 2851 filas procesadas, periodo: 2014-01-02 a 2025-03-27\n",
      "2025-03-28 15:56:25,436 [INFO] \n",
      "Procesando: Shanghai_Composite (index_pricing)\n",
      "2025-03-28 15:56:25,438 [INFO] - Archivo: Shanghai_Composite\n",
      "2025-03-28 15:56:25,439 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 15:56:25,441 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\Shanghai_Composite.csv\n",
      "2025-03-28 15:56:25,466 [INFO] Columna de fecha detectada: Date\n",
      "2025-03-28 15:56:25,480 [INFO] Formato de fecha detectado para Shanghai_Composite: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:26,436 [INFO] Ejemplos de fechas convertidas para Shanghai_Composite: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:26,438 [INFO] Formato numérico detectado para Shanghai_Composite: americano\n",
      "2025-03-28 15:56:26,449 [INFO] Para Shanghai_Composite (columna Date), la fecha mínima es 2014-01-02 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:26,450 [INFO] - Shanghai_Composite: 2731 filas procesadas, periodo: 2014-01-02 a 2025-03-27\n",
      "2025-03-28 15:56:26,452 [INFO] \n",
      "Procesando: VIX_VolatilityIndex (index_pricing)\n",
      "2025-03-28 15:56:26,453 [INFO] - Archivo: VIX_VolatilityIndex\n",
      "2025-03-28 15:56:26,454 [INFO] - Columna TARGET: ULTIMO\n",
      "2025-03-28 15:56:26,455 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\VIX_VolatilityIndex.csv\n",
      "2025-03-28 15:56:26,463 [INFO] Columna de fecha detectada: Fecha\n",
      "2025-03-28 15:56:26,471 [INFO] Formato de fecha detectado para VIX_VolatilityIndex: dayfirst=False (confianza: 0.00)\n",
      "2025-03-28 15:56:27,037 [INFO] Ejemplos de fechas convertidas para VIX_VolatilityIndex: [Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-21 00:00:00')]\n",
      "2025-03-28 15:56:27,038 [INFO] Formato numérico detectado para VIX_VolatilityIndex: americano\n",
      "2025-03-28 15:56:27,052 [INFO] Para VIX_VolatilityIndex (columna Fecha), la fecha mínima es 2014-01-02 00:00:00 y la fecha máxima es 2025-03-27 00:00:00\n",
      "2025-03-28 15:56:27,053 [INFO] - VIX_VolatilityIndex: 2860 filas procesadas, periodo: 2014-01-02 a 2025-03-27\n",
      "2025-03-28 15:56:27,053 [INFO] \n",
      "Generando índice temporal diario...\n",
      "2025-03-28 15:56:27,055 [INFO] Archivo con fecha mínima global: Australia_10Y_Bond (2014-01-01)\n",
      "2025-03-28 15:56:27,055 [INFO] Archivo con fecha máxima global: EUR_USD_Spot (2025-03-27)\n",
      "2025-03-28 15:56:27,058 [INFO] - Total de fechas diarias generadas: 4104\n",
      "2025-03-28 15:56:27,060 [INFO] \n",
      "Combinando datos con índice diario (usando join para reducir consumo de memoria)...\n",
      "2025-03-28 15:56:27,062 [INFO] - Combinando: PRICE_Australia_10Y_Bond_bond\n",
      "2025-03-28 15:56:27,066 [INFO] - Combinando: PRICE_Italy_10Y_Bond_bond\n",
      "2025-03-28 15:56:27,070 [INFO] - Combinando: PRICE_Japan_10Y_Bond_bond\n",
      "2025-03-28 15:56:27,075 [INFO] - Combinando: PRICE_UK_10Y_Bond_bond\n",
      "2025-03-28 15:56:27,081 [INFO] - Combinando: PRICE_Germany_10Y_Bond_bond\n",
      "2025-03-28 15:56:27,085 [INFO] - Combinando: PRICE_Canada_10Y_Bond_bond\n",
      "2025-03-28 15:56:27,089 [INFO] - Combinando: PRICE_China_10Y_Bond_bond\n",
      "2025-03-28 15:56:27,094 [INFO] - Combinando: PRICE_CrudeOil_WTI_commodities\n",
      "2025-03-28 15:56:27,097 [INFO] - Combinando: PRICE_Gold_Spot_commodities\n",
      "2025-03-28 15:56:27,102 [INFO] - Combinando: PRICE_Silver_Spot_commodities\n",
      "2025-03-28 15:56:27,110 [INFO] - Combinando: PRICE_Copper_Futures_commodities\n",
      "2025-03-28 15:56:27,116 [INFO] - Combinando: PRICE_Platinum_Spot_commodities\n",
      "2025-03-28 15:56:27,119 [INFO] - Combinando: PRICE_EUR_USD_Spot_exchange_rate\n",
      "2025-03-28 15:56:27,123 [INFO] - Combinando: PRICE_GBP_USD_Spot_exchange_rate\n",
      "2025-03-28 15:56:27,128 [INFO] - Combinando: PRICE_JPY_USD_Spot_exchange_rate\n",
      "2025-03-28 15:56:27,131 [INFO] - Combinando: PRICE_CNY_USD_Spot_exchange_rate\n",
      "2025-03-28 15:56:27,136 [INFO] - Combinando: PRICE_AUD_USD_Spot_exchange_rate\n",
      "2025-03-28 15:56:27,139 [INFO] - Combinando: PRICE_CAD_USD_Spot_exchange_rate\n",
      "2025-03-28 15:56:27,143 [INFO] - Combinando: PRICE_MXN_USD_Spot_exchange_rate\n",
      "2025-03-28 15:56:27,148 [INFO] - Combinando: PRICE_EUR_GBP_Cross_exchange_rate\n",
      "2025-03-28 15:56:27,151 [INFO] - Combinando: ULTIMO_S&P500_Index_index_pricing\n",
      "2025-03-28 15:56:27,156 [INFO] - Combinando: ULTIMO_NASDAQ_Composite_index_pricing\n",
      "2025-03-28 15:56:27,158 [INFO] - Combinando: ULTIMO_Russell_2000_index_pricing\n",
      "2025-03-28 15:56:27,162 [INFO] - Combinando: ULTIMO_FTSE_100_index_pricing\n",
      "2025-03-28 15:56:27,165 [INFO] - Combinando: ULTIMO_Nikkei_225_index_pricing\n",
      "2025-03-28 15:56:27,169 [INFO] - Combinando: ULTIMO_DAX_30_index_pricing\n",
      "2025-03-28 15:56:27,173 [INFO] - Combinando: PRICE_Shanghai_Composite_index_pricing\n",
      "2025-03-28 15:56:27,177 [INFO] - Combinando: ULTIMO_VIX_VolatilityIndex_index_pricing\n",
      "2025-03-28 15:56:27,184 [INFO] - DataFrame combinado: 4104 filas, 29 columnas\n",
      "2025-03-28 15:56:27,185 [INFO] \n",
      "==================================================\n",
      "2025-03-28 15:56:27,185 [INFO] RESUMEN DE COBERTURA FINAL\n",
      "2025-03-28 15:56:27,187 [INFO] ==================================================\n",
      "2025-03-28 15:56:27,187 [INFO] Total indicadores procesados: 28\n",
      "2025-03-28 15:56:27,188 [INFO] Rango de fechas: 2014-01-01 a 2025-03-27\n",
      "2025-03-28 15:56:27,190 [INFO] Total días en la serie: 4104\n",
      "2025-03-28 15:56:27,190 [INFO] - Australia_10Y_Bond (PRICE_Australia_10Y_Bond_bond): Cobertura aproximada 92.84%\n",
      "2025-03-28 15:56:27,190 [INFO] - Italy_10Y_Bond (PRICE_Italy_10Y_Bond_bond): Cobertura aproximada 78.90%\n",
      "2025-03-28 15:56:27,192 [INFO] - Japan_10Y_Bond (PRICE_Japan_10Y_Bond_bond): Cobertura aproximada 78.05%\n",
      "2025-03-28 15:56:27,192 [INFO] - UK_10Y_Bond (PRICE_UK_10Y_Bond_bond): Cobertura aproximada 83.43%\n",
      "2025-03-28 15:56:27,192 [INFO] - Germany_10Y_Bond (PRICE_Germany_10Y_Bond_bond): Cobertura aproximada 74.93%\n",
      "2025-03-28 15:56:27,193 [INFO] - Canada_10Y_Bond (PRICE_Canada_10Y_Bond_bond): Cobertura aproximada 72.25%\n",
      "2025-03-28 15:56:27,193 [INFO] - China_10Y_Bond (PRICE_China_10Y_Bond_bond): Cobertura aproximada 71.00%\n",
      "2025-03-28 15:56:27,195 [INFO] - CrudeOil_WTI (PRICE_CrudeOil_WTI_commodities): Cobertura aproximada 71.95%\n",
      "2025-03-28 15:56:27,195 [INFO] - Gold_Spot (PRICE_Gold_Spot_commodities): Cobertura aproximada 70.03%\n",
      "2025-03-28 15:56:27,196 [INFO] - Silver_Spot (PRICE_Silver_Spot_commodities): Cobertura aproximada 70.93%\n",
      "2025-03-28 15:56:27,198 [INFO] - Copper_Futures (PRICE_Copper_Futures_commodities): Cobertura aproximada 70.86%\n",
      "2025-03-28 15:56:27,198 [INFO] - Platinum_Spot (PRICE_Platinum_Spot_commodities): Cobertura aproximada 84.38%\n",
      "2025-03-28 15:56:27,199 [INFO] - EUR_USD_Spot (PRICE_EUR_USD_Spot_exchange_rate): Cobertura aproximada 71.44%\n",
      "2025-03-28 15:56:27,199 [INFO] - GBP_USD_Spot (PRICE_GBP_USD_Spot_exchange_rate): Cobertura aproximada 71.44%\n",
      "2025-03-28 15:56:27,201 [INFO] - JPY_USD_Spot (PRICE_JPY_USD_Spot_exchange_rate): Cobertura aproximada 71.44%\n",
      "2025-03-28 15:56:27,201 [INFO] - CNY_USD_Spot (PRICE_CNY_USD_Spot_exchange_rate): Cobertura aproximada 71.47%\n",
      "2025-03-28 15:56:27,201 [INFO] - AUD_USD_Spot (PRICE_AUD_USD_Spot_exchange_rate): Cobertura aproximada 71.44%\n",
      "2025-03-28 15:56:27,204 [INFO] - CAD_USD_Spot (PRICE_CAD_USD_Spot_exchange_rate): Cobertura aproximada 71.44%\n",
      "2025-03-28 15:56:27,205 [INFO] - MXN_USD_Spot (PRICE_MXN_USD_Spot_exchange_rate): Cobertura aproximada 71.44%\n",
      "2025-03-28 15:56:27,205 [INFO] - EUR_GBP_Cross (PRICE_EUR_GBP_Cross_exchange_rate): Cobertura aproximada 71.44%\n",
      "2025-03-28 15:56:27,207 [INFO] - S&P500_Index (ULTIMO_S&P500_Index_index_pricing): Cobertura aproximada 68.86%\n",
      "2025-03-28 15:56:27,209 [INFO] - NASDAQ_Composite (ULTIMO_NASDAQ_Composite_index_pricing): Cobertura aproximada 68.86%\n",
      "2025-03-28 15:56:27,209 [INFO] - Russell_2000 (ULTIMO_Russell_2000_index_pricing): Cobertura aproximada 69.20%\n",
      "2025-03-28 15:56:27,210 [INFO] - FTSE_100 (ULTIMO_FTSE_100_index_pricing): Cobertura aproximada 69.20%\n",
      "2025-03-28 15:56:27,213 [INFO] - Nikkei_225 (ULTIMO_Nikkei_225_index_pricing): Cobertura aproximada 66.79%\n",
      "2025-03-28 15:56:27,215 [INFO] - DAX_30 (ULTIMO_DAX_30_index_pricing): Cobertura aproximada 69.47%\n",
      "2025-03-28 15:56:27,215 [INFO] - Shanghai_Composite (PRICE_Shanghai_Composite_index_pricing): Cobertura aproximada 66.54%\n",
      "2025-03-28 15:56:27,215 [INFO] - VIX_VolatilityIndex (ULTIMO_VIX_VolatilityIndex_index_pricing): Cobertura aproximada 69.69%\n",
      "2025-03-28 15:56:27,216 [INFO] \n",
      "==================================================\n",
      "2025-03-28 15:56:27,218 [INFO] ESTADÍSTICAS DE VALORES\n",
      "2025-03-28 15:56:27,220 [INFO] ==================================================\n",
      "2025-03-28 15:56:27,222 [INFO] \n",
      "Estadísticas para PRICE_Australia_10Y_Bond_bond:\n",
      "2025-03-28 15:56:27,224 [INFO] - Min: 0.6010\n",
      "2025-03-28 15:56:27,225 [INFO] - Max: 4.9680\n",
      "2025-03-28 15:56:27,227 [INFO] - Media: 2.7097\n",
      "2025-03-28 15:56:27,229 [INFO] - Mediana: 2.7025\n",
      "2025-03-28 15:56:27,229 [INFO] - Desv. Estándar: 1.0845\n",
      "2025-03-28 15:56:27,232 [INFO] \n",
      "Estadísticas para PRICE_Italy_10Y_Bond_bond:\n",
      "2025-03-28 15:56:27,232 [INFO] - Min: 0.4610\n",
      "2025-03-28 15:56:27,234 [INFO] - Max: 4.9880\n",
      "2025-03-28 15:56:27,235 [INFO] - Media: 2.3621\n",
      "2025-03-28 15:56:27,235 [INFO] - Mediana: 2.1180\n",
      "2025-03-28 15:56:27,236 [INFO] - Desv. Estándar: 1.1532\n",
      "2025-03-28 15:56:27,239 [INFO] \n",
      "Estadísticas para PRICE_Japan_10Y_Bond_bond:\n",
      "2025-03-28 15:56:27,239 [INFO] - Min: -0.2910\n",
      "2025-03-28 15:56:27,240 [INFO] - Max: 1.5610\n",
      "2025-03-28 15:56:27,242 [INFO] - Media: 0.2615\n",
      "2025-03-28 15:56:27,243 [INFO] - Mediana: 0.1040\n",
      "2025-03-28 15:56:27,243 [INFO] - Desv. Estándar: 0.3457\n",
      "2025-03-28 15:56:27,246 [INFO] \n",
      "Estadísticas para PRICE_UK_10Y_Bond_bond:\n",
      "2025-03-28 15:56:27,248 [INFO] - Min: 0.0750\n",
      "2025-03-28 15:56:27,248 [INFO] - Max: 4.8850\n",
      "2025-03-28 15:56:27,250 [INFO] - Media: 1.9328\n",
      "2025-03-28 15:56:27,250 [INFO] - Mediana: 1.4620\n",
      "2025-03-28 15:56:27,251 [INFO] - Desv. Estándar: 1.3117\n",
      "2025-03-28 15:56:27,254 [INFO] \n",
      "Estadísticas para PRICE_Germany_10Y_Bond_bond:\n",
      "2025-03-28 15:56:27,254 [INFO] - Min: -0.8540\n",
      "2025-03-28 15:56:27,255 [INFO] - Max: 2.9680\n",
      "2025-03-28 15:56:27,257 [INFO] - Media: 0.7411\n",
      "2025-03-28 15:56:27,257 [INFO] - Mediana: 0.4270\n",
      "2025-03-28 15:56:27,257 [INFO] - Desv. Estándar: 1.0257\n",
      "2025-03-28 15:56:27,260 [INFO] \n",
      "Estadísticas para PRICE_Canada_10Y_Bond_bond:\n",
      "2025-03-28 15:56:27,260 [INFO] - Min: 0.4350\n",
      "2025-03-28 15:56:27,261 [INFO] - Max: 4.2750\n",
      "2025-03-28 15:56:27,261 [INFO] - Media: 2.0485\n",
      "2025-03-28 15:56:27,263 [INFO] - Mediana: 1.8740\n",
      "2025-03-28 15:56:27,263 [INFO] - Desv. Estándar: 0.8708\n",
      "2025-03-28 15:56:27,266 [INFO] \n",
      "Estadísticas para PRICE_China_10Y_Bond_bond:\n",
      "2025-03-28 15:56:27,268 [INFO] - Min: 1.6070\n",
      "2025-03-28 15:56:27,268 [INFO] - Max: 4.7100\n",
      "2025-03-28 15:56:27,269 [INFO] - Media: 3.1233\n",
      "2025-03-28 15:56:27,269 [INFO] - Mediana: 3.0940\n",
      "2025-03-28 15:56:27,271 [INFO] - Desv. Estándar: 0.5733\n",
      "2025-03-28 15:56:27,272 [INFO] \n",
      "Estadísticas para PRICE_CrudeOil_WTI_commodities:\n",
      "2025-03-28 15:56:27,274 [INFO] - Min: 11.5700\n",
      "2025-03-28 15:56:27,275 [INFO] - Max: 119.7800\n",
      "2025-03-28 15:56:27,275 [INFO] - Media: 64.8420\n",
      "2025-03-28 15:56:27,275 [INFO] - Mediana: 63.3800\n",
      "2025-03-28 15:56:27,277 [INFO] - Desv. Estándar: 19.1693\n",
      "2025-03-28 15:56:27,278 [INFO] \n",
      "Estadísticas para PRICE_Gold_Spot_commodities:\n",
      "2025-03-28 15:56:27,280 [INFO] - Min: 1049.6000\n",
      "2025-03-28 15:56:27,282 [INFO] - Max: 3071.3000\n",
      "2025-03-28 15:56:27,282 [INFO] - Media: 1601.5690\n",
      "2025-03-28 15:56:27,283 [INFO] - Mediana: 1462.9000\n",
      "2025-03-28 15:56:27,285 [INFO] - Desv. Estándar: 427.1199\n",
      "2025-03-28 15:56:27,287 [INFO] \n",
      "Estadísticas para PRICE_Silver_Spot_commodities:\n",
      "2025-03-28 15:56:27,287 [INFO] - Min: 11.7720\n",
      "2025-03-28 15:56:27,289 [INFO] - Max: 35.0410\n",
      "2025-03-28 15:56:27,289 [INFO] - Media: 20.3172\n",
      "2025-03-28 15:56:27,290 [INFO] - Mediana: 18.6510\n",
      "2025-03-28 15:56:27,290 [INFO] - Desv. Estándar: 4.8965\n",
      "2025-03-28 15:56:27,292 [INFO] \n",
      "Estadísticas para PRICE_Copper_Futures_commodities:\n",
      "2025-03-28 15:56:27,293 [INFO] - Min: 1.9435\n",
      "2025-03-28 15:56:27,295 [INFO] - Max: 5.2430\n",
      "2025-03-28 15:56:27,297 [INFO] - Media: 3.2489\n",
      "2025-03-28 15:56:27,298 [INFO] - Mediana: 3.0675\n",
      "2025-03-28 15:56:27,298 [INFO] - Desv. Estándar: 0.7632\n",
      "2025-03-28 15:56:27,301 [INFO] \n",
      "Estadísticas para PRICE_Platinum_Spot_commodities:\n",
      "2025-03-28 15:56:27,302 [INFO] - Min: 595.2000\n",
      "2025-03-28 15:56:27,302 [INFO] - Max: 1516.2000\n",
      "2025-03-28 15:56:27,304 [INFO] - Media: 1001.9474\n",
      "2025-03-28 15:56:27,304 [INFO] - Mediana: 966.6500\n",
      "2025-03-28 15:56:27,305 [INFO] - Desv. Estándar: 157.0175\n",
      "2025-03-28 15:56:27,309 [INFO] \n",
      "Estadísticas para PRICE_EUR_USD_Spot_exchange_rate:\n",
      "2025-03-28 15:56:27,309 [INFO] - Min: 0.9592\n",
      "2025-03-28 15:56:27,310 [INFO] - Max: 1.3933\n",
      "2025-03-28 15:56:27,312 [INFO] - Media: 1.1360\n",
      "2025-03-28 15:56:27,316 [INFO] - Mediana: 1.1192\n",
      "2025-03-28 15:56:27,318 [INFO] - Desv. Estándar: 0.0800\n",
      "2025-03-28 15:56:27,321 [INFO] \n",
      "Estadísticas para PRICE_GBP_USD_Spot_exchange_rate:\n",
      "2025-03-28 15:56:27,323 [INFO] - Min: 1.0684\n",
      "2025-03-28 15:56:27,323 [INFO] - Max: 1.7163\n",
      "2025-03-28 15:56:27,324 [INFO] - Media: 1.3479\n",
      "2025-03-28 15:56:27,324 [INFO] - Mediana: 1.3062\n",
      "2025-03-28 15:56:27,326 [INFO] - Desv. Estándar: 0.1300\n",
      "2025-03-28 15:56:27,327 [INFO] \n",
      "Estadísticas para PRICE_JPY_USD_Spot_exchange_rate:\n",
      "2025-03-28 15:56:27,330 [INFO] - Min: 99.8700\n",
      "2025-03-28 15:56:27,332 [INFO] - Max: 161.6800\n",
      "2025-03-28 15:56:27,332 [INFO] - Media: 119.5522\n",
      "2025-03-28 15:56:27,333 [INFO] - Mediana: 112.5050\n",
      "2025-03-28 15:56:27,333 [INFO] - Desv. Estándar: 16.2139\n",
      "2025-03-28 15:56:27,336 [INFO] \n",
      "Estadísticas para PRICE_CNY_USD_Spot_exchange_rate:\n",
      "2025-03-28 15:56:27,337 [INFO] - Min: 6.0402\n",
      "2025-03-28 15:56:27,337 [INFO] - Max: 7.3430\n",
      "2025-03-28 15:56:27,339 [INFO] - Media: 6.7138\n",
      "2025-03-28 15:56:27,339 [INFO] - Mediana: 6.7204\n",
      "2025-03-28 15:56:27,340 [INFO] - Desv. Estándar: 0.3520\n",
      "2025-03-28 15:56:27,343 [INFO] \n",
      "Estadísticas para PRICE_AUD_USD_Spot_exchange_rate:\n",
      "2025-03-28 15:56:27,343 [INFO] - Min: 0.5741\n",
      "2025-03-28 15:56:27,345 [INFO] - Max: 0.9496\n",
      "2025-03-28 15:56:27,347 [INFO] - Media: 0.7311\n",
      "2025-03-28 15:56:27,348 [INFO] - Mediana: 0.7226\n",
      "2025-03-28 15:56:27,349 [INFO] - Desv. Estándar: 0.0706\n",
      "2025-03-28 15:56:27,353 [INFO] \n",
      "Estadísticas para PRICE_CAD_USD_Spot_exchange_rate:\n",
      "2025-03-28 15:56:27,353 [INFO] - Min: 1.0631\n",
      "2025-03-28 15:56:27,354 [INFO] - Max: 1.4576\n",
      "2025-03-28 15:56:27,356 [INFO] - Media: 1.2978\n",
      "2025-03-28 15:56:27,356 [INFO] - Mediana: 1.3135\n",
      "2025-03-28 15:56:27,359 [INFO] - Desv. Estándar: 0.0775\n",
      "2025-03-28 15:56:27,360 [INFO] \n",
      "Estadísticas para PRICE_MXN_USD_Spot_exchange_rate:\n",
      "2025-03-28 15:56:27,361 [INFO] - Min: 12.8375\n",
      "2025-03-28 15:56:27,363 [INFO] - Max: 25.3380\n",
      "2025-03-28 15:56:27,364 [INFO] - Media: 18.5027\n",
      "2025-03-28 15:56:27,364 [INFO] - Mediana: 18.9318\n",
      "2025-03-28 15:56:27,366 [INFO] - Desv. Estándar: 2.3166\n",
      "2025-03-28 15:56:27,368 [INFO] \n",
      "Estadísticas para PRICE_EUR_GBP_Cross_exchange_rate:\n",
      "2025-03-28 15:56:27,369 [INFO] - Min: 0.6937\n",
      "2025-03-28 15:56:27,371 [INFO] - Max: 0.9396\n",
      "2025-03-28 15:56:27,372 [INFO] - Media: 0.8457\n",
      "2025-03-28 15:56:27,374 [INFO] - Mediana: 0.8568\n",
      "2025-03-28 15:56:27,374 [INFO] - Desv. Estándar: 0.0493\n",
      "2025-03-28 15:56:27,375 [INFO] \n",
      "Estadísticas para ULTIMO_S&P500_Index_index_pricing:\n",
      "2025-03-28 15:56:27,379 [INFO] - Min: 1741.9000\n",
      "2025-03-28 15:56:27,379 [INFO] - Max: 6144.1500\n",
      "2025-03-28 15:56:27,380 [INFO] - Media: 3283.5838\n",
      "2025-03-28 15:56:27,380 [INFO] - Mediana: 2914.0000\n",
      "2025-03-28 15:56:27,382 [INFO] - Desv. Estándar: 1166.1993\n",
      "2025-03-28 15:56:27,385 [INFO] \n",
      "Estadísticas para ULTIMO_NASDAQ_Composite_index_pricing:\n",
      "2025-03-28 15:56:27,386 [INFO] - Min: 3996.9600\n",
      "2025-03-28 15:56:27,386 [INFO] - Max: 20173.8900\n",
      "2025-03-28 15:56:27,388 [INFO] - Media: 9561.0893\n",
      "2025-03-28 15:56:27,388 [INFO] - Mediana: 8028.2300\n",
      "2025-03-28 15:56:27,389 [INFO] - Desv. Estándar: 4414.3752\n",
      "2025-03-28 15:56:27,391 [INFO] \n",
      "Estadísticas para ULTIMO_Russell_2000_index_pricing:\n",
      "2025-03-28 15:56:27,392 [INFO] - Min: 953.7200\n",
      "2025-03-28 15:56:27,394 [INFO] - Max: 2442.7400\n",
      "2025-03-28 15:56:27,394 [INFO] - Media: 1622.3269\n",
      "2025-03-28 15:56:27,396 [INFO] - Mediana: 1565.7500\n",
      "2025-03-28 15:56:27,396 [INFO] - Desv. Estándar: 379.5475\n",
      "2025-03-28 15:56:27,399 [INFO] \n",
      "Estadísticas para ULTIMO_FTSE_100_index_pricing:\n",
      "2025-03-28 15:56:27,399 [INFO] - Min: 4993.8900\n",
      "2025-03-28 15:56:27,400 [INFO] - Max: 8871.3100\n",
      "2025-03-28 15:56:27,400 [INFO] - Media: 7130.4668\n",
      "2025-03-28 15:56:27,402 [INFO] - Mediana: 7198.7000\n",
      "2025-03-28 15:56:27,402 [INFO] - Desv. Estándar: 634.3461\n",
      "2025-03-28 15:56:27,405 [INFO] \n",
      "Estadísticas para ULTIMO_Nikkei_225_index_pricing:\n",
      "2025-03-28 15:56:27,406 [INFO] - Min: 13910.1600\n",
      "2025-03-28 15:56:27,408 [INFO] - Max: 42224.0200\n",
      "2025-03-28 15:56:27,408 [INFO] - Media: 24275.9486\n",
      "2025-03-28 15:56:27,408 [INFO] - Mediana: 22508.6900\n",
      "2025-03-28 15:56:27,409 [INFO] - Desv. Estándar: 6837.3404\n",
      "2025-03-28 15:56:27,412 [INFO] \n",
      "Estadísticas para ULTIMO_DAX_30_index_pricing:\n",
      "2025-03-28 15:56:27,412 [INFO] - Min: 8441.7100\n",
      "2025-03-28 15:56:27,414 [INFO] - Max: 23419.4800\n",
      "2025-03-28 15:56:27,416 [INFO] - Media: 13188.9842\n",
      "2025-03-28 15:56:27,416 [INFO] - Mediana: 12630.2300\n",
      "2025-03-28 15:56:27,417 [INFO] - Desv. Estándar: 2873.9918\n",
      "2025-03-28 15:56:27,419 [INFO] \n",
      "Estadísticas para PRICE_Shanghai_Composite_index_pricing:\n",
      "2025-03-28 15:56:27,420 [INFO] - Min: 1991.2500\n",
      "2025-03-28 15:56:27,422 [INFO] - Max: 5166.3500\n",
      "2025-03-28 15:56:27,423 [INFO] - Media: 3109.6248\n",
      "2025-03-28 15:56:27,423 [INFO] - Mediana: 3135.8900\n",
      "2025-03-28 15:56:27,425 [INFO] - Desv. Estándar: 427.9591\n",
      "2025-03-28 15:56:27,428 [INFO] \n",
      "Estadísticas para ULTIMO_VIX_VolatilityIndex_index_pricing:\n",
      "2025-03-28 15:56:27,428 [INFO] - Min: 9.1400\n",
      "2025-03-28 15:56:27,429 [INFO] - Max: 82.6900\n",
      "2025-03-28 15:56:27,429 [INFO] - Media: 17.8182\n",
      "2025-03-28 15:56:27,431 [INFO] - Mediana: 15.9600\n",
      "2025-03-28 15:56:27,431 [INFO] - Desv. Estándar: 6.9428\n",
      "2025-03-28 15:56:27,432 [INFO] \n",
      "==================================================\n",
      "2025-03-28 15:56:27,434 [INFO] GUARDANDO RESULTADOS\n",
      "2025-03-28 15:56:27,435 [INFO] ==================================================\n",
      "2025-03-28 15:56:27,435 [INFO] Guardando resultados en: datos_economicos_normales_procesados.xlsx\n",
      "2025-03-28 15:56:29,743 [INFO] Archivo guardado exitosamente: datos_economicos_normales_procesados.xlsx\n",
      "2025-03-28 15:56:29,744 [INFO] \n",
      "==================================================\n",
      "2025-03-28 15:56:29,746 [INFO] RESUMEN DE EJECUCIÓN\n",
      "2025-03-28 15:56:29,748 [INFO] ==================================================\n",
      "2025-03-28 15:56:29,749 [INFO] Proceso: MyinvestingreportNormal\n",
      "2025-03-28 15:56:29,753 [INFO] Tiempo de ejecución: 30.01 segundos\n",
      "2025-03-28 15:56:29,753 [INFO] Archivos procesados: 28\n",
      "2025-03-28 15:56:29,754 [INFO] Archivos con error: 0\n",
      "2025-03-28 15:56:29,756 [INFO] Archivos procesados correctamente: 28\n",
      "2025-03-28 15:56:29,758 [INFO] Periodo de datos: 2014-01-01 a 2025-03-27\n",
      "2025-03-28 15:56:29,758 [INFO] Datos combinados: 4104 filas, 29 columnas\n",
      "2025-03-28 15:56:29,759 [INFO] Archivo de salida: datos_economicos_normales_procesados.xlsx\n",
      "2025-03-28 15:56:29,761 [INFO] Estado: COMPLETADO\n",
      "2025-03-28 15:56:29,761 [INFO] ==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado exitosamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Configuración de logging\n",
    "# ---------------------------------------------------\n",
    "def configurar_logging(log_file='myinvestingreportnormal.log'):\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger('MyinvestingreportNormal')\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Función para convertir valores numéricos\n",
    "# ---------------------------------------------------\n",
    "def convertir_valor(valor, variable=None, formatos_conocidos=None):\n",
    "    \"\"\"\n",
    "    Convierte cualquier representación de valor numérico a float.\n",
    "    \"\"\"\n",
    "    if isinstance(valor, (int, float)):\n",
    "        return float(valor)\n",
    "    \n",
    "    if not isinstance(valor, str) or valor is None:\n",
    "        return None\n",
    "\n",
    "    valor_limpio = valor.strip()\n",
    "    if not valor_limpio:\n",
    "        return None\n",
    "\n",
    "    # Aplicar formato conocido si existe\n",
    "    if variable and formatos_conocidos and variable in formatos_conocidos:\n",
    "        formato = formatos_conocidos[variable]\n",
    "        if formato == 'europeo':\n",
    "            valor_limpio = valor_limpio.replace('.', '')\n",
    "            valor_limpio = valor_limpio.replace(',', '.')\n",
    "    \n",
    "    # Multiplicadores para sufijos (K, M, etc.)\n",
    "    multiplicadores = {'%': 1, 'K': 1e3, 'M': 1e6, 'B': 1e9, 'T': 1e12}\n",
    "    multiplicador = 1\n",
    "    for sufijo, mult in multiplicadores.items():\n",
    "        if valor_limpio.endswith(sufijo):\n",
    "            valor_limpio = valor_limpio.replace(sufijo, '')\n",
    "            multiplicador = mult\n",
    "            break\n",
    "\n",
    "    # Ajuste de separadores: si se detectan ambos, se decide según la posición\n",
    "    if ',' in valor_limpio and '.' in valor_limpio:\n",
    "        if valor_limpio.rfind(',') > valor_limpio.rfind('.'):\n",
    "            valor_limpio = valor_limpio.replace('.', '')\n",
    "            valor_limpio = valor_limpio.replace(',', '.')\n",
    "        else:\n",
    "            valor_limpio = valor_limpio.replace(',', '')\n",
    "    elif ',' in valor_limpio:\n",
    "        partes = valor_limpio.split(',')\n",
    "        if len(partes) == 2 and len(partes[1]) <= 2:\n",
    "            valor_limpio = valor_limpio.replace(',', '.')\n",
    "        else:\n",
    "            valor_limpio = valor_limpio.replace(',', '')\n",
    "    \n",
    "    try:\n",
    "        return float(valor_limpio) * multiplicador\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Detección dinámica del formato de fechas\n",
    "# ---------------------------------------------------\n",
    "def detectar_formato_fecha_inteligente(df, col_fecha, muestra_registros=10):\n",
    "    \"\"\"\n",
    "    Analiza una muestra de la columna de fecha para determinar si se debe forzar dayfirst=True.\n",
    "    Retorna un diccionario con {'dayfirst': bool, 'confianza': float}\n",
    "    \"\"\"\n",
    "    fecha_actual = pd.Timestamp(datetime.now().date())\n",
    "    muestras = df[col_fecha].dropna().astype(str).head(muestra_registros).tolist()\n",
    "    \n",
    "    resultados = {\n",
    "        'dayfirst': {'validas': 0, 'invalidas': 0, 'futuras': 0},\n",
    "        'no_dayfirst': {'validas': 0, 'invalidas': 0, 'futuras': 0}\n",
    "    }\n",
    "    \n",
    "    for fecha_str in muestras:\n",
    "        fecha_str = fecha_str.strip()\n",
    "        ambigua = False\n",
    "        # Identifica fechas con formato numérico separado por /, - o .\n",
    "        if re.match(r'^\\d{1,2}[\\/\\-\\.]\\d{1,2}[\\/\\-\\.]\\d{4}$', fecha_str):\n",
    "            separador = re.findall(r'[\\/\\-\\.]', fecha_str)[0]\n",
    "            partes = fecha_str.split(separador)\n",
    "            if len(partes) == 3:\n",
    "                try:\n",
    "                    p1, p2 = int(partes[0]), int(partes[1])\n",
    "                    # Si ambos números son menores o iguales a 12, es ambigua\n",
    "                    if p1 <= 12 and p2 <= 12:\n",
    "                        ambigua = True\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        for modo, dayfirst in [('dayfirst', True), ('no_dayfirst', False)]:\n",
    "            try:\n",
    "                fecha = pd.to_datetime(fecha_str, dayfirst=dayfirst)\n",
    "                if fecha > fecha_actual + pd.Timedelta(days=30):\n",
    "                    resultados[modo]['futuras'] += 1\n",
    "                else:\n",
    "                    resultados[modo]['validas'] += 1\n",
    "            except:\n",
    "                resultados[modo]['invalidas'] += 1\n",
    "\n",
    "    score_dayfirst = resultados['dayfirst']['validas'] - (resultados['dayfirst']['invalidas'] * 0.5) - (resultados['dayfirst']['futuras'] * 2)\n",
    "    score_no_dayfirst = resultados['no_dayfirst']['validas'] - (resultados['no_dayfirst']['invalidas'] * 0.5) - (resultados['no_dayfirst']['futuras'] * 2)\n",
    "    usar_dayfirst = score_dayfirst > score_no_dayfirst\n",
    "    confianza = abs(score_dayfirst - score_no_dayfirst) / (muestra_registros * 2)\n",
    "    return {'dayfirst': usar_dayfirst, 'confianza': confianza}\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Conversión adaptativa de fechas\n",
    "# ---------------------------------------------------\n",
    "def convertir_fecha_adaptativo(fecha_str, configuracion_archivo=None):\n",
    "    \"\"\"\n",
    "    Convierte una fecha a pd.Timestamp usando la configuración detectada.\n",
    "    Si la cadena contiene puntos (.) y coincide con el patrón DD.MM.YYYY, se fuerza el formato.\n",
    "    \"\"\"\n",
    "    # Si ya es Timestamp o datetime, retornarla\n",
    "    if isinstance(fecha_str, (pd.Timestamp, datetime)):\n",
    "        return pd.Timestamp(fecha_str)\n",
    "    if pd.isna(fecha_str):\n",
    "        return None\n",
    "    fecha_str = str(fecha_str).strip()\n",
    "    # Si se detecta un punto como separador y el patrón es DD.MM.YYYY, forzamos el formato\n",
    "    if re.match(r'^\\d{1,2}\\.\\d{1,2}\\.\\d{4}$', fecha_str):\n",
    "        try:\n",
    "            fecha = pd.to_datetime(fecha_str, format='%d.%m.%Y', dayfirst=True)\n",
    "            return fecha\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Si hay configuración detectada, usarla\n",
    "    if configuracion_archivo is not None:\n",
    "        try:\n",
    "            fecha = pd.to_datetime(fecha_str, dayfirst=configuracion_archivo['dayfirst'])\n",
    "            return fecha\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Intento estándar sin forzar dayfirst\n",
    "    try:\n",
    "        fecha = pd.to_datetime(fecha_str)\n",
    "        return fecha\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Clase para gestionar y cachear formatos de fechas\n",
    "# ---------------------------------------------------\n",
    "class FormatosFechas:\n",
    "    \"\"\"Gestiona y cachea la configuración de conversión de fechas por archivo.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.formatos_cache = {}  # {variable: configuracion}\n",
    "    \n",
    "    def detectar_formato(self, df, col_fecha, variable=None):\n",
    "        configuracion = detectar_formato_fecha_inteligente(df, col_fecha)\n",
    "        if variable:\n",
    "            self.formatos_cache[variable] = configuracion\n",
    "        return configuracion\n",
    "        \n",
    "    def obtener_formato(self, variable):\n",
    "        return self.formatos_cache.get(variable)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Clase principal para procesar los datos económicos\n",
    "# ---------------------------------------------------\n",
    "class MyinvestingreportNormal:\n",
    "    \"\"\"\n",
    "    Procesa datos económicos con detección dinámica de formatos de fechas y \n",
    "    validación para evitar interpretaciones erróneas (como fechas en abril cuando\n",
    "    los datos crudos solo llegan hasta marzo).\n",
    "    \"\"\"\n",
    "    def __init__(self, config_file, data_root='data/Macro/raw', log_file='myinvestingreportnormal.log'):\n",
    "        self.config_file = config_file\n",
    "        self.data_root = data_root\n",
    "        self.logger = configurar_logging(log_file)\n",
    "        self.config_data = None\n",
    "        self.fecha_min_global = None\n",
    "        self.fecha_max_global = None\n",
    "        self.archivo_fecha_min = None\n",
    "        self.archivo_fecha_max = None\n",
    "        self.indice_diario = None\n",
    "        self.datos_procesados = {}\n",
    "        self.df_combinado = None\n",
    "        self.estadisticas = {}\n",
    "\n",
    "        self.formatos_numericos = {}  # Se usará un diccionario para formatos numéricos simples (si se desea ampliar)\n",
    "        self.formatos_fechas = FormatosFechas()\n",
    "        self.formatos_conocidos = {}  # Configuraciones exitosas de CSV\n",
    "\n",
    "        self.inicializar_formatos_conocidos()\n",
    "\n",
    "        self.logger.info(\"=\" * 80)\n",
    "        self.logger.info(\"INICIANDO PROCESO: MyinvestingreportNormal\")\n",
    "        self.logger.info(f\"Archivo de configuración: {config_file}\")\n",
    "        self.logger.info(f\"Directorio raíz de datos: {data_root}\")\n",
    "        self.logger.info(f\"Fecha y hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        self.logger.info(\"=\" * 80)\n",
    "\n",
    "    def inicializar_formatos_conocidos(self):\n",
    "        # Para algunos índices se conoce el formato numérico; aquí se puede ampliar si es necesario.\n",
    "        indices_europeos = ['Russell_2000', 'NASDAQ_Composite', 'S&P500_Index', 'Nikkei_225', 'DAX_30', 'VIX_VolatilityIndex']\n",
    "        for indice in indices_europeos:\n",
    "            self.formatos_conocidos[indice] = 'europeo'\n",
    "\n",
    "    def leer_configuracion(self):\n",
    "        self.logger.info(\"Leyendo archivo de configuración...\")\n",
    "        try:\n",
    "            df_config = pd.read_excel(self.config_file)\n",
    "            self.config_data = df_config[\n",
    "                (df_config['Fuente'] == 'Investing Data') &\n",
    "                (df_config['Tipo de Preprocesamiento Según la Fuente'] == 'Normal')\n",
    "            ].copy()\n",
    "            num_configs = len(self.config_data)\n",
    "            self.logger.info(f\"Se encontraron {num_configs} configuraciones para procesar\")\n",
    "            if num_configs == 0:\n",
    "                self.logger.warning(\"No se encontraron configuraciones que cumplan los criterios\")\n",
    "                return None\n",
    "            return self.config_data\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al leer configuración: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def encontrar_ruta_archivo(self, variable, tipo_macro):\n",
    "        ruta_base = os.path.join(self.data_root, tipo_macro)\n",
    "        nombre_archivo = f\"{variable}.csv\"\n",
    "        ruta_completa = os.path.join(ruta_base, nombre_archivo)\n",
    "        if os.path.exists(ruta_completa):\n",
    "            return ruta_completa\n",
    "        nombre_archivo_alt = f\"{variable}.xlsx\"\n",
    "        ruta_completa_alt = os.path.join(ruta_base, nombre_archivo_alt)\n",
    "        if os.path.exists(ruta_completa_alt):\n",
    "            return ruta_completa_alt\n",
    "        for root, dirs, files in os.walk(self.data_root):\n",
    "            if nombre_archivo in files:\n",
    "                return os.path.join(root, nombre_archivo)\n",
    "            if nombre_archivo_alt in files:\n",
    "                return os.path.join(root, nombre_archivo_alt)\n",
    "        return None\n",
    "\n",
    "    def leer_csv_adaptativo(self, ruta_archivo, variable):\n",
    "        configuraciones = [\n",
    "            {'sep': ',', 'decimal': '.', 'encoding': 'utf-8'},\n",
    "            {'sep': ',', 'decimal': '.', 'encoding': 'latin1'},\n",
    "            {'sep': ';', 'decimal': ',', 'thousands': '.', 'encoding': 'utf-8'},\n",
    "            {'sep': ';', 'decimal': ',', 'thousands': '.', 'encoding': 'latin1'},\n",
    "            {'sep': ',', 'decimal': ',', 'thousands': '.', 'encoding': 'utf-8'},\n",
    "            {'sep': '\\t', 'encoding': 'utf-8'},\n",
    "            {'sep': ' ', 'encoding': 'utf-8'}\n",
    "        ]\n",
    "        if variable in self.formatos_conocidos:\n",
    "            config_conocida = self.formatos_conocidos[variable]\n",
    "            try:\n",
    "                df = pd.read_csv(ruta_archivo, **config_conocida)\n",
    "                if len(df) > 0:\n",
    "                    return df\n",
    "            except Exception:\n",
    "                pass\n",
    "        errores = []\n",
    "        for idx, config in enumerate(configuraciones):\n",
    "            try:\n",
    "                df = pd.read_csv(ruta_archivo, **config)\n",
    "                if len(df) > 0:\n",
    "                    self.formatos_conocidos[variable] = config\n",
    "                    return df\n",
    "            except Exception as e:\n",
    "                errores.append(f\"Config {idx}: {str(e)}\")\n",
    "        self.logger.error(f\"No se pudo leer {ruta_archivo} con ninguna configuración\")\n",
    "        for error in errores:\n",
    "            self.logger.debug(f\"- {error}\")\n",
    "        return None\n",
    "\n",
    "    def detectar_columnas(self, df):\n",
    "        candidatos_fecha = [col for col in df.columns if any(\n",
    "            palabra in col.lower() for palabra in ['date', 'fecha', 'time', 'día', 'day', 'periodo']\n",
    "        )]\n",
    "        candidatos_valor = [col for col in df.columns if any(\n",
    "            palabra in col.lower() for palabra in ['price', 'precio', 'close', 'cierre', 'último', 'ultimo', 'valor', 'value']\n",
    "        )]\n",
    "        columnas_datetime = [col for col in df.columns if pd.api.types.is_datetime64_any_dtype(df[col])]\n",
    "        columna_fecha = None\n",
    "        if columnas_datetime:\n",
    "            columna_fecha = columnas_datetime[0]\n",
    "        elif candidatos_fecha:\n",
    "            for col in candidatos_fecha:\n",
    "                try:\n",
    "                    pd.to_datetime(df[col].iloc[:5])\n",
    "                    columna_fecha = col\n",
    "                    break\n",
    "                except Exception:\n",
    "                    continue\n",
    "        if columna_fecha is None and len(df.columns) > 0:\n",
    "            try:\n",
    "                pd.to_datetime(df[df.columns[0]].iloc[:5])\n",
    "                columna_fecha = df.columns[0]\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        columna_valor = None\n",
    "        if candidatos_valor:\n",
    "            columna_valor = candidatos_valor[0]\n",
    "        elif len(df.columns) > 1:\n",
    "            columna_valor = df.columns[1]\n",
    "        return columna_fecha, columna_valor\n",
    "\n",
    "    def convertir_fecha(self, fecha_str, configuracion_archivo=None):\n",
    "        return convertir_fecha_adaptativo(fecha_str, configuracion_archivo)\n",
    "\n",
    "    def limpiar_valor_porcentaje(self, valor, variable=None):\n",
    "        return convertir_valor(valor, variable, self.formatos_conocidos)\n",
    "\n",
    "    def procesar_archivo(self, config_row):\n",
    "        variable = config_row['Variable']\n",
    "        tipo_macro = config_row['Tipo Macro']\n",
    "        target_col = config_row['TARGET']\n",
    "\n",
    "        ruta_archivo = self.encontrar_ruta_archivo(variable, tipo_macro)\n",
    "        self.logger.info(f\"\\nProcesando: {variable} ({tipo_macro})\")\n",
    "        self.logger.info(f\"- Archivo: {variable}\")\n",
    "        self.logger.info(f\"- Columna TARGET: {target_col}\")\n",
    "        if ruta_archivo is None:\n",
    "            self.logger.error(f\"- ERROR: Archivo no encontrado: {variable}\")\n",
    "            return variable, None\n",
    "        self.logger.info(f\"- Ruta encontrada: {ruta_archivo}\")\n",
    "\n",
    "        try:\n",
    "            _, extension = os.path.splitext(ruta_archivo)\n",
    "            extension = extension.lower()\n",
    "            if extension == '.csv':\n",
    "                df = self.leer_csv_adaptativo(ruta_archivo, variable)\n",
    "            elif extension in ['.xlsx', '.xls']:\n",
    "                df = pd.read_excel(ruta_archivo, engine='openpyxl')\n",
    "            else:\n",
    "                self.logger.error(f\"- ERROR: Formato de archivo no soportado: {extension}\")\n",
    "                return variable, None\n",
    "            if df is None or len(df) == 0:\n",
    "                self.logger.error(\"- ERROR: El archivo está vacío o no se pudo leer\")\n",
    "                return variable, None\n",
    "\n",
    "            col_fecha, col_valor = self.detectar_columnas(df)\n",
    "            if col_fecha is None or col_valor is None:\n",
    "                self.logger.error(\"- ERROR: No se pudieron detectar columnas necesarias (fecha o valor)\")\n",
    "                return variable, None\n",
    "\n",
    "            self.logger.info(f\"Columna de fecha detectada: {col_fecha}\")\n",
    "            # Detección dinámica del formato de fechas\n",
    "            config_fecha = self.formatos_fechas.detectar_formato(df, col_fecha, variable)\n",
    "            self.logger.info(f\"Formato de fecha detectado para {variable}: dayfirst={config_fecha['dayfirst']} (confianza: {config_fecha['confianza']:.2f})\")\n",
    "            \n",
    "            # Convertir fechas usando la configuración detectada\n",
    "            df['fecha'] = df[col_fecha].apply(lambda x: self.convertir_fecha(x, configuracion_archivo=config_fecha))\n",
    "            df = df.dropna(subset=['fecha'])\n",
    "            ejemplos = df['fecha'].head(5).tolist()\n",
    "            self.logger.info(f\"Ejemplos de fechas convertidas para {variable}: {ejemplos}\")\n",
    "            \n",
    "            # Validar fechas excesivamente futuras (más de 30 días a partir de hoy)\n",
    "            fecha_actual = pd.Timestamp(datetime.now().date())\n",
    "            fechas_futuras = df[df['fecha'] > fecha_actual + pd.Timedelta(days=30)]\n",
    "            if len(fechas_futuras) > 0:\n",
    "                self.logger.warning(f\"Se detectaron {len(fechas_futuras)} fechas futuras anómalas en {variable}\")\n",
    "                self.logger.warning(f\"Ejemplos de fechas futuras: {fechas_futuras['fecha'].head(3).tolist()}\")\n",
    "                df = df[df['fecha'] <= fecha_actual + pd.Timedelta(days=30)].copy()\n",
    "            \n",
    "            muestra_valores = df[col_valor].astype(str).head(20).tolist()\n",
    "            formato_detectado = \"americano\"  # Se usa como etiqueta básica\n",
    "            self.logger.info(f\"Formato numérico detectado para {variable}: {formato_detectado}\")\n",
    "\n",
    "            df['valor'] = df[col_valor].apply(lambda x: self.limpiar_valor_porcentaje(x, variable))\n",
    "            df = df.dropna(subset=['valor'])\n",
    "\n",
    "            total_filas = len(df)\n",
    "            if total_filas == 0:\n",
    "                self.logger.error(f\"- ERROR: No se encontraron valores válidos en {variable}\")\n",
    "                return variable, None\n",
    "\n",
    "            nuevo_nombre = f\"{target_col}_{variable}_{tipo_macro}\"\n",
    "            df.rename(columns={'valor': nuevo_nombre}, inplace=True)\n",
    "            df_procesado = df[['fecha', nuevo_nombre]].copy()\n",
    "            df_procesado = df_procesado.sort_values('fecha')\n",
    "\n",
    "            fecha_min = df_procesado['fecha'].min()\n",
    "            fecha_max = df_procesado['fecha'].max()\n",
    "            self.logger.info(f\"Para {variable} (columna {col_fecha}), la fecha mínima es {fecha_min} y la fecha máxima es {fecha_max}\")\n",
    "            \n",
    "            if self.fecha_min_global is None or fecha_min < self.fecha_min_global:\n",
    "                self.fecha_min_global = fecha_min\n",
    "                self.archivo_fecha_min = variable\n",
    "            if self.fecha_max_global is None or fecha_max > self.fecha_max_global:\n",
    "                self.fecha_max_global = fecha_max\n",
    "                self.archivo_fecha_max = variable\n",
    "\n",
    "            self.estadisticas[variable] = {\n",
    "                'tipo_macro': tipo_macro,\n",
    "                'columna_target': target_col,\n",
    "                'total_filas': total_filas,\n",
    "                'valores_validos': df_procesado[nuevo_nombre].count(),\n",
    "                'fecha_min': fecha_min,\n",
    "                'fecha_max': fecha_max,\n",
    "                'nuevo_nombre': nuevo_nombre,\n",
    "                'formato_fecha': f\"dayfirst={config_fecha['dayfirst']}\",\n",
    "                'confianza_formato': config_fecha['confianza']\n",
    "            }\n",
    "            self.logger.info(f\"- {variable}: {total_filas} filas procesadas, periodo: {fecha_min.strftime('%Y-%m-%d')} a {fecha_max.strftime('%Y-%m-%d')}\")\n",
    "            return variable, df_procesado\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"- ERROR al procesar {ruta_archivo}: {str(e)}\")\n",
    "            return variable, None\n",
    "\n",
    "    def generar_indice_diario(self):\n",
    "        if self.fecha_min_global is None or self.fecha_max_global is None:\n",
    "            self.logger.error(\"No se pudieron determinar fechas mínima y máxima globales\")\n",
    "            return None\n",
    "        self.logger.info(\"\\nGenerando índice temporal diario...\")\n",
    "        self.logger.info(f\"Archivo con fecha mínima global: {self.archivo_fecha_min} ({self.fecha_min_global.strftime('%Y-%m-%d')})\")\n",
    "        self.logger.info(f\"Archivo con fecha máxima global: {self.archivo_fecha_max} ({self.fecha_max_global.strftime('%Y-%m-%d')})\")\n",
    "        todas_fechas = pd.date_range(start=self.fecha_min_global, end=self.fecha_max_global, freq='D')\n",
    "        self.indice_diario = pd.DataFrame({'fecha': todas_fechas})\n",
    "        self.logger.info(f\"- Total de fechas diarias generadas: {len(self.indice_diario)}\")\n",
    "        return self.indice_diario\n",
    "\n",
    "    def combinar_datos(self):\n",
    "        if not self.datos_procesados:\n",
    "            self.logger.error(\"No hay datos procesados para combinar\")\n",
    "            return None\n",
    "        if self.indice_diario is None:\n",
    "            self.logger.error(\"No se ha generado el índice diario\")\n",
    "            return None\n",
    "        self.logger.info(\"\\nCombinando datos con índice diario (usando join para reducir consumo de memoria)...\")\n",
    "        df_combinado = self.indice_diario.copy().set_index('fecha')\n",
    "        for variable, df in self.datos_procesados.items():\n",
    "            if df is None:\n",
    "                self.logger.warning(f\"Omitiendo {variable} por errores de procesamiento\")\n",
    "                continue\n",
    "            nombre_col = df.columns[1]\n",
    "            self.logger.info(f\"- Combinando: {nombre_col}\")\n",
    "            df_temp = df.set_index('fecha')[[nombre_col]]\n",
    "            df_temp = df_temp[~df_temp.index.duplicated(keep='first')]\n",
    "            df_temp = df_temp.reindex(df_combinado.index)\n",
    "            df_temp = df_temp.ffill()\n",
    "            df_combinado = df_combinado.join(df_temp)\n",
    "        self.df_combinado = df_combinado.reset_index()\n",
    "        self.logger.info(f\"- DataFrame combinado: {len(self.df_combinado)} filas, {len(self.df_combinado.columns)} columnas\")\n",
    "        return self.df_combinado\n",
    "\n",
    "    def analizar_cobertura_final(self):\n",
    "        if self.df_combinado is None or not self.estadisticas:\n",
    "            self.logger.error(\"No hay datos combinados o estadísticas para analizar\")\n",
    "            return\n",
    "        self.logger.info(\"\\n\" + \"=\" * 50)\n",
    "        self.logger.info(\"RESUMEN DE COBERTURA FINAL\")\n",
    "        self.logger.info(\"=\" * 50)\n",
    "        total_indicadores = len(self.estadisticas)\n",
    "        total_dias = len(self.indice_diario)\n",
    "        self.logger.info(f\"Total indicadores procesados: {total_indicadores}\")\n",
    "        self.logger.info(f\"Rango de fechas: {self.fecha_min_global.strftime('%Y-%m-%d')} a {self.fecha_max_global.strftime('%Y-%m-%d')}\")\n",
    "        self.logger.info(f\"Total días en la serie: {total_dias}\")\n",
    "        for variable, stats in self.estadisticas.items():\n",
    "            cobertura = (stats['valores_validos'] / total_dias) * 100\n",
    "            self.logger.info(f\"- {variable} ({stats['nuevo_nombre']}): Cobertura aproximada {cobertura:.2f}%\")\n",
    "\n",
    "    def generar_estadisticas_valores(self):\n",
    "        if self.df_combinado is None:\n",
    "            self.logger.error(\"No hay datos combinados para analizar\")\n",
    "            return\n",
    "        self.logger.info(\"\\n\" + \"=\" * 50)\n",
    "        self.logger.info(\"ESTADÍSTICAS DE VALORES\")\n",
    "        self.logger.info(\"=\" * 50)\n",
    "        for col in self.df_combinado.columns:\n",
    "            if col == 'fecha':\n",
    "                continue\n",
    "            serie = self.df_combinado[col].dropna()\n",
    "            if len(serie) == 0:\n",
    "                self.logger.warning(f\"La columna {col} no tiene valores\")\n",
    "                continue\n",
    "            stats = {\n",
    "                'min': serie.min(),\n",
    "                'max': serie.max(),\n",
    "                'mean': serie.mean(),\n",
    "                'median': serie.median(),\n",
    "                'std': serie.std()\n",
    "            }\n",
    "            self.logger.info(f\"\\nEstadísticas para {col}:\")\n",
    "            self.logger.info(f\"- Min: {stats['min']:.4f}\")\n",
    "            self.logger.info(f\"- Max: {stats['max']:.4f}\")\n",
    "            self.logger.info(f\"- Media: {stats['mean']:.4f}\")\n",
    "            self.logger.info(f\"- Mediana: {stats['median']:.4f}\")\n",
    "            self.logger.info(f\"- Desv. Estándar: {stats['std']:.4f}\")\n",
    "            if col in self.estadisticas:\n",
    "                self.estadisticas[col] = {**self.estadisticas.get(col, {}), **stats}\n",
    "\n",
    "    def guardar_resultados(self, output_file='datos_economicos_normales_procesados.xlsx'):\n",
    "        if self.df_combinado is None:\n",
    "            self.logger.error(\"No hay datos para guardar\")\n",
    "            return False\n",
    "        try:\n",
    "            self.logger.info(\"\\n\" + \"=\" * 50)\n",
    "            self.logger.info(\"GUARDANDO RESULTADOS\")\n",
    "            self.logger.info(\"=\" * 50)\n",
    "            self.logger.info(f\"Guardando resultados en: {output_file}\")\n",
    "            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "                self.df_combinado.to_excel(writer, sheet_name='Datos Diarios', index=False)\n",
    "                df_stats = pd.DataFrame()\n",
    "                for var, stats in self.estadisticas.items():\n",
    "                    serie = pd.Series(stats, name=var)\n",
    "                    df_temp = pd.DataFrame(serie).transpose()\n",
    "                    df_stats = pd.concat([df_stats, df_temp])\n",
    "                df_stats.to_excel(writer, sheet_name='Estadisticas')\n",
    "                metadata = {\n",
    "                    'Proceso': ['MyinvestingreportNormal'],\n",
    "                    'Fecha de proceso': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                    'Total indicadores': [len(self.estadisticas)],\n",
    "                    'Periodo': [f\"{self.fecha_min_global.strftime('%Y-%m-%d')} a {self.fecha_max_global.strftime('%Y-%m-%d')}\"],\n",
    "                    'Total días': [len(self.indice_diario)]\n",
    "                }\n",
    "                pd.DataFrame(metadata).to_excel(writer, sheet_name='Metadatos')\n",
    "            self.logger.info(f\"Archivo guardado exitosamente: {output_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al guardar resultados: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def ejecutar_proceso_completo(self, output_file='datos_economicos_normales_procesados.xlsx'):\n",
    "        inicio = time.time()\n",
    "        self.logger.info(\"Iniciando proceso completo MyinvestingreportNormal...\")\n",
    "        self.leer_configuracion()\n",
    "        if self.config_data is None or len(self.config_data) == 0:\n",
    "            return False\n",
    "        for _, config_row in self.config_data.iterrows():\n",
    "            variable, df_procesado = self.procesar_archivo(config_row)\n",
    "            self.datos_procesados[variable] = df_procesado\n",
    "        archivos_correctos = sum(1 for df in self.datos_procesados.values() if df is not None)\n",
    "        if archivos_correctos == 0:\n",
    "            self.logger.error(\"No se pudo procesar correctamente ningún archivo\")\n",
    "            return False\n",
    "        self.generar_indice_diario()\n",
    "        if self.indice_diario is None:\n",
    "            return False\n",
    "        self.combinar_datos()\n",
    "        if self.df_combinado is None:\n",
    "            return False\n",
    "        self.analizar_cobertura_final()\n",
    "        self.generar_estadisticas_valores()\n",
    "        resultado = self.guardar_resultados(output_file)\n",
    "        fin = time.time()\n",
    "        tiempo_ejecucion = fin - inicio\n",
    "        self.logger.info(\"\\n\" + \"=\" * 50)\n",
    "        self.logger.info(\"RESUMEN DE EJECUCIÓN\")\n",
    "        self.logger.info(\"=\" * 50)\n",
    "        self.logger.info(f\"Proceso: MyinvestingreportNormal\")\n",
    "        self.logger.info(f\"Tiempo de ejecución: {tiempo_ejecucion:.2f} segundos\")\n",
    "        self.logger.info(f\"Archivos procesados: {len(self.datos_procesados)}\")\n",
    "        self.logger.info(f\"Archivos con error: {sum(1 for df in self.datos_procesados.values() if df is None)}\")\n",
    "        self.logger.info(f\"Archivos procesados correctamente: {archivos_correctos}\")\n",
    "        self.logger.info(f\"Periodo de datos: {self.fecha_min_global.strftime('%Y-%m-%d')} a {self.fecha_max_global.strftime('%Y-%m-%d')}\")\n",
    "        self.logger.info(f\"Datos combinados: {len(self.df_combinado)} filas, {len(self.df_combinado.columns)} columnas\")\n",
    "        self.logger.info(f\"Archivo de salida: {output_file}\")\n",
    "        self.logger.info(f\"Estado: {'COMPLETADO' if resultado else 'ERROR'}\")\n",
    "        self.logger.info(\"=\" * 50)\n",
    "        return resultado\n",
    "\n",
    "def ejecutar_myinvestingreportnormal(config_file='Data Engineering.xlsx',\n",
    "                                     output_file='datos_economicos_normales_procesados.xlsx',\n",
    "                                     data_root='data/Macro/raw',\n",
    "                                     log_file='myinvestingreportnormal.log'):\n",
    "    procesador = MyinvestingreportNormal(config_file, data_root, log_file)\n",
    "    return procesador.ejecutar_proceso_completo(output_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resultado = ejecutar_myinvestingreportnormal()\n",
    "    print(f\"Proceso {'completado exitosamente' if resultado else 'finalizado con errores'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 18:07:48,590 [INFO] ================================================================================\n",
      "2025-03-28 18:07:48,591 [INFO] INICIANDO PROCESO: EconomicDataProcessor\n",
      "2025-03-28 18:07:48,593 [INFO] Archivo de configuración: Data Engineering.xlsx\n",
      "2025-03-28 18:07:48,594 [INFO] Directorio raíz de datos: data/Macro/raw\n",
      "2025-03-28 18:07:48,595 [INFO] Fecha y hora: 2025-03-28 18:07:48\n",
      "2025-03-28 18:07:48,597 [INFO] ================================================================================\n",
      "2025-03-28 18:07:48,599 [INFO] Leyendo archivo de configuración...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 18:07:48,642 [INFO] Se encontraron 21 configuraciones para procesar\n",
      "2025-03-28 18:07:48,643 [INFO] \n",
      "Procesando: US_ISM_Manufacturing (business_confidence)\n",
      "2025-03-28 18:07:48,645 [INFO] - Archivo: US_ISM_Manufacturing.xlsx\n",
      "2025-03-28 18:07:48,646 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:48,647 [INFO] - Ruta encontrada: data/Macro/raw\\business_confidence\\US_ISM_Manufacturing.xlsx\n",
      "2025-03-28 18:07:48,666 [INFO] - Filas encontradas: 138\n",
      "2025-03-28 18:07:48,674 [INFO] Preferencia de dayfirst para data/Macro/raw\\business_confidence\\US_ISM_Manufacturing.xlsx: True\n",
      "2025-03-28 18:07:48,729 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:48,731 [INFO] - Valores no nulos en TARGET: 137\n",
      "2025-03-28 18:07:48,733 [INFO] - Periodo: 2013-11-01 a 2025-03-03\n",
      "2025-03-28 18:07:48,733 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 18:07:48,737 [INFO] \n",
      "Procesando: US_ISM_Services (business_confidence)\n",
      "2025-03-28 18:07:48,738 [INFO] - Archivo: US_ISM_Services.xlsx\n",
      "2025-03-28 18:07:48,738 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:48,740 [INFO] - Ruta encontrada: data/Macro/raw\\business_confidence\\US_ISM_Services.xlsx\n",
      "2025-03-28 18:07:48,760 [INFO] - Filas encontradas: 137\n",
      "2025-03-28 18:07:48,767 [INFO] Preferencia de dayfirst para data/Macro/raw\\business_confidence\\US_ISM_Services.xlsx: True\n",
      "2025-03-28 18:07:48,818 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:48,821 [INFO] - Valores no nulos en TARGET: 136\n",
      "2025-03-28 18:07:48,822 [INFO] - Periodo: 2013-12-04 a 2025-03-05\n",
      "2025-03-28 18:07:48,823 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 18:07:48,825 [INFO] \n",
      "Procesando: US_Philly_Fed_Index (business_confidence)\n",
      "2025-03-28 18:07:48,825 [INFO] - Archivo: US_Philly_Fed_Index.xlsx\n",
      "2025-03-28 18:07:48,825 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:48,827 [INFO] - Ruta encontrada: data/Macro/raw\\business_confidence\\US_Philly_Fed_Index.xlsx\n",
      "2025-03-28 18:07:48,844 [INFO] - Filas encontradas: 136\n",
      "2025-03-28 18:07:48,851 [INFO] Preferencia de dayfirst para data/Macro/raw\\business_confidence\\US_Philly_Fed_Index.xlsx: True\n",
      "2025-03-28 18:07:48,913 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:48,916 [INFO] - Valores no nulos en TARGET: 136\n",
      "2025-03-28 18:07:48,917 [INFO] - Periodo: 2013-12-19 a 2025-03-20\n",
      "2025-03-28 18:07:48,919 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 18:07:48,921 [INFO] \n",
      "Procesando: France_Business_Climate (business_confidence)\n",
      "2025-03-28 18:07:48,921 [INFO] - Archivo: France_Business_Climate.xlsx\n",
      "2025-03-28 18:07:48,923 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:48,924 [INFO] - Ruta encontrada: data/Macro/raw\\business_confidence\\France_Business_Climate.xlsx\n",
      "2025-03-28 18:07:48,942 [INFO] - Filas encontradas: 137\n",
      "2025-03-28 18:07:48,948 [INFO] Preferencia de dayfirst para data/Macro/raw\\business_confidence\\France_Business_Climate.xlsx: True\n",
      "2025-03-28 18:07:49,013 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:49,018 [INFO] - Valores no nulos en TARGET: 137\n",
      "2025-03-28 18:07:49,018 [INFO] - Periodo: 2013-12-20 a 2025-03-21\n",
      "2025-03-28 18:07:49,019 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 18:07:49,024 [INFO] \n",
      "Procesando: EuroZone_Business_Climate (business_confidence)\n",
      "2025-03-28 18:07:49,025 [INFO] - Archivo: EuroZone_Business_Climate.xlsx\n",
      "2025-03-28 18:07:49,027 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:49,029 [INFO] - Ruta encontrada: data/Macro/raw\\business_confidence\\EuroZone_Business_Climate.xlsx\n",
      "2025-03-28 18:07:49,050 [INFO] - Filas encontradas: 138\n",
      "2025-03-28 18:07:49,058 [INFO] Preferencia de dayfirst para data/Macro/raw\\business_confidence\\EuroZone_Business_Climate.xlsx: True\n",
      "2025-03-28 18:07:49,137 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:49,141 [INFO] - Valores no nulos en TARGET: 137\n",
      "2025-03-28 18:07:49,141 [INFO] - Periodo: 2013-10-30 a 2025-02-27\n",
      "2025-03-28 18:07:49,143 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 18:07:49,146 [INFO] \n",
      "Procesando: U.S. All Car Sales (car_registrations)\n",
      "2025-03-28 18:07:49,147 [INFO] - Archivo: U.S. All Car Sales.xlsx\n",
      "2025-03-28 18:07:49,149 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:49,149 [INFO] - Ruta encontrada: data/Macro/raw\\car_registrations\\U.S. All Car Sales.xlsx\n",
      "2025-03-28 18:07:49,169 [INFO] - Filas encontradas: 132\n",
      "2025-03-28 18:07:49,176 [INFO] Preferencia de dayfirst para data/Macro/raw\\car_registrations\\U.S. All Car Sales.xlsx: True\n",
      "2025-03-28 18:07:49,232 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:49,235 [ERROR] No se encontraron valores válidos para 'Actual' en data/Macro/raw\\car_registrations\\U.S. All Car Sales.xlsx\n",
      "2025-03-28 18:07:49,236 [INFO] \n",
      "Procesando: US_Consumer_Confidence (consumer_confidence)\n",
      "2025-03-28 18:07:49,238 [INFO] - Archivo: US_Consumer_Confidence.xlsx\n",
      "2025-03-28 18:07:49,238 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:49,239 [INFO] - Ruta encontrada: data/Macro/raw\\consumer_confidence\\US_Consumer_Confidence.xlsx\n",
      "2025-03-28 18:07:49,257 [INFO] - Filas encontradas: 136\n",
      "2025-03-28 18:07:49,264 [INFO] Preferencia de dayfirst para data/Macro/raw\\consumer_confidence\\US_Consumer_Confidence.xlsx: True\n",
      "2025-03-28 18:07:49,319 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:49,324 [INFO] - Valores no nulos en TARGET: 136\n",
      "2025-03-28 18:07:49,324 [INFO] - Periodo: 2013-12-31 a 2025-03-25\n",
      "2025-03-28 18:07:49,324 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 18:07:49,328 [INFO] \n",
      "Procesando: China_PMI_Manufacturing (economics)\n",
      "2025-03-28 18:07:49,328 [INFO] - Archivo: China_PMI_Manufacturing.xlsx\n",
      "2025-03-28 18:07:49,330 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:49,331 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\China_PMI_Manufacturing.xlsx\n",
      "2025-03-28 18:07:49,348 [INFO] - Filas encontradas: 136\n",
      "2025-03-28 18:07:49,355 [INFO] Preferencia de dayfirst para data/Macro/raw\\economics\\China_PMI_Manufacturing.xlsx: True\n",
      "2025-03-28 18:07:49,407 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:49,411 [INFO] - Valores no nulos en TARGET: 135\n",
      "2025-03-28 18:07:49,413 [INFO] - Periodo: 2013-12-31 a 2025-02-28\n",
      "2025-03-28 18:07:49,414 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 18:07:49,416 [INFO] \n",
      "Procesando: Singapore_NonOil_Exports_YoY (economics)\n",
      "2025-03-28 18:07:49,418 [INFO] - Archivo: Singapore_NonOil_Exports_YoY.xlsx\n",
      "2025-03-28 18:07:49,418 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:49,421 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\Singapore_NonOil_Exports_YoY.xlsx\n",
      "2025-03-28 18:07:49,443 [INFO] - Filas encontradas: 138\n",
      "2025-03-28 18:07:49,448 [INFO] Preferencia de dayfirst para data/Macro/raw\\economics\\Singapore_NonOil_Exports_YoY.xlsx: True\n",
      "2025-03-28 18:07:49,504 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:49,508 [ERROR] No se encontraron valores válidos para 'Actual' en data/Macro/raw\\economics\\Singapore_NonOil_Exports_YoY.xlsx\n",
      "2025-03-28 18:07:49,508 [INFO] \n",
      "Procesando: Japan_M2_MoneySupply_YoY (economics)\n",
      "2025-03-28 18:07:49,511 [INFO] - Archivo: Japan_M2_MoneySupply_YoY.xlsx\n",
      "2025-03-28 18:07:49,511 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:49,512 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\Japan_M2_MoneySupply_YoY.xlsx\n",
      "2025-03-28 18:07:49,526 [INFO] - Filas encontradas: 131\n",
      "2025-03-28 18:07:49,534 [INFO] Preferencia de dayfirst para data/Macro/raw\\economics\\Japan_M2_MoneySupply_YoY.xlsx: True\n",
      "2025-03-28 18:07:49,587 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:49,592 [ERROR] No se encontraron valores válidos para 'Actual' en data/Macro/raw\\economics\\Japan_M2_MoneySupply_YoY.xlsx\n",
      "2025-03-28 18:07:49,593 [INFO] \n",
      "Procesando: China_M2_MoneySupply_YoY (economics)\n",
      "2025-03-28 18:07:49,595 [INFO] - Archivo: China_M2_MoneySupply_YoY.xlsx\n",
      "2025-03-28 18:07:49,595 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:49,596 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\China_M2_MoneySupply_YoY.xlsx\n",
      "2025-03-28 18:07:49,634 [INFO] - Filas encontradas: 137\n",
      "2025-03-28 18:07:49,643 [INFO] Preferencia de dayfirst para data/Macro/raw\\economics\\China_M2_MoneySupply_YoY.xlsx: True\n",
      "2025-03-28 18:07:49,717 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:49,718 [ERROR] No se encontraron valores válidos para 'Actual' en data/Macro/raw\\economics\\China_M2_MoneySupply_YoY.xlsx\n",
      "2025-03-28 18:07:49,720 [INFO] \n",
      "Procesando: Mexico_CPI_MoM (economics)\n",
      "2025-03-28 18:07:49,720 [INFO] - Archivo: Mexico_CPI_MoM.xlsx\n",
      "2025-03-28 18:07:49,723 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:49,723 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\Mexico_CPI_MoM.xlsx\n",
      "2025-03-28 18:07:49,791 [INFO] - Filas encontradas: 138\n",
      "2025-03-28 18:07:49,796 [INFO] Preferencia de dayfirst para data/Macro/raw\\economics\\Mexico_CPI_MoM.xlsx: True\n",
      "2025-03-28 18:07:49,847 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:49,849 [ERROR] No se encontraron valores válidos para 'Actual' en data/Macro/raw\\economics\\Mexico_CPI_MoM.xlsx\n",
      "2025-03-28 18:07:49,850 [INFO] \n",
      "Procesando: BOJ_Policy_Rate (economics)\n",
      "2025-03-28 18:07:49,852 [INFO] - Archivo: BOJ_Policy_Rate.xlsx\n",
      "2025-03-28 18:07:49,852 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:49,852 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\BOJ_Policy_Rate.xlsx\n",
      "2025-03-28 18:07:49,864 [INFO] - Filas encontradas: 111\n",
      "2025-03-28 18:07:49,876 [INFO] Preferencia de dayfirst para data/Macro/raw\\economics\\BOJ_Policy_Rate.xlsx: True\n",
      "2025-03-28 18:07:49,934 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:49,938 [ERROR] No se encontraron valores válidos para 'Actual' en data/Macro/raw\\economics\\BOJ_Policy_Rate.xlsx\n",
      "2025-03-28 18:07:49,940 [INFO] \n",
      "Procesando: UK_Retail_Sales_MoM (economics)\n",
      "2025-03-28 18:07:49,941 [INFO] - Archivo: UK_Retail_Sales_MoM.xlsx\n",
      "2025-03-28 18:07:49,941 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:49,943 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\UK_Retail_Sales_MoM.xlsx\n",
      "2025-03-28 18:07:49,961 [INFO] - Filas encontradas: 138\n",
      "2025-03-28 18:07:49,967 [INFO] Preferencia de dayfirst para data/Macro/raw\\economics\\UK_Retail_Sales_MoM.xlsx: True\n",
      "2025-03-28 18:07:50,027 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:50,030 [ERROR] No se encontraron valores válidos para 'Actual' en data/Macro/raw\\economics\\UK_Retail_Sales_MoM.xlsx\n",
      "2025-03-28 18:07:50,031 [INFO] \n",
      "Procesando: China_Exports (exports)\n",
      "2025-03-28 18:07:50,031 [INFO] - Archivo: China_Exports.xlsx\n",
      "2025-03-28 18:07:50,031 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:50,033 [INFO] - Ruta encontrada: data/Macro/raw\\exports\\China_Exports.xlsx\n",
      "2025-03-28 18:07:50,054 [INFO] - Filas encontradas: 131\n",
      "2025-03-28 18:07:50,062 [INFO] Preferencia de dayfirst para data/Macro/raw\\exports\\China_Exports.xlsx: True\n",
      "2025-03-28 18:07:50,156 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:50,160 [ERROR] No se encontraron valores válidos para 'Actual' en data/Macro/raw\\exports\\China_Exports.xlsx\n",
      "2025-03-28 18:07:50,161 [INFO] \n",
      "Procesando: US_Exports (exports)\n",
      "2025-03-28 18:07:50,165 [INFO] - Archivo: US_Exports.xlsx\n",
      "2025-03-28 18:07:50,166 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:50,167 [INFO] - Ruta encontrada: data/Macro/raw\\exports\\US_Exports.xlsx\n",
      "2025-03-28 18:07:50,187 [INFO] - Filas encontradas: 87\n",
      "2025-03-28 18:07:50,197 [INFO] Preferencia de dayfirst para data/Macro/raw\\exports\\US_Exports.xlsx: True\n",
      "2025-03-28 18:07:50,247 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:50,252 [ERROR] No se encontraron valores válidos para 'Actual' en data/Macro/raw\\exports\\US_Exports.xlsx\n",
      "2025-03-28 18:07:50,253 [INFO] \n",
      "Procesando: US_Leading_EconIndex (leading_economic_index)\n",
      "2025-03-28 18:07:50,253 [INFO] - Archivo: US_Leading_EconIndex.xlsx\n",
      "2025-03-28 18:07:50,255 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:50,256 [INFO] - Ruta encontrada: data/Macro/raw\\leading_economic_index\\US_Leading_EconIndex.xlsx\n",
      "2025-03-28 18:07:50,258 [INFO] Utilizando estrategia especial para US_Leading_EconIndex (header=2)\n",
      "2025-03-28 18:07:50,278 [INFO] Columnas leídas: ['Feb 20, 2025 (Jan)', nan, '-0.3%', '-0.1%', '0.1%']\n",
      "2025-03-28 18:07:50,281 [INFO] - Filas encontradas: 133\n",
      "2025-03-28 18:07:50,281 [ERROR] No se encontró la columna 'Release Date' en data/Macro/raw\\leading_economic_index\\US_Leading_EconIndex.xlsx\n",
      "2025-03-28 18:07:50,283 [INFO] \n",
      "Procesando: US_ConferenceBoard_LEI (leading_economic_index)\n",
      "2025-03-28 18:07:50,284 [INFO] - Archivo: US_ConferenceBoard_LEI.xlsx\n",
      "2025-03-28 18:07:50,284 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:50,286 [INFO] - Ruta encontrada: data/Macro/raw\\leading_economic_index\\US_ConferenceBoard_LEI.xlsx\n",
      "2025-03-28 18:07:50,301 [INFO] - Filas encontradas: 135\n",
      "2025-03-28 18:07:50,306 [INFO] Preferencia de dayfirst para data/Macro/raw\\leading_economic_index\\US_ConferenceBoard_LEI.xlsx: True\n",
      "2025-03-28 18:07:50,382 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:50,385 [INFO] - Valores no nulos en TARGET: 8\n",
      "2025-03-28 18:07:50,385 [INFO] - Periodo: 2014-01-28 a 2014-08-26\n",
      "2025-03-28 18:07:50,387 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 18:07:50,388 [INFO] \n",
      "Procesando: Japan_Leading_Indicator (leading_economic_index)\n",
      "2025-03-28 18:07:50,391 [INFO] - Archivo: Japan_Leading_Indicator.xlsx\n",
      "2025-03-28 18:07:50,391 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:50,393 [INFO] - Ruta encontrada: data/Macro/raw\\leading_economic_index\\Japan_Leading_Indicator.xlsx\n",
      "2025-03-28 18:07:50,432 [INFO] - Filas encontradas: 257\n",
      "2025-03-28 18:07:50,438 [INFO] Preferencia de dayfirst para data/Macro/raw\\leading_economic_index\\Japan_Leading_Indicator.xlsx: True\n",
      "2025-03-28 18:07:50,597 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:50,605 [INFO] - Valores no nulos en TARGET: 257\n",
      "2025-03-28 18:07:50,606 [INFO] - Periodo: 2014-01-10 a 2025-03-26\n",
      "2025-03-28 18:07:50,609 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 18:07:50,614 [INFO] \n",
      "Procesando: China_Unemployment_Rate (unemployment_rate)\n",
      "2025-03-28 18:07:50,618 [INFO] - Archivo: China_Unemployment_Rate.xlsx\n",
      "2025-03-28 18:07:50,620 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:50,621 [INFO] - Ruta encontrada: data/Macro/raw\\unemployment_rate\\China_Unemployment_Rate.xlsx\n",
      "2025-03-28 18:07:50,643 [INFO] - Filas encontradas: 75\n",
      "2025-03-28 18:07:50,652 [INFO] Preferencia de dayfirst para data/Macro/raw\\unemployment_rate\\China_Unemployment_Rate.xlsx: True\n",
      "2025-03-28 18:07:50,703 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:50,706 [ERROR] No se encontraron valores válidos para 'Actual' en data/Macro/raw\\unemployment_rate\\China_Unemployment_Rate.xlsx\n",
      "2025-03-28 18:07:50,707 [INFO] \n",
      "Procesando: Eurozone_Unemployment_Rate (unemployment_rate)\n",
      "2025-03-28 18:07:50,707 [INFO] - Archivo: Eurozone_Unemployment_Rate.xlsx\n",
      "2025-03-28 18:07:50,709 [INFO] - Columna TARGET: ACTUAL\n",
      "2025-03-28 18:07:50,709 [INFO] - Ruta encontrada: data/Macro/raw\\unemployment_rate\\Eurozone_Unemployment_Rate.xlsx\n",
      "2025-03-28 18:07:50,731 [INFO] - Filas encontradas: 136\n",
      "2025-03-28 18:07:50,737 [INFO] Preferencia de dayfirst para data/Macro/raw\\unemployment_rate\\Eurozone_Unemployment_Rate.xlsx: True\n",
      "2025-03-28 18:07:50,825 [WARNING] No se encontró 'ACTUAL', se usará 'Actual'\n",
      "2025-03-28 18:07:50,829 [ERROR] No se encontraron valores válidos para 'Actual' en data/Macro/raw\\unemployment_rate\\Eurozone_Unemployment_Rate.xlsx\n",
      "2025-03-28 18:07:50,832 [INFO] Índice diario generado: 4166 días desde 2013-10-30 hasta 2025-03-26\n",
      "2025-03-28 18:07:50,858 [WARNING] Omitiendo U.S. All Car Sales por falta de datos\n",
      "2025-03-28 18:07:50,871 [WARNING] Omitiendo Singapore_NonOil_Exports_YoY por falta de datos\n",
      "2025-03-28 18:07:50,871 [WARNING] Omitiendo Japan_M2_MoneySupply_YoY por falta de datos\n",
      "2025-03-28 18:07:50,873 [WARNING] Omitiendo China_M2_MoneySupply_YoY por falta de datos\n",
      "2025-03-28 18:07:50,874 [WARNING] Omitiendo Mexico_CPI_MoM por falta de datos\n",
      "2025-03-28 18:07:50,874 [WARNING] Omitiendo BOJ_Policy_Rate por falta de datos\n",
      "2025-03-28 18:07:50,876 [WARNING] Omitiendo UK_Retail_Sales_MoM por falta de datos\n",
      "2025-03-28 18:07:50,877 [WARNING] Omitiendo China_Exports por falta de datos\n",
      "2025-03-28 18:07:50,879 [WARNING] Omitiendo US_Exports por falta de datos\n",
      "2025-03-28 18:07:50,879 [WARNING] Omitiendo US_Leading_EconIndex por falta de datos\n",
      "2025-03-28 18:07:50,896 [WARNING] Omitiendo China_Unemployment_Rate por falta de datos\n",
      "2025-03-28 18:07:50,897 [WARNING] Omitiendo Eurozone_Unemployment_Rate por falta de datos\n",
      "2025-03-28 18:07:50,898 [INFO] DataFrame final combinado: 4166 filas, 10 columnas\n",
      "2025-03-28 18:07:50,899 [INFO] \n",
      "Resumen de Cobertura:\n",
      "2025-03-28 18:07:50,900 [INFO] - US_ISM_Manufacturing: 100.00% desde 2013-11-01 a 2025-03-03\n",
      "2025-03-28 18:07:50,902 [INFO] - US_ISM_Services: 100.00% desde 2013-12-04 a 2025-03-05\n",
      "2025-03-28 18:07:50,904 [INFO] - US_Philly_Fed_Index: 100.00% desde 2013-12-19 a 2025-03-20\n",
      "2025-03-28 18:07:50,905 [INFO] - France_Business_Climate: 100.00% desde 2013-12-20 a 2025-03-21\n",
      "2025-03-28 18:07:50,906 [INFO] - EuroZone_Business_Climate: 100.00% desde 2013-10-30 a 2025-02-27\n",
      "2025-03-28 18:07:50,907 [INFO] - US_Consumer_Confidence: 100.00% desde 2013-12-31 a 2025-03-25\n",
      "2025-03-28 18:07:50,908 [INFO] - China_PMI_Manufacturing: 100.00% desde 2013-12-31 a 2025-02-28\n",
      "2025-03-28 18:07:50,910 [INFO] - US_ConferenceBoard_LEI: 100.00% desde 2014-01-28 a 2014-08-26\n",
      "2025-03-28 18:07:50,912 [INFO] - Japan_Leading_Indicator: 100.00% desde 2014-01-10 a 2025-03-26\n",
      "2025-03-28 18:07:51,653 [INFO] Archivo guardado exitosamente: datos_economicos_procesados.xlsx\n",
      "2025-03-28 18:07:51,655 [INFO] \n",
      "Resumen de Ejecución:\n",
      "2025-03-28 18:07:51,658 [INFO] Tiempo de ejecución: 3.06 segundos\n",
      "2025-03-28 18:07:51,661 [INFO] Archivos procesados: 21\n",
      "2025-03-28 18:07:51,662 [INFO] Archivo de salida: datos_economicos_procesados.xlsx\n",
      "2025-03-28 18:07:51,664 [INFO] Estado: COMPLETADO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado exitosamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de logging\n",
    "def configurar_logging(log_file='myinvestingreportcp.log'):\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger('EconomicDataProcessor')\n",
    "\n",
    "class EconomicDataProcessor:\n",
    "    \"\"\"\n",
    "    Clase para procesar datos macroeconómicos con robustez en el manejo de fechas y \n",
    "    forward filling de series de frecuencia (por ejemplo, mensuales a diarios).\n",
    "\n",
    "    Funcionalidades:\n",
    "      - Conversión robusta de cadenas de fecha usando múltiples estrategias.\n",
    "      - Transformación de series (generalmente mensuales) a datos diarios mediante merge_asof.\n",
    "      - Renombrado de la columna de valores usando el patrón: \n",
    "            {target_col}_{variable}_{tipo_macro}\n",
    "      - Validación y log detallado en cada etapa.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config_file, data_root='data/Macro/raw', log_file='myinvestingreportcp.log'):\n",
    "        self.config_file = config_file\n",
    "        self.data_root = data_root\n",
    "        self.logger = configurar_logging(log_file)\n",
    "        self.config_data = None\n",
    "        self.global_min_date = None\n",
    "        self.global_max_date = None\n",
    "        self.daily_index = None\n",
    "        self.processed_data = {}  # Diccionario {variable: DataFrame procesado}\n",
    "        self.final_df = None\n",
    "        self.stats = {}\n",
    "        # Cache para la preferencia de conversión de fecha\n",
    "        self.date_cache = {}\n",
    "\n",
    "        self.logger.info(\"=\" * 80)\n",
    "        self.logger.info(\"INICIANDO PROCESO: EconomicDataProcessor\")\n",
    "        self.logger.info(f\"Archivo de configuración: {config_file}\")\n",
    "        self.logger.info(f\"Directorio raíz de datos: {data_root}\")\n",
    "        self.logger.info(f\"Fecha y hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        self.logger.info(\"=\" * 80)\n",
    "\n",
    "    def read_config(self):\n",
    "        try:\n",
    "            self.logger.info(\"Leyendo archivo de configuración...\")\n",
    "            df_config = pd.read_excel(self.config_file)\n",
    "            self.config_data = df_config[\n",
    "                (df_config['Fuente'] == 'Investing Data') &\n",
    "                (df_config['Tipo de Preprocesamiento Según la Fuente'] == 'Copiar y Pegar')\n",
    "            ].copy()\n",
    "            self.logger.info(f\"Se encontraron {len(self.config_data)} configuraciones para procesar\")\n",
    "            return self.config_data\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al leer configuración: {e}\")\n",
    "            return None\n",
    "\n",
    "    def robust_parse_date(self, date_str, preferred_dayfirst=None):\n",
    "        \"\"\"\n",
    "        Intenta convertir la cadena de fecha usando múltiples estrategias.\n",
    "        - Primero, busca patrones como \"Apr 01, 2025 (Mar)\".\n",
    "        - Luego utiliza pd.to_datetime con la opción dayfirst según la preferencia.\n",
    "        - Si no se especifica, prueba ambas opciones y elige la que dé una fecha razonable.\n",
    "\n",
    "        Args:\n",
    "            date_str (str): Cadena de fecha.\n",
    "            preferred_dayfirst (bool, opcional): Preferencia de interpretación.\n",
    "\n",
    "        Returns:\n",
    "            pd.Timestamp o None.\n",
    "        \"\"\"\n",
    "        if not isinstance(date_str, str):\n",
    "            return None\n",
    "        date_str = date_str.strip()\n",
    "        if not date_str:\n",
    "            return None\n",
    "\n",
    "        m = re.search(r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})', date_str)\n",
    "        if m:\n",
    "            candidate = m.group(1)\n",
    "            try:\n",
    "                parsed = pd.to_datetime(candidate, errors='coerce')\n",
    "                if parsed is not None:\n",
    "                    return parsed\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Error al parsear patrón en '{date_str}': {e}\")\n",
    "\n",
    "        if preferred_dayfirst is not None:\n",
    "            try:\n",
    "                parsed = pd.to_datetime(date_str, dayfirst=preferred_dayfirst, errors='coerce')\n",
    "                threshold = pd.Timestamp.today() + pd.Timedelta(days=30)\n",
    "                if parsed and parsed <= threshold:\n",
    "                    return parsed\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Error con dayfirst={preferred_dayfirst} en '{date_str}': {e}\")\n",
    "\n",
    "        try:\n",
    "            parsed_true = pd.to_datetime(date_str, dayfirst=True, errors='coerce')\n",
    "            parsed_false = pd.to_datetime(date_str, dayfirst=False, errors='coerce')\n",
    "            threshold = pd.Timestamp.today() + pd.Timedelta(days=30)\n",
    "            valid_true = parsed_true and parsed_true <= threshold\n",
    "            valid_false = parsed_false and parsed_false <= threshold\n",
    "            if valid_true and not valid_false:\n",
    "                return parsed_true\n",
    "            elif valid_false and not valid_true:\n",
    "                return parsed_false\n",
    "            elif valid_true and valid_false:\n",
    "                return parsed_true  # Por defecto dayfirst=True\n",
    "            else:\n",
    "                return parsed_true if pd.notnull(parsed_true) else parsed_false\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Error en robust_parse_date para '{date_str}': {e}\")\n",
    "            return None\n",
    "\n",
    "    def process_file(self, config_row):\n",
    "        \"\"\"\n",
    "        Procesa un archivo individual:\n",
    "          - Lee el archivo (se usa estrategia especial para US_Leading_EconIndex).\n",
    "          - Convierte la columna 'Release Date' robustamente.\n",
    "          - Detecta y convierte la columna target a numérico.\n",
    "          - Renombra la columna de valor usando el patrón:\n",
    "                {target_col}_{variable}_{tipo_macro}\n",
    "          - Selecciona solo las columnas 'fecha' y la columna renombrada.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (variable, DataFrame procesado) o (variable, None) en caso de error.\n",
    "        \"\"\"\n",
    "        variable = config_row['Variable']\n",
    "        macro_type = config_row['Tipo Macro']\n",
    "        target_col = config_row['TARGET']\n",
    "\n",
    "        # Construir la ruta (buscando también en subdirectorios)\n",
    "        ruta = os.path.join(self.data_root, macro_type, f\"{variable}.xlsx\")\n",
    "        if not os.path.exists(ruta):\n",
    "            for root, dirs, files in os.walk(self.data_root):\n",
    "                if f\"{variable}.xlsx\" in files:\n",
    "                    ruta = os.path.join(root, f\"{variable}.xlsx\")\n",
    "                    break\n",
    "        if not os.path.exists(ruta):\n",
    "            self.logger.error(f\"Archivo no encontrado: {variable}.xlsx\")\n",
    "            return variable, None\n",
    "\n",
    "        self.logger.info(f\"\\nProcesando: {variable} ({macro_type})\")\n",
    "        self.logger.info(f\"- Archivo: {variable}.xlsx\")\n",
    "        self.logger.info(f\"- Columna TARGET: {target_col}\")\n",
    "        self.logger.info(f\"- Ruta encontrada: {ruta}\")\n",
    "\n",
    "        try:\n",
    "            # Estrategia especial para US_Leading_EconIndex: ajustar header y limpiar columnas\n",
    "            if variable == \"US_Leading_EconIndex\":\n",
    "                self.logger.info(\"Utilizando estrategia especial para US_Leading_EconIndex (header=2)\")\n",
    "                df = pd.read_excel(ruta, header=2, engine='openpyxl')\n",
    "                df.columns = df.columns.str.strip()\n",
    "                self.logger.info(f\"Columnas leídas: {df.columns.tolist()}\")\n",
    "            else:\n",
    "                df = pd.read_excel(ruta, engine='openpyxl')\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al leer {ruta}: {e}\")\n",
    "            return variable, None\n",
    "\n",
    "        self.logger.info(f\"- Filas encontradas: {len(df)}\")\n",
    "        if 'Release Date' not in df.columns:\n",
    "            self.logger.error(f\"No se encontró la columna 'Release Date' en {ruta}\")\n",
    "            return variable, None\n",
    "\n",
    "        # Determinar preferencia de dayfirst (cacheada)\n",
    "        if ruta not in self.date_cache:\n",
    "            sample = df['Release Date'].dropna().head(10)\n",
    "            count_true, count_false = 0, 0\n",
    "            threshold = pd.Timestamp.today() + pd.Timedelta(days=30)\n",
    "            for val in sample:\n",
    "                dt_true = pd.to_datetime(val, dayfirst=True, errors='coerce')\n",
    "                dt_false = pd.to_datetime(val, dayfirst=False, errors='coerce')\n",
    "                if pd.notnull(dt_true) and dt_true <= threshold:\n",
    "                    count_true += 1\n",
    "                if pd.notnull(dt_false) and dt_false <= threshold:\n",
    "                    count_false += 1\n",
    "            preferred = count_true >= count_false\n",
    "            self.date_cache[ruta] = preferred\n",
    "            self.logger.info(f\"Preferencia de dayfirst para {ruta}: {preferred}\")\n",
    "        else:\n",
    "            preferred = self.date_cache[ruta]\n",
    "\n",
    "        df['fecha'] = df['Release Date'].apply(lambda x: self.robust_parse_date(x, preferred_dayfirst=preferred))\n",
    "        df = df.dropna(subset=['fecha'])\n",
    "        df = df.sort_values('fecha')\n",
    "\n",
    "        # Si el target especificado no está, intenta buscar una alternativa\n",
    "        if target_col not in df.columns:\n",
    "            for col in df.columns:\n",
    "                if col.strip().lower() == target_col.strip().lower():\n",
    "                    target_col = col\n",
    "                    self.logger.warning(f\"No se encontró '{config_row['TARGET']}', se usará '{target_col}'\")\n",
    "                    break\n",
    "        if target_col not in df.columns:\n",
    "            self.logger.error(f\"No se encontró columna TARGET ni alternativa en {ruta}\")\n",
    "            return variable, None\n",
    "\n",
    "        # Convertir la columna target a numérico y descartar valores no válidos\n",
    "        df['valor'] = pd.to_numeric(df[target_col], errors='coerce')\n",
    "        df = df.dropna(subset=['valor'])\n",
    "        if df.empty:\n",
    "            self.logger.error(f\"No se encontraron valores válidos para '{target_col}' en {ruta}\")\n",
    "            return variable, None\n",
    "\n",
    "        # Actualizar rango global de fechas\n",
    "        current_min = df['fecha'].min()\n",
    "        current_max = df['fecha'].max()\n",
    "        if self.global_min_date is None or current_min < self.global_min_date:\n",
    "            self.global_min_date = current_min\n",
    "        if self.global_max_date is None or current_max > self.global_max_date:\n",
    "            self.global_max_date = current_max\n",
    "\n",
    "        # Calcular cobertura (puedes ajustar la fórmula si lo deseas)\n",
    "        cobertura = (len(df) / len(df)) * 100\n",
    "\n",
    "        # RENOMBRAR LA COLUMNA: Crear un nombre único\n",
    "        nuevo_nombre = f\"{target_col}_{variable}_{macro_type}\"\n",
    "        df.rename(columns={'valor': nuevo_nombre}, inplace=True)\n",
    "        self.stats[variable] = {\n",
    "            'macro_type': macro_type,\n",
    "            'target_column': target_col,\n",
    "            'total_rows': len(df),\n",
    "            'valid_values': len(df),\n",
    "            'coverage': cobertura,\n",
    "            'date_min': current_min,\n",
    "            'date_max': current_max,\n",
    "            'nuevo_nombre': nuevo_nombre\n",
    "        }\n",
    "        self.logger.info(f\"- Valores no nulos en TARGET: {len(df)}\")\n",
    "        self.logger.info(f\"- Periodo: {current_min.strftime('%Y-%m-%d')} a {current_max.strftime('%Y-%m-%d')}\")\n",
    "        self.logger.info(f\"- Cobertura: {cobertura:.2f}%\")\n",
    "        return variable, df[['fecha', nuevo_nombre]].copy()\n",
    "\n",
    "    def generate_daily_index(self):\n",
    "        \"\"\"\n",
    "        Genera un DataFrame con un índice diario desde la fecha global mínima hasta la máxima.\n",
    "        \"\"\"\n",
    "        if self.global_min_date is None or self.global_max_date is None:\n",
    "            self.logger.error(\"No se pudieron determinar las fechas globales\")\n",
    "            return None\n",
    "        self.daily_index = pd.DataFrame({\n",
    "            'fecha': pd.date_range(start=self.global_min_date, end=self.global_max_date, freq='D')\n",
    "        })\n",
    "        self.logger.info(f\"Índice diario generado: {len(self.daily_index)} días desde {self.global_min_date.strftime('%Y-%m-%d')} hasta {self.global_max_date.strftime('%Y-%m-%d')}\")\n",
    "        return self.daily_index\n",
    "\n",
    "    def combine_data(self):\n",
    "        \"\"\"\n",
    "        Convierte cada serie (generalmente reportada en frecuencias bajas) a datos diarios usando merge_asof.\n",
    "        Para cada archivo, se asocia el dato reportado más reciente a cada día.\n",
    "        \"\"\"\n",
    "        if self.daily_index is None:\n",
    "            self.logger.error(\"El índice diario no ha sido generado\")\n",
    "            return None\n",
    "\n",
    "        combined = self.daily_index.copy()\n",
    "        for variable, df in self.processed_data.items():\n",
    "            if df is None or df.empty:\n",
    "                self.logger.warning(f\"Omitiendo {variable} por falta de datos\")\n",
    "                continue\n",
    "            df = df.sort_values('fecha')\n",
    "            # merge_asof para asignar cada día con el valor reportado más reciente\n",
    "            df_daily = pd.merge_asof(combined, df, on='fecha', direction='backward')\n",
    "            col_name = self.stats[variable]['nuevo_nombre']\n",
    "            # Como precaución se aplica ffill\n",
    "            df_daily[col_name] = df_daily[col_name].ffill()\n",
    "            combined = combined.merge(df_daily[['fecha', col_name]], on='fecha', how='left')\n",
    "        self.final_df = combined\n",
    "        self.logger.info(f\"DataFrame final combinado: {len(self.final_df)} filas, {len(self.final_df.columns)} columnas\")\n",
    "        return self.final_df\n",
    "\n",
    "    def analyze_coverage(self):\n",
    "        \"\"\"\n",
    "        Genera un resumen de cobertura y estadísticas para cada indicador.\n",
    "        \"\"\"\n",
    "        total_days = len(self.daily_index)\n",
    "        self.logger.info(\"\\nResumen de Cobertura:\")\n",
    "        for variable, stats in self.stats.items():\n",
    "            self.logger.info(f\"- {variable}: {stats['coverage']:.2f}% desde {stats['date_min'].strftime('%Y-%m-%d')} a {stats['date_max'].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    def save_results(self, output_file='datos_economicos_procesados.xlsx'):\n",
    "        \"\"\"\n",
    "        Guarda el DataFrame final combinado y las estadísticas en un archivo Excel.\n",
    "        \"\"\"\n",
    "        if self.final_df is None:\n",
    "            self.logger.error(\"No hay datos combinados para guardar\")\n",
    "            return False\n",
    "        try:\n",
    "            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "                self.final_df.to_excel(writer, sheet_name='Datos Diarios', index=False)\n",
    "                df_stats = pd.DataFrame(self.stats).T\n",
    "                df_stats.to_excel(writer, sheet_name='Estadisticas')\n",
    "                meta = {\n",
    "                    'Proceso': ['EconomicDataProcessor'],\n",
    "                    'Fecha de proceso': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                    'Total indicadores': [len(self.stats)],\n",
    "                    'Periodo': [f\"{self.global_min_date.strftime('%Y-%m-%d')} a {self.global_max_date.strftime('%Y-%m-%d')}\"],\n",
    "                    'Total días': [len(self.daily_index)]\n",
    "                }\n",
    "                pd.DataFrame(meta).to_excel(writer, sheet_name='Metadatos', index=False)\n",
    "            self.logger.info(f\"Archivo guardado exitosamente: {output_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al guardar resultados: {e}\")\n",
    "            return False\n",
    "\n",
    "    def run(self, output_file='datos_economicos_procesados.xlsx'):\n",
    "        \"\"\"\n",
    "        Ejecuta el proceso completo:\n",
    "          1. Lee la configuración.\n",
    "          2. Procesa cada archivo.\n",
    "          3. Determina el rango global de fechas.\n",
    "          4. Genera el índice diario.\n",
    "          5. Convierte cada serie a datos diarios y los combina.\n",
    "          6. Realiza un análisis de cobertura.\n",
    "          7. Guarda los resultados.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        if self.read_config() is None:\n",
    "            return False\n",
    "\n",
    "        for _, config_row in self.config_data.iterrows():\n",
    "            var, df_processed = self.process_file(config_row)\n",
    "            self.processed_data[var] = df_processed\n",
    "\n",
    "        if len([df for df in self.processed_data.values() if df is not None]) == 0:\n",
    "            self.logger.error(\"No se procesó ningún archivo correctamente\")\n",
    "            return False\n",
    "\n",
    "        self.generate_daily_index()\n",
    "        self.combine_data()\n",
    "        self.analyze_coverage()\n",
    "        result = self.save_results(output_file)\n",
    "        end_time = time.time()\n",
    "        self.logger.info(\"\\nResumen de Ejecución:\")\n",
    "        self.logger.info(f\"Tiempo de ejecución: {end_time - start_time:.2f} segundos\")\n",
    "        self.logger.info(f\"Archivos procesados: {len(self.config_data)}\")\n",
    "        self.logger.info(f\"Archivo de salida: {output_file}\")\n",
    "        self.logger.info(f\"Estado: {'COMPLETADO' if result else 'ERROR'}\")\n",
    "        return result\n",
    "\n",
    "# Función principal para ejecutar el proceso\n",
    "def run_economic_data_processor(config_file='Data Engineering.xlsx',\n",
    "                                output_file='datos_economicos_procesados.xlsx',\n",
    "                                data_root='data/Macro/raw',\n",
    "                                log_file='myinvestingreportcp.log'):\n",
    "    processor = EconomicDataProcessor(config_file, data_root, log_file)\n",
    "    return processor.run(output_file)\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    success = run_economic_data_processor()\n",
    "    print(f\"Proceso {'completado exitosamente' if success else 'finalizado con errores'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 20:06:28,401 [INFO] ================================================================================\n",
      "2025-03-28 20:06:28,401 [INFO] INICIANDO PROCESO: FredDataProcessor\n",
      "2025-03-28 20:06:28,402 [INFO] Archivo de configuración: Data Engineering.xlsx\n",
      "2025-03-28 20:06:28,402 [INFO] Directorio raíz de datos: data/Macro/raw\n",
      "2025-03-28 20:06:28,404 [INFO] Fecha y hora: 2025-03-28 20:06:28\n",
      "2025-03-28 20:06:28,404 [INFO] ================================================================================\n",
      "2025-03-28 20:06:28,405 [INFO] Leyendo archivo de configuración...\n",
      "2025-03-28 20:06:28,431 [INFO] Se encontraron 35 configuraciones para procesar\n",
      "2025-03-28 20:06:28,432 [INFO] \n",
      "Procesando: US_10Y_Treasury (bond)\n",
      "2025-03-28 20:06:28,434 [INFO] - Archivo: US_10Y_Treasury.csv\n",
      "2025-03-28 20:06:28,434 [INFO] - Columna TARGET: DGS10\n",
      "2025-03-28 20:06:28,435 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\US_10Y_Treasury.csv\n",
      "2025-03-28 20:06:28,439 [INFO] - Filas encontradas: 2929\n",
      "2025-03-28 20:06:28,442 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:28,442 [INFO] Formato detectado para data/Macro/raw\\bond\\US_10Y_Treasury.csv: ISO\n",
      "2025-03-28 20:06:28,664 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-02 00:00:00'), Timestamp('2014-01-03 00:00:00'), Timestamp('2014-01-06 00:00:00'), Timestamp('2014-01-07 00:00:00'), Timestamp('2014-01-08 00:00:00')]\n",
      "2025-03-28 20:06:28,668 [INFO] - Valores no nulos en TARGET: 2808\n",
      "2025-03-28 20:06:28,671 [INFO] - Periodo: 2014-01-02 a 2025-03-25\n",
      "2025-03-28 20:06:28,673 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:28,676 [INFO] \n",
      "Procesando: US_2Y_Treasury (bond)\n",
      "2025-03-28 20:06:28,677 [INFO] - Archivo: US_2Y_Treasury.csv\n",
      "2025-03-28 20:06:28,677 [INFO] - Columna TARGET: DGS2\n",
      "2025-03-28 20:06:28,679 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\US_2Y_Treasury.csv\n",
      "2025-03-28 20:06:28,686 [INFO] - Filas encontradas: 2929\n",
      "2025-03-28 20:06:28,688 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:28,688 [INFO] Formato detectado para data/Macro/raw\\bond\\US_2Y_Treasury.csv: ISO\n",
      "2025-03-28 20:06:28,949 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-02 00:00:00'), Timestamp('2014-01-03 00:00:00'), Timestamp('2014-01-06 00:00:00'), Timestamp('2014-01-07 00:00:00'), Timestamp('2014-01-08 00:00:00')]\n",
      "2025-03-28 20:06:28,954 [INFO] - Valores no nulos en TARGET: 2808\n",
      "2025-03-28 20:06:28,955 [INFO] - Periodo: 2014-01-02 a 2025-03-25\n",
      "2025-03-28 20:06:28,955 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:28,957 [INFO] \n",
      "Procesando: Corporate_Bond_AAA_Spread (bond)\n",
      "2025-03-28 20:06:28,958 [INFO] - Archivo: Corporate_Bond_AAA_Spread.csv\n",
      "2025-03-28 20:06:28,958 [INFO] - Columna TARGET: AAA\n",
      "2025-03-28 20:06:28,958 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Corporate_Bond_AAA_Spread.csv\n",
      "2025-03-28 20:06:28,962 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:28,964 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:28,964 [INFO] Formato detectado para data/Macro/raw\\bond\\Corporate_Bond_AAA_Spread.csv: ISO\n",
      "2025-03-28 20:06:28,984 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:28,990 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:28,992 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:28,992 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:28,995 [INFO] \n",
      "Procesando: Corporate_Bond_BBB_Spread (bond)\n",
      "2025-03-28 20:06:28,996 [INFO] - Archivo: Corporate_Bond_BBB_Spread.csv\n",
      "2025-03-28 20:06:28,998 [INFO] - Columna TARGET: BAA10YM\n",
      "2025-03-28 20:06:28,998 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\Corporate_Bond_BBB_Spread.csv\n",
      "2025-03-28 20:06:29,001 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,002 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,004 [INFO] Formato detectado para data/Macro/raw\\bond\\Corporate_Bond_BBB_Spread.csv: ISO\n",
      "2025-03-28 20:06:29,019 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,020 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,023 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,025 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,026 [INFO] \n",
      "Procesando: High_Yield_Bond_Spread (bond)\n",
      "2025-03-28 20:06:29,028 [INFO] - Archivo: High_Yield_Bond_Spread.csv\n",
      "2025-03-28 20:06:29,028 [INFO] - Columna TARGET: BAMLH0A0HYM2\n",
      "2025-03-28 20:06:29,031 [INFO] - Ruta encontrada: data/Macro/raw\\bond\\High_Yield_Bond_Spread.csv\n",
      "2025-03-28 20:06:29,034 [INFO] - Filas encontradas: 2967\n",
      "2025-03-28 20:06:29,037 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,039 [INFO] Formato detectado para data/Macro/raw\\bond\\High_Yield_Bond_Spread.csv: ISO\n",
      "2025-03-28 20:06:29,260 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-02 00:00:00'), Timestamp('2014-01-03 00:00:00'), Timestamp('2014-01-06 00:00:00'), Timestamp('2014-01-07 00:00:00'), Timestamp('2014-01-08 00:00:00')]\n",
      "2025-03-28 20:06:29,263 [INFO] - Valores no nulos en TARGET: 2932\n",
      "2025-03-28 20:06:29,263 [INFO] - Periodo: 2014-01-02 a 2025-03-25\n",
      "2025-03-28 20:06:29,265 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,267 [INFO] \n",
      "Procesando: Denmark_Car_Registrations_MoM (car_registrations)\n",
      "2025-03-28 20:06:29,267 [INFO] - Archivo: Denmark_Car_Registrations_MoM.csv\n",
      "2025-03-28 20:06:29,269 [INFO] - Columna TARGET: DNKSLRTCR03GPSAM\n",
      "2025-03-28 20:06:29,269 [INFO] - Ruta encontrada: data/Macro/raw\\car_registrations\\Denmark_Car_Registrations_MoM.csv\n",
      "2025-03-28 20:06:29,271 [INFO] - Filas encontradas: 133\n",
      "2025-03-28 20:06:29,272 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,272 [INFO] Formato detectado para data/Macro/raw\\car_registrations\\Denmark_Car_Registrations_MoM.csv: ISO\n",
      "2025-03-28 20:06:29,285 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,288 [INFO] - Valores no nulos en TARGET: 133\n",
      "2025-03-28 20:06:29,289 [INFO] - Periodo: 2014-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:29,290 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,290 [INFO] \n",
      "Procesando: US_Car_Registrations_MoM (car_registrations)\n",
      "2025-03-28 20:06:29,297 [INFO] - Archivo: US_Car_Registrations_MoM.csv\n",
      "2025-03-28 20:06:29,298 [INFO] - Columna TARGET: USASLRTCR03GPSAM\n",
      "2025-03-28 20:06:29,304 [INFO] - Ruta encontrada: data/Macro/raw\\car_registrations\\US_Car_Registrations_MoM.csv\n",
      "2025-03-28 20:06:29,307 [INFO] - Filas encontradas: 132\n",
      "2025-03-28 20:06:29,310 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,310 [INFO] Formato detectado para data/Macro/raw\\car_registrations\\US_Car_Registrations_MoM.csv: ISO\n",
      "2025-03-28 20:06:29,322 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,327 [INFO] - Valores no nulos en TARGET: 132\n",
      "2025-03-28 20:06:29,329 [INFO] - Periodo: 2014-01-01 a 2024-12-01\n",
      "2025-03-28 20:06:29,330 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,332 [INFO] \n",
      "Procesando: SouthAfrica_Car_Registrations_MoM (car_registrations)\n",
      "2025-03-28 20:06:29,332 [INFO] - Archivo: SouthAfrica_Car_Registrations_MoM.csv\n",
      "2025-03-28 20:06:29,333 [INFO] - Columna TARGET: ZAFSLRTCR03GPSAM\n",
      "2025-03-28 20:06:29,333 [INFO] - Ruta encontrada: data/Macro/raw\\car_registrations\\SouthAfrica_Car_Registrations_MoM.csv\n",
      "2025-03-28 20:06:29,336 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,338 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,338 [INFO] Formato detectado para data/Macro/raw\\car_registrations\\SouthAfrica_Car_Registrations_MoM.csv: ISO\n",
      "2025-03-28 20:06:29,350 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,352 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,352 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,354 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,355 [INFO] \n",
      "Procesando: United_Kingdom_Car_Registrations_MoM (car_registrations)\n",
      "2025-03-28 20:06:29,357 [INFO] - Archivo: United_Kingdom_Car_Registrations_MoM.csv\n",
      "2025-03-28 20:06:29,357 [INFO] - Columna TARGET: GBRSLRTCR03GPSAM\n",
      "2025-03-28 20:06:29,358 [INFO] - Ruta encontrada: data/Macro/raw\\car_registrations\\United_Kingdom_Car_Registrations_MoM.csv\n",
      "2025-03-28 20:06:29,360 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,363 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,364 [INFO] Formato detectado para data/Macro/raw\\car_registrations\\United_Kingdom_Car_Registrations_MoM.csv: ISO\n",
      "2025-03-28 20:06:29,377 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,380 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,381 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,381 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,384 [INFO] \n",
      "Procesando: Spain_Car_Registrations_MoM (car_registrations)\n",
      "2025-03-28 20:06:29,384 [INFO] - Archivo: Spain_Car_Registrations_MoM.xlsx\n",
      "2025-03-28 20:06:29,385 [INFO] - Columna TARGET: ESPSLRTCR03GPSAM\n",
      "2025-03-28 20:06:29,385 [INFO] - Ruta encontrada: data/Macro/raw\\car_registrations\\Spain_Car_Registrations_MoM.xlsx\n",
      "2025-03-28 20:06:29,396 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,398 [INFO] Detección formato: 0/20 registros ISO (ratio 0.00)\n",
      "2025-03-28 20:06:29,399 [INFO] Formato detectado para data/Macro/raw\\car_registrations\\Spain_Car_Registrations_MoM.xlsx: AMBIGUOUS\n",
      "2025-03-28 20:06:29,402 [INFO] Preferencia de dayfirst para data/Macro/raw\\car_registrations\\Spain_Car_Registrations_MoM.xlsx: True (score True: 1.00, False: 1.00)\n",
      "2025-03-28 20:06:29,405 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,408 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,411 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,411 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,414 [INFO] \n",
      "Procesando: US_Commercial_Loans (comm_loans)\n",
      "2025-03-28 20:06:29,414 [INFO] - Archivo: US_Commercial_Loans.csv\n",
      "2025-03-28 20:06:29,414 [INFO] - Columna TARGET: BUSLOANS\n",
      "2025-03-28 20:06:29,416 [INFO] - Ruta encontrada: data/Macro/raw\\comm_loans\\US_Commercial_Loans.csv\n",
      "2025-03-28 20:06:29,419 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,420 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,420 [INFO] Formato detectado para data/Macro/raw\\comm_loans\\US_Commercial_Loans.csv: ISO\n",
      "2025-03-28 20:06:29,431 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,434 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,436 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,436 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,440 [INFO] \n",
      "Procesando: US_RealEstate_Commercial_Loans (comm_loans)\n",
      "2025-03-28 20:06:29,445 [INFO] - Archivo: US_RealEstate_Commercial_Loans.csv\n",
      "2025-03-28 20:06:29,448 [INFO] - Columna TARGET: CREACBM027NBOG\n",
      "2025-03-28 20:06:29,450 [INFO] - Ruta encontrada: data/Macro/raw\\comm_loans\\US_RealEstate_Commercial_Loans.csv\n",
      "2025-03-28 20:06:29,455 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,458 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,460 [INFO] Formato detectado para data/Macro/raw\\comm_loans\\US_RealEstate_Commercial_Loans.csv: ISO\n",
      "2025-03-28 20:06:29,489 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,492 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,493 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,495 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,496 [INFO] \n",
      "Procesando: US_Consumer_Credit (comm_loans)\n",
      "2025-03-28 20:06:29,496 [INFO] - Archivo: US_Consumer_Credit.csv\n",
      "2025-03-28 20:06:29,498 [INFO] - Columna TARGET: TOTALSL\n",
      "2025-03-28 20:06:29,498 [INFO] - Ruta encontrada: data/Macro/raw\\comm_loans\\US_Consumer_Credit.csv\n",
      "2025-03-28 20:06:29,502 [INFO] - Filas encontradas: 133\n",
      "2025-03-28 20:06:29,504 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,505 [INFO] Formato detectado para data/Macro/raw\\comm_loans\\US_Consumer_Credit.csv: ISO\n",
      "2025-03-28 20:06:29,520 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,525 [INFO] - Valores no nulos en TARGET: 133\n",
      "2025-03-28 20:06:29,527 [INFO] - Periodo: 2014-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:29,527 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,530 [INFO] \n",
      "Procesando: EuroZone_Consumer_Confidence (consumer_confidence)\n",
      "2025-03-28 20:06:29,532 [INFO] - Archivo: EuroZone_Consumer_Confidence.csv\n",
      "2025-03-28 20:06:29,533 [INFO] - Columna TARGET: CSCICP02EZM460S\n",
      "2025-03-28 20:06:29,533 [INFO] - Ruta encontrada: data/Macro/raw\\consumer_confidence\\EuroZone_Consumer_Confidence.csv\n",
      "2025-03-28 20:06:29,536 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,538 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,539 [INFO] Formato detectado para data/Macro/raw\\consumer_confidence\\EuroZone_Consumer_Confidence.csv: ISO\n",
      "2025-03-28 20:06:29,552 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,555 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,557 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,558 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,560 [INFO] \n",
      "Procesando: Switzerland_Consumer_Confidence (consumer_confidence)\n",
      "2025-03-28 20:06:29,562 [INFO] - Archivo: Switzerland_Consumer_Confidence.csv\n",
      "2025-03-28 20:06:29,562 [INFO] - Columna TARGET: CSCICP02CHQ460S\n",
      "2025-03-28 20:06:29,563 [INFO] - Ruta encontrada: data/Macro/raw\\consumer_confidence\\Switzerland_Consumer_Confidence.csv\n",
      "2025-03-28 20:06:29,566 [INFO] - Filas encontradas: 45\n",
      "2025-03-28 20:06:29,568 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,568 [INFO] Formato detectado para data/Macro/raw\\consumer_confidence\\Switzerland_Consumer_Confidence.csv: ISO\n",
      "2025-03-28 20:06:29,575 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-07-01 00:00:00'), Timestamp('2014-10-01 00:00:00'), Timestamp('2015-01-01 00:00:00')]\n",
      "2025-03-28 20:06:29,580 [INFO] - Valores no nulos en TARGET: 45\n",
      "2025-03-28 20:06:29,582 [INFO] - Periodo: 2014-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:29,582 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,585 [INFO] \n",
      "Procesando: Michigan_Consumer_Sentiment (consumer_confidence)\n",
      "2025-03-28 20:06:29,586 [INFO] - Archivo: Michigan_Consumer_Sentiment.csv\n",
      "2025-03-28 20:06:29,588 [INFO] - Columna TARGET: UMCSENT\n",
      "2025-03-28 20:06:29,589 [INFO] - Ruta encontrada: data/Macro/raw\\consumer_confidence\\Michigan_Consumer_Sentiment.csv\n",
      "2025-03-28 20:06:29,592 [INFO] - Filas encontradas: 121\n",
      "2025-03-28 20:06:29,594 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,595 [INFO] Formato detectado para data/Macro/raw\\consumer_confidence\\Michigan_Consumer_Sentiment.csv: ISO\n",
      "2025-03-28 20:06:29,609 [INFO] Primeras fechas convertidas: [Timestamp('2015-01-01 00:00:00'), Timestamp('2015-02-01 00:00:00'), Timestamp('2015-03-01 00:00:00'), Timestamp('2015-04-01 00:00:00'), Timestamp('2015-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,613 [INFO] - Valores no nulos en TARGET: 121\n",
      "2025-03-28 20:06:29,615 [INFO] - Periodo: 2015-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:29,616 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,618 [INFO] \n",
      "Procesando: US_CPI (economics)\n",
      "2025-03-28 20:06:29,621 [INFO] - Archivo: US_CPI.csv\n",
      "2025-03-28 20:06:29,622 [INFO] - Columna TARGET: CPIAUCSL\n",
      "2025-03-28 20:06:29,624 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\US_CPI.csv\n",
      "2025-03-28 20:06:29,627 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,627 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,628 [INFO] Formato detectado para data/Macro/raw\\economics\\US_CPI.csv: ISO\n",
      "2025-03-28 20:06:29,640 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,643 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,645 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,645 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,648 [INFO] \n",
      "Procesando: US_Core_CPI (economics)\n",
      "2025-03-28 20:06:29,649 [INFO] - Archivo: US_Core_CPI.csv\n",
      "2025-03-28 20:06:29,649 [INFO] - Columna TARGET: CPILFESL\n",
      "2025-03-28 20:06:29,650 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\US_Core_CPI.csv\n",
      "2025-03-28 20:06:29,653 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,653 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,655 [INFO] Formato detectado para data/Macro/raw\\economics\\US_Core_CPI.csv: ISO\n",
      "2025-03-28 20:06:29,667 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,670 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,671 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,673 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,676 [INFO] \n",
      "Procesando: US_PCE (economics)\n",
      "2025-03-28 20:06:29,677 [INFO] - Archivo: US_PCE.csv\n",
      "2025-03-28 20:06:29,677 [INFO] - Columna TARGET: PCE\n",
      "2025-03-28 20:06:29,679 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\US_PCE.csv\n",
      "2025-03-28 20:06:29,683 [INFO] - Filas encontradas: 133\n",
      "2025-03-28 20:06:29,684 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,684 [INFO] Formato detectado para data/Macro/raw\\economics\\US_PCE.csv: ISO\n",
      "2025-03-28 20:06:29,697 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,700 [INFO] - Valores no nulos en TARGET: 133\n",
      "2025-03-28 20:06:29,701 [INFO] - Periodo: 2014-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:29,702 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,704 [INFO] \n",
      "Procesando: US_Core_PCE (economics)\n",
      "2025-03-28 20:06:29,706 [INFO] - Archivo: US_Core_PCE.csv\n",
      "2025-03-28 20:06:29,706 [INFO] - Columna TARGET: PCEPILFE\n",
      "2025-03-28 20:06:29,707 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\US_Core_PCE.csv\n",
      "2025-03-28 20:06:29,709 [INFO] - Filas encontradas: 133\n",
      "2025-03-28 20:06:29,710 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,712 [INFO] Formato detectado para data/Macro/raw\\economics\\US_Core_PCE.csv: ISO\n",
      "2025-03-28 20:06:29,727 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,728 [INFO] - Valores no nulos en TARGET: 133\n",
      "2025-03-28 20:06:29,731 [INFO] - Periodo: 2014-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:29,731 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,734 [INFO] \n",
      "Procesando: US_PPI (economics)\n",
      "2025-03-28 20:06:29,734 [INFO] - Archivo: US_PPI.csv\n",
      "2025-03-28 20:06:29,734 [INFO] - Columna TARGET: PPIACO\n",
      "2025-03-28 20:06:29,736 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\US_PPI.csv\n",
      "2025-03-28 20:06:29,739 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,739 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,740 [INFO] Formato detectado para data/Macro/raw\\economics\\US_PPI.csv: ISO\n",
      "2025-03-28 20:06:29,753 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,756 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,756 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,758 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,761 [INFO] \n",
      "Procesando: US_Industrial_Production_MoM (economics)\n",
      "2025-03-28 20:06:29,761 [INFO] - Archivo: US_Industrial_Production_MoM.csv\n",
      "2025-03-28 20:06:29,761 [INFO] - Columna TARGET: INDPRO\n",
      "2025-03-28 20:06:29,762 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\US_Industrial_Production_MoM.csv\n",
      "2025-03-28 20:06:29,766 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,767 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,767 [INFO] Formato detectado para data/Macro/raw\\economics\\US_Industrial_Production_MoM.csv: ISO\n",
      "2025-03-28 20:06:29,781 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,785 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,785 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,787 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,787 [INFO] \n",
      "Procesando: US_CaseShiller_HomePrice (economics)\n",
      "2025-03-28 20:06:29,788 [INFO] - Archivo: US_CaseShiller_HomePrice.csv\n",
      "2025-03-28 20:06:29,788 [INFO] - Columna TARGET: CSUSHPINSA\n",
      "2025-03-28 20:06:29,790 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\US_CaseShiller_HomePrice.csv\n",
      "2025-03-28 20:06:29,792 [INFO] - Filas encontradas: 133\n",
      "2025-03-28 20:06:29,794 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,796 [INFO] Formato detectado para data/Macro/raw\\economics\\US_CaseShiller_HomePrice.csv: ISO\n",
      "2025-03-28 20:06:29,808 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,811 [INFO] - Valores no nulos en TARGET: 133\n",
      "2025-03-28 20:06:29,812 [INFO] - Periodo: 2014-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:29,814 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,815 [INFO] \n",
      "Procesando: US_GDP_Growth (economics)\n",
      "2025-03-28 20:06:29,815 [INFO] - Archivo: US_GDP_Growth.csv\n",
      "2025-03-28 20:06:29,817 [INFO] - Columna TARGET: GDP\n",
      "2025-03-28 20:06:29,817 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\US_GDP_Growth.csv\n",
      "2025-03-28 20:06:29,820 [INFO] - Filas encontradas: 44\n",
      "2025-03-28 20:06:29,820 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,822 [INFO] Formato detectado para data/Macro/raw\\economics\\US_GDP_Growth.csv: ISO\n",
      "2025-03-28 20:06:29,831 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-07-01 00:00:00'), Timestamp('2014-10-01 00:00:00'), Timestamp('2015-01-01 00:00:00')]\n",
      "2025-03-28 20:06:29,832 [INFO] - Valores no nulos en TARGET: 44\n",
      "2025-03-28 20:06:29,834 [INFO] - Periodo: 2014-01-01 a 2024-10-01\n",
      "2025-03-28 20:06:29,834 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,837 [INFO] \n",
      "Procesando: US_Capacity_Utilization (economics)\n",
      "2025-03-28 20:06:29,837 [INFO] - Archivo: US_Capacity_Utilization.csv\n",
      "2025-03-28 20:06:29,838 [INFO] - Columna TARGET: TCU\n",
      "2025-03-28 20:06:29,838 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\US_Capacity_Utilization.csv\n",
      "2025-03-28 20:06:29,841 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,842 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,842 [INFO] Formato detectado para data/Macro/raw\\economics\\US_Capacity_Utilization.csv: ISO\n",
      "2025-03-28 20:06:29,855 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,858 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,859 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,860 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,862 [INFO] \n",
      "Procesando: US_Building_Permits (economics)\n",
      "2025-03-28 20:06:29,862 [INFO] - Archivo: US_Building_Permits.csv\n",
      "2025-03-28 20:06:29,864 [INFO] - Columna TARGET: PERMIT\n",
      "2025-03-28 20:06:29,864 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\US_Building_Permits.csv\n",
      "2025-03-28 20:06:29,865 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,867 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,868 [INFO] Formato detectado para data/Macro/raw\\economics\\US_Building_Permits.csv: ISO\n",
      "2025-03-28 20:06:29,880 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,883 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,883 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,885 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,886 [INFO] \n",
      "Procesando: US_Housing_Starts (economics)\n",
      "2025-03-28 20:06:29,886 [INFO] - Archivo: US_Housing_Starts.csv\n",
      "2025-03-28 20:06:29,888 [INFO] - Columna TARGET: HOUST\n",
      "2025-03-28 20:06:29,888 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\US_Housing_Starts.csv\n",
      "2025-03-28 20:06:29,891 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,892 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,892 [INFO] Formato detectado para data/Macro/raw\\economics\\US_Housing_Starts.csv: ISO\n",
      "2025-03-28 20:06:29,905 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,908 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,908 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,910 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,910 [INFO] \n",
      "Procesando: US_FedFunds_Rate (economics)\n",
      "2025-03-28 20:06:29,913 [INFO] - Archivo: US_FedFunds_Rate.csv\n",
      "2025-03-28 20:06:29,913 [INFO] - Columna TARGET: FEDFUNDS\n",
      "2025-03-28 20:06:29,914 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\US_FedFunds_Rate.csv\n",
      "2025-03-28 20:06:29,916 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:29,917 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,919 [INFO] Formato detectado para data/Macro/raw\\economics\\US_FedFunds_Rate.csv: ISO\n",
      "2025-03-28 20:06:29,940 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:29,942 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:29,943 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:29,945 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:29,946 [INFO] \n",
      "Procesando: ECB_Deposit_Rate (economics)\n",
      "2025-03-28 20:06:29,948 [INFO] - Archivo: ECB_Deposit_Rate.csv\n",
      "2025-03-28 20:06:29,948 [INFO] - Columna TARGET: ECBDFR\n",
      "2025-03-28 20:06:29,949 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\ECB_Deposit_Rate.csv\n",
      "2025-03-28 20:06:29,953 [INFO] - Filas encontradas: 4103\n",
      "2025-03-28 20:06:29,955 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:29,956 [INFO] Formato detectado para data/Macro/raw\\economics\\ECB_Deposit_Rate.csv: ISO\n",
      "2025-03-28 20:06:30,449 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-01-02 00:00:00'), Timestamp('2014-01-03 00:00:00'), Timestamp('2014-01-04 00:00:00'), Timestamp('2014-01-05 00:00:00')]\n",
      "2025-03-28 20:06:30,452 [INFO] - Valores no nulos en TARGET: 4103\n",
      "2025-03-28 20:06:30,454 [INFO] - Periodo: 2014-01-01 a 2025-03-26\n",
      "2025-03-28 20:06:30,454 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:30,456 [INFO] \n",
      "Procesando: Fed_Balance_Sheet (economics)\n",
      "2025-03-28 20:06:30,456 [INFO] - Archivo: Fed_Balance_Sheet.csv\n",
      "2025-03-28 20:06:30,456 [INFO] - Columna TARGET: WALCL\n",
      "2025-03-28 20:06:30,457 [INFO] - Ruta encontrada: data/Macro/raw\\economics\\Fed_Balance_Sheet.csv\n",
      "2025-03-28 20:06:30,459 [INFO] - Filas encontradas: 586\n",
      "2025-03-28 20:06:30,461 [INFO] Detección formato: 20/20 registros ISO (ratio 1.00)\n",
      "2025-03-28 20:06:30,461 [INFO] Formato detectado para data/Macro/raw\\economics\\Fed_Balance_Sheet.csv: ISO\n",
      "2025-03-28 20:06:30,503 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-01-08 00:00:00'), Timestamp('2014-01-15 00:00:00'), Timestamp('2014-01-22 00:00:00'), Timestamp('2014-01-29 00:00:00')]\n",
      "2025-03-28 20:06:30,507 [INFO] - Valores no nulos en TARGET: 586\n",
      "2025-03-28 20:06:30,508 [INFO] - Periodo: 2014-01-01 a 2025-03-19\n",
      "2025-03-28 20:06:30,508 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:30,511 [INFO] \n",
      "Procesando: Dollar_Index_DXY (index_pricing)\n",
      "2025-03-28 20:06:30,511 [INFO] - Archivo: Dollar_Index_DXY.xlsx\n",
      "2025-03-28 20:06:30,512 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 20:06:30,512 [INFO] - Ruta encontrada: data/Macro/raw\\index_pricing\\Dollar_Index_DXY.xlsx\n",
      "2025-03-28 20:06:30,587 [INFO] - Filas encontradas: 2927\n",
      "2025-03-28 20:06:30,588 [INFO] Detección formato: 0/20 registros ISO (ratio 0.00)\n",
      "2025-03-28 20:06:30,590 [INFO] Formato detectado para data/Macro/raw\\index_pricing\\Dollar_Index_DXY.xlsx: AMBIGUOUS\n",
      "2025-03-28 20:06:30,593 [INFO] Preferencia de dayfirst para data/Macro/raw\\index_pricing\\Dollar_Index_DXY.xlsx: True (score True: 1.00, False: 1.00)\n",
      "2025-03-28 20:06:30,600 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-02 00:00:00'), Timestamp('2014-01-03 00:00:00'), Timestamp('2014-01-06 00:00:00'), Timestamp('2014-01-07 00:00:00'), Timestamp('2014-01-08 00:00:00')]\n",
      "2025-03-28 20:06:30,601 [WARNING] No se encontró 'PRICE', se usará 'Price'\n",
      "2025-03-28 20:06:30,605 [INFO] - Valores no nulos en TARGET: 2792\n",
      "2025-03-28 20:06:30,607 [INFO] - Periodo: 2014-01-02 a 2025-03-21\n",
      "2025-03-28 20:06:30,607 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:30,608 [INFO] \n",
      "Procesando: US_Unemployment_Rate (unemployment_rate)\n",
      "2025-03-28 20:06:30,610 [INFO] - Archivo: US_Unemployment_Rate.xlsx\n",
      "2025-03-28 20:06:30,611 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 20:06:30,612 [INFO] - Ruta encontrada: data/Macro/raw\\unemployment_rate\\US_Unemployment_Rate.xlsx\n",
      "2025-03-28 20:06:30,627 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:30,628 [INFO] Detección formato: 0/20 registros ISO (ratio 0.00)\n",
      "2025-03-28 20:06:30,628 [INFO] Formato detectado para data/Macro/raw\\unemployment_rate\\US_Unemployment_Rate.xlsx: AMBIGUOUS\n",
      "2025-03-28 20:06:30,634 [INFO] Preferencia de dayfirst para data/Macro/raw\\unemployment_rate\\US_Unemployment_Rate.xlsx: True (score True: 1.00, False: 1.00)\n",
      "2025-03-28 20:06:30,640 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:30,643 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:30,643 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,645 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:30,648 [INFO] \n",
      "Procesando: US_Nonfarm_Payrolls (unemployment_rate)\n",
      "2025-03-28 20:06:30,650 [INFO] - Archivo: US_Nonfarm_Payrolls.xlsx\n",
      "2025-03-28 20:06:30,651 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 20:06:30,652 [INFO] - Ruta encontrada: data/Macro/raw\\unemployment_rate\\US_Nonfarm_Payrolls.xlsx\n",
      "2025-03-28 20:06:30,665 [INFO] - Filas encontradas: 134\n",
      "2025-03-28 20:06:30,665 [INFO] Detección formato: 0/20 registros ISO (ratio 0.00)\n",
      "2025-03-28 20:06:30,666 [INFO] Formato detectado para data/Macro/raw\\unemployment_rate\\US_Nonfarm_Payrolls.xlsx: AMBIGUOUS\n",
      "2025-03-28 20:06:30,669 [INFO] Preferencia de dayfirst para data/Macro/raw\\unemployment_rate\\US_Nonfarm_Payrolls.xlsx: True (score True: 1.00, False: 1.00)\n",
      "2025-03-28 20:06:30,672 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:30,675 [INFO] - Valores no nulos en TARGET: 134\n",
      "2025-03-28 20:06:30,675 [INFO] - Periodo: 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,676 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:30,678 [INFO] \n",
      "Procesando: US_Initial_Jobless_Claims (unemployment_rate)\n",
      "2025-03-28 20:06:30,679 [INFO] - Archivo: US_Initial_Jobless_Claims.xlsx\n",
      "2025-03-28 20:06:30,681 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 20:06:30,682 [INFO] - Ruta encontrada: data/Macro/raw\\unemployment_rate\\US_Initial_Jobless_Claims.xlsx\n",
      "2025-03-28 20:06:30,701 [INFO] - Filas encontradas: 586\n",
      "2025-03-28 20:06:30,703 [INFO] Detección formato: 0/20 registros ISO (ratio 0.00)\n",
      "2025-03-28 20:06:30,704 [INFO] Formato detectado para data/Macro/raw\\unemployment_rate\\US_Initial_Jobless_Claims.xlsx: AMBIGUOUS\n",
      "2025-03-28 20:06:30,706 [INFO] Preferencia de dayfirst para data/Macro/raw\\unemployment_rate\\US_Initial_Jobless_Claims.xlsx: True (score True: 1.00, False: 1.00)\n",
      "2025-03-28 20:06:30,711 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-04 00:00:00'), Timestamp('2014-01-11 00:00:00'), Timestamp('2014-01-18 00:00:00'), Timestamp('2014-01-25 00:00:00'), Timestamp('2014-02-01 00:00:00')]\n",
      "2025-03-28 20:06:30,714 [INFO] - Valores no nulos en TARGET: 586\n",
      "2025-03-28 20:06:30,714 [INFO] - Periodo: 2014-01-04 a 2025-03-22\n",
      "2025-03-28 20:06:30,716 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:30,717 [INFO] \n",
      "Procesando: US_JOLTS (unemployment_rate)\n",
      "2025-03-28 20:06:30,719 [INFO] - Archivo: US_JOLTS.xlsx\n",
      "2025-03-28 20:06:30,719 [INFO] - Columna TARGET: PRICE\n",
      "2025-03-28 20:06:30,720 [INFO] - Ruta encontrada: data/Macro/raw\\unemployment_rate\\US_JOLTS.xlsx\n",
      "2025-03-28 20:06:30,731 [INFO] - Filas encontradas: 133\n",
      "2025-03-28 20:06:30,732 [INFO] Detección formato: 0/20 registros ISO (ratio 0.00)\n",
      "2025-03-28 20:06:30,732 [INFO] Formato detectado para data/Macro/raw\\unemployment_rate\\US_JOLTS.xlsx: AMBIGUOUS\n",
      "2025-03-28 20:06:30,734 [INFO] Preferencia de dayfirst para data/Macro/raw\\unemployment_rate\\US_JOLTS.xlsx: True (score True: 1.00, False: 1.00)\n",
      "2025-03-28 20:06:30,738 [INFO] Primeras fechas convertidas: [Timestamp('2014-01-01 00:00:00'), Timestamp('2014-02-01 00:00:00'), Timestamp('2014-03-01 00:00:00'), Timestamp('2014-04-01 00:00:00'), Timestamp('2014-05-01 00:00:00')]\n",
      "2025-03-28 20:06:30,740 [INFO] - Valores no nulos en TARGET: 133\n",
      "2025-03-28 20:06:30,743 [INFO] - Periodo: 2014-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:30,743 [INFO] - Cobertura: 100.00%\n",
      "2025-03-28 20:06:30,745 [INFO] Índice diario generado: 4103 días desde 2014-01-01 hasta 2025-03-26\n",
      "2025-03-28 20:06:30,866 [INFO] DataFrame final combinado: 4103 filas, 36 columnas\n",
      "2025-03-28 20:06:30,868 [INFO] \n",
      "Resumen de Cobertura:\n",
      "2025-03-28 20:06:30,870 [INFO] - US_10Y_Treasury: 100.00% desde 2014-01-02 a 2025-03-25\n",
      "2025-03-28 20:06:30,871 [INFO] - US_2Y_Treasury: 100.00% desde 2014-01-02 a 2025-03-25\n",
      "2025-03-28 20:06:30,871 [INFO] - Corporate_Bond_AAA_Spread: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,872 [INFO] - Corporate_Bond_BBB_Spread: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,872 [INFO] - High_Yield_Bond_Spread: 100.00% desde 2014-01-02 a 2025-03-25\n",
      "2025-03-28 20:06:30,872 [INFO] - Denmark_Car_Registrations_MoM: 100.00% desde 2014-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:30,874 [INFO] - US_Car_Registrations_MoM: 100.00% desde 2014-01-01 a 2024-12-01\n",
      "2025-03-28 20:06:30,875 [INFO] - SouthAfrica_Car_Registrations_MoM: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,875 [INFO] - United_Kingdom_Car_Registrations_MoM: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,877 [INFO] - Spain_Car_Registrations_MoM: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,877 [INFO] - US_Commercial_Loans: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,877 [INFO] - US_RealEstate_Commercial_Loans: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,878 [INFO] - US_Consumer_Credit: 100.00% desde 2014-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:30,880 [INFO] - EuroZone_Consumer_Confidence: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,881 [INFO] - Switzerland_Consumer_Confidence: 100.00% desde 2014-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:30,882 [INFO] - Michigan_Consumer_Sentiment: 100.00% desde 2015-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:30,884 [INFO] - US_CPI: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,884 [INFO] - US_Core_CPI: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,886 [INFO] - US_PCE: 100.00% desde 2014-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:30,886 [INFO] - US_Core_PCE: 100.00% desde 2014-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:30,887 [INFO] - US_PPI: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,889 [INFO] - US_Industrial_Production_MoM: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,890 [INFO] - US_CaseShiller_HomePrice: 100.00% desde 2014-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:30,892 [INFO] - US_GDP_Growth: 100.00% desde 2014-01-01 a 2024-10-01\n",
      "2025-03-28 20:06:30,892 [INFO] - US_Capacity_Utilization: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,893 [INFO] - US_Building_Permits: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,893 [INFO] - US_Housing_Starts: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,895 [INFO] - US_FedFunds_Rate: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,896 [INFO] - ECB_Deposit_Rate: 100.00% desde 2014-01-01 a 2025-03-26\n",
      "2025-03-28 20:06:30,898 [INFO] - Fed_Balance_Sheet: 100.00% desde 2014-01-01 a 2025-03-19\n",
      "2025-03-28 20:06:30,898 [INFO] - Dollar_Index_DXY: 100.00% desde 2014-01-02 a 2025-03-21\n",
      "2025-03-28 20:06:30,900 [INFO] - US_Unemployment_Rate: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,901 [INFO] - US_Nonfarm_Payrolls: 100.00% desde 2014-01-01 a 2025-02-01\n",
      "2025-03-28 20:06:30,902 [INFO] - US_Initial_Jobless_Claims: 100.00% desde 2014-01-04 a 2025-03-22\n",
      "2025-03-28 20:06:30,904 [INFO] - US_JOLTS: 100.00% desde 2014-01-01 a 2025-01-01\n",
      "2025-03-28 20:06:33,540 [INFO] Archivo guardado exitosamente: datos_economicos_procesados.xlsx\n",
      "2025-03-28 20:06:33,541 [INFO] \n",
      "Resumen de Ejecución:\n",
      "2025-03-28 20:06:33,542 [INFO] Tiempo de ejecución: 5.14 segundos\n",
      "2025-03-28 20:06:33,544 [INFO] Archivos procesados: 35\n",
      "2025-03-28 20:06:33,545 [INFO] Archivo de salida: datos_economicos_procesados.xlsx\n",
      "2025-03-28 20:06:33,547 [INFO] Estado: COMPLETADO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado exitosamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de logging\n",
    "def configurar_logging(log_file='freddataprocessor.log'):\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger('FredDataProcessor')\n",
    "\n",
    "class FredDataProcessor:\n",
    "    \"\"\"\n",
    "    Clase para procesar datos de FRED (Fuente \"FRED\" y Preprocesamiento \"Normal\").\n",
    "\n",
    "    Se espera que cada archivo tenga:\n",
    "      - Una columna de fecha llamada \"observation_date\" (o \"DATE\" si no existe).\n",
    "      - Una columna de datos cuyo nombre se especifica en el archivo de configuración (TARGET).\n",
    "\n",
    "    Esta versión:\n",
    "      - Busca el archivo usando varias extensiones: .csv, .xlsx, .xls.\n",
    "      - Detecta dinámicamente el formato de fecha analizando hasta 20 registros.\n",
    "         Si la mayoría siguen el formato ISO (YYYY-MM-DD), se fuerza ese formato;\n",
    "         de lo contrario se evalúan ambas opciones (dayfirst True/False) usando la monotonicidad.\n",
    "      - La función improved_robust_parse_date ahora maneja objetos Timestamp y valores no-string.\n",
    "      - Convierte la columna de fecha y la columna target a numérico.\n",
    "      - Renombra la columna de datos con el patrón: {TARGET}_{variable}_{Tipo_Macro}.\n",
    "      - Genera un índice diario global y usa merge_asof para imputar los datos (forward fill).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config_file, data_root='data/Macro/raw', log_file='freddataprocessor.log'):\n",
    "        self.config_file = config_file\n",
    "        self.data_root = data_root\n",
    "        self.logger = configurar_logging(log_file)\n",
    "        self.config_data = None\n",
    "        self.global_min_date = None\n",
    "        self.global_max_date = None\n",
    "        self.daily_index = None\n",
    "        self.processed_data = {}   # {variable: DataFrame procesado}\n",
    "        self.final_df = None\n",
    "        self.stats = {}\n",
    "        self.date_cache = {}  # Guarda la preferencia de formato para cada archivo\n",
    "\n",
    "        self.logger.info(\"=\" * 80)\n",
    "        self.logger.info(\"INICIANDO PROCESO: FredDataProcessor\")\n",
    "        self.logger.info(f\"Archivo de configuración: {config_file}\")\n",
    "        self.logger.info(f\"Directorio raíz de datos: {data_root}\")\n",
    "        self.logger.info(f\"Fecha y hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        self.logger.info(\"=\" * 80)\n",
    "\n",
    "    def read_config(self):\n",
    "        try:\n",
    "            self.logger.info(\"Leyendo archivo de configuración...\")\n",
    "            df_config = pd.read_excel(self.config_file)\n",
    "            self.config_data = df_config[\n",
    "                (df_config['Fuente'] == 'FRED') &\n",
    "                (df_config['Tipo de Preprocesamiento Según la Fuente'] == 'Normal')\n",
    "            ].copy()\n",
    "            self.logger.info(f\"Se encontraron {len(self.config_data)} configuraciones para procesar\")\n",
    "            return self.config_data\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al leer configuración: {e}\")\n",
    "            return None\n",
    "\n",
    "    def detect_date_format(self, series, n=20, iso_threshold=0.6):\n",
    "        \"\"\"\n",
    "        Analiza hasta n registros de la serie de fechas para determinar si la mayoría \n",
    "        siguen el formato ISO (YYYY-MM-DD).\n",
    "\n",
    "        Returns:\n",
    "            \"ISO\" si al menos iso_threshold de los registros coinciden con el patrón ISO,\n",
    "            de lo contrario \"AMBIGUOUS\".\n",
    "        \"\"\"\n",
    "        sample = series.dropna().head(n)\n",
    "        if len(sample) == 0:\n",
    "            return \"AMBIGUOUS\"\n",
    "        iso_count = 0\n",
    "        for val in sample:\n",
    "            if isinstance(val, str) and re.match(r'^\\d{4}-\\d{2}-\\d{2}$', val.strip()):\n",
    "                iso_count += 1\n",
    "        ratio = iso_count / len(sample)\n",
    "        self.logger.info(f\"Detección formato: {iso_count}/{len(sample)} registros ISO (ratio {ratio:.2f})\")\n",
    "        return \"ISO\" if ratio >= iso_threshold else \"AMBIGUOUS\"\n",
    "\n",
    "    def monotonic_score(self, parsed_series):\n",
    "        \"\"\"\n",
    "        Calcula la puntuación de monotonicidad de una serie de fechas.\n",
    "        Es la proporción de diferencias no negativas respecto al total.\n",
    "        \"\"\"\n",
    "        parsed = parsed_series.dropna()\n",
    "        if len(parsed) < 2:\n",
    "            return 0\n",
    "        diffs = parsed.diff().dropna()\n",
    "        score = (diffs >= timedelta(0)).sum() / len(diffs)\n",
    "        return score\n",
    "\n",
    "    def improved_robust_parse_date(self, date_str, preferred_dayfirst=None, use_iso=False):\n",
    "        \"\"\"\n",
    "        Convierte una cadena o timestamp de fecha.\n",
    "\n",
    "        Args:\n",
    "            date_str: Cadena de fecha o timestamp.\n",
    "            preferred_dayfirst (bool, opcional): Preferencia para la conversión.\n",
    "            use_iso (bool): Si se debe forzar el formato ISO (YYYY-MM-DD).\n",
    "\n",
    "        Returns:\n",
    "            pd.Timestamp o None.\n",
    "        \"\"\"\n",
    "        # Si ya es un timestamp, devolverlo directamente\n",
    "        if isinstance(date_str, pd.Timestamp):\n",
    "            return date_str\n",
    "\n",
    "        if not isinstance(date_str, str):\n",
    "            self.logger.debug(f\"Valor no string en fecha: {date_str} (tipo: {type(date_str)})\")\n",
    "            return None\n",
    "\n",
    "        date_str = date_str.strip()\n",
    "        if not date_str:\n",
    "            return None\n",
    "\n",
    "        if use_iso:\n",
    "            try:\n",
    "                return pd.to_datetime(date_str, format='%Y-%m-%d', errors='coerce')\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Error al convertir formato ISO en '{date_str}': {e}\")\n",
    "                return None\n",
    "\n",
    "        # Intentar patrón \"Apr 01, 2025 (Mar)\"\n",
    "        m = re.search(r'([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})', date_str)\n",
    "        if m:\n",
    "            candidate = m.group(1)\n",
    "            try:\n",
    "                parsed = pd.to_datetime(candidate, errors='coerce')\n",
    "                if pd.notnull(parsed):\n",
    "                    return parsed\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Error al parsear patrón en '{date_str}': {e}\")\n",
    "\n",
    "        if preferred_dayfirst is not None:\n",
    "            try:\n",
    "                return pd.to_datetime(date_str, dayfirst=preferred_dayfirst, errors='coerce')\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Error con dayfirst={preferred_dayfirst} en '{date_str}': {e}\")\n",
    "\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, dayfirst=True, errors='coerce')\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Error en improved_robust_parse_date para '{date_str}': {e}\")\n",
    "            return None\n",
    "\n",
    "    def process_file(self, config_row):\n",
    "        \"\"\"\n",
    "        Procesa un archivo individual de FRED.\n",
    "        \n",
    "        - Busca el archivo usando extensiones: .csv, .xlsx, .xls.\n",
    "        - Usa la columna de fecha \"observation_date\" (o \"DATE\").\n",
    "        - Analiza hasta 20 registros para determinar el formato de fecha.\n",
    "        - Convierte la columna de fecha y la columna target a numérico.\n",
    "        - Renombra la columna de datos con el patrón: {TARGET}_{variable}_{Tipo_Macro}.\n",
    "        - Devuelve un DataFrame con columnas ['fecha', nuevo_nombre].\n",
    "        \"\"\"\n",
    "        variable = config_row['Variable']\n",
    "        macro_type = config_row['Tipo Macro']\n",
    "        target_col = config_row['TARGET']\n",
    "\n",
    "        # Lista de extensiones a buscar\n",
    "        extensions = ['.csv', '.xlsx', '.xls']\n",
    "        ruta = None\n",
    "        for ext in extensions:\n",
    "            ruta_candidate = os.path.join(self.data_root, macro_type, f\"{variable}{ext}\")\n",
    "            if os.path.exists(ruta_candidate):\n",
    "                ruta = ruta_candidate\n",
    "                break\n",
    "        if ruta is None:\n",
    "            for ext in extensions:\n",
    "                for root, dirs, files in os.walk(self.data_root):\n",
    "                    if f\"{variable}{ext}\" in files:\n",
    "                        ruta = os.path.join(root, f\"{variable}{ext}\")\n",
    "                        break\n",
    "                if ruta is not None:\n",
    "                    break\n",
    "        if ruta is None:\n",
    "            self.logger.error(f\"Archivo no encontrado: {variable}* (se probaron extensiones: {', '.join(extensions)})\")\n",
    "            return variable, None\n",
    "\n",
    "        self.logger.info(f\"\\nProcesando: {variable} ({macro_type})\")\n",
    "        self.logger.info(f\"- Archivo: {os.path.basename(ruta)}\")\n",
    "        self.logger.info(f\"- Columna TARGET: {target_col}\")\n",
    "        self.logger.info(f\"- Ruta encontrada: {ruta}\")\n",
    "\n",
    "        try:\n",
    "            if ruta.endswith('.csv'):\n",
    "                df = pd.read_csv(ruta)\n",
    "            elif ruta.endswith(('.xlsx', '.xls')):\n",
    "                df = pd.read_excel(ruta)\n",
    "            else:\n",
    "                self.logger.error(f\"Extensión no soportada para {ruta}\")\n",
    "                return variable, None\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al leer {ruta}: {e}\")\n",
    "            return variable, None\n",
    "\n",
    "        self.logger.info(f\"- Filas encontradas: {len(df)}\")\n",
    "        # Determinar la columna de fecha: preferir \"observation_date\", sino \"DATE\"\n",
    "        if 'observation_date' in df.columns:\n",
    "            date_col = 'observation_date'\n",
    "        elif 'DATE' in df.columns:\n",
    "            date_col = 'DATE'\n",
    "        else:\n",
    "            self.logger.error(f\"No se encontró columna de fecha ('observation_date' o 'DATE') en {ruta}\")\n",
    "            return variable, None\n",
    "\n",
    "        # Detectar el formato de fecha a partir de 20 registros\n",
    "        fmt = self.detect_date_format(df[date_col], n=20, iso_threshold=0.6)\n",
    "        use_iso = (fmt == \"ISO\")\n",
    "        self.logger.info(f\"Formato detectado para {ruta}: {fmt}\")\n",
    "\n",
    "        # Si el formato no es ISO, determinar la preferencia de dayfirst usando la monotonicidad\n",
    "        if not use_iso:\n",
    "            sample = df[date_col].dropna().head(20)\n",
    "            parsed_true = pd.to_datetime(sample, dayfirst=True, errors='coerce')\n",
    "            parsed_false = pd.to_datetime(sample, dayfirst=False, errors='coerce')\n",
    "            score_true = self.monotonic_score(parsed_true)\n",
    "            score_false = self.monotonic_score(parsed_false)\n",
    "            preferred = score_true >= score_false\n",
    "            self.date_cache[ruta] = preferred\n",
    "            self.logger.info(f\"Preferencia de dayfirst para {ruta}: {preferred} (score True: {score_true:.2f}, False: {score_false:.2f})\")\n",
    "        else:\n",
    "            preferred = None\n",
    "\n",
    "        # Convertir la columna de fecha usando improved_robust_parse_date\n",
    "        df['fecha'] = df[date_col].apply(lambda x: self.improved_robust_parse_date(x, preferred_dayfirst=preferred, use_iso=use_iso))\n",
    "        df = df.dropna(subset=['fecha'])\n",
    "        df = df.sort_values('fecha')\n",
    "        self.logger.info(f\"Primeras fechas convertidas: {df['fecha'].head(5).tolist()}\")\n",
    "\n",
    "        # Verificar la columna target usando búsqueda insensible a mayúsculas\n",
    "        if target_col not in df.columns:\n",
    "            for col in df.columns:\n",
    "                if col.strip().lower() == target_col.strip().lower():\n",
    "                    target_col = col\n",
    "                    self.logger.warning(f\"No se encontró '{config_row['TARGET']}', se usará '{target_col}'\")\n",
    "                    break\n",
    "        if target_col not in df.columns:\n",
    "            self.logger.error(f\"No se encontró columna TARGET ni alternativa en {ruta}\")\n",
    "            return variable, None\n",
    "\n",
    "        df['valor'] = pd.to_numeric(df[target_col], errors='coerce')\n",
    "        df = df.dropna(subset=['valor'])\n",
    "        if df.empty:\n",
    "            self.logger.error(f\"No se encontraron valores válidos para '{target_col}' en {ruta}\")\n",
    "            return variable, None\n",
    "\n",
    "        current_min = df['fecha'].min()\n",
    "        current_max = df['fecha'].max()\n",
    "        if self.global_min_date is None or current_min < self.global_min_date:\n",
    "            self.global_min_date = current_min\n",
    "        if self.global_max_date is None or current_max > self.global_max_date:\n",
    "            self.global_max_date = current_max\n",
    "\n",
    "        # Renombrar la columna de datos usando el patrón\n",
    "        nuevo_nombre = f\"{target_col}_{variable}_{macro_type}\"\n",
    "        df.rename(columns={'valor': nuevo_nombre}, inplace=True)\n",
    "        self.stats[variable] = {\n",
    "            'macro_type': macro_type,\n",
    "            'target_column': target_col,\n",
    "            'total_rows': len(df),\n",
    "            'valid_values': len(df),\n",
    "            'coverage': 100.0,\n",
    "            'date_min': current_min,\n",
    "            'date_max': current_max,\n",
    "            'nuevo_nombre': nuevo_nombre\n",
    "        }\n",
    "        self.logger.info(f\"- Valores no nulos en TARGET: {len(df)}\")\n",
    "        self.logger.info(f\"- Periodo: {current_min.strftime('%Y-%m-%d')} a {current_max.strftime('%Y-%m-%d')}\")\n",
    "        self.logger.info(f\"- Cobertura: 100.00%\")\n",
    "        return variable, df[['fecha', nuevo_nombre]].copy()\n",
    "\n",
    "    def generate_daily_index(self):\n",
    "        \"\"\"\n",
    "        Genera un índice diario desde la fecha global mínima hasta la máxima.\n",
    "        \"\"\"\n",
    "        if self.global_min_date is None or self.global_max_date is None:\n",
    "            self.logger.error(\"No se pudieron determinar las fechas globales\")\n",
    "            return None\n",
    "        self.daily_index = pd.DataFrame({\n",
    "            'fecha': pd.date_range(start=self.global_min_date, end=self.global_max_date, freq='D')\n",
    "        })\n",
    "        self.logger.info(f\"Índice diario generado: {len(self.daily_index)} días desde {self.global_min_date.strftime('%Y-%m-%d')} hasta {self.global_max_date.strftime('%Y-%m-%d')}\")\n",
    "        return self.daily_index\n",
    "\n",
    "    def combine_data(self):\n",
    "        \"\"\"\n",
    "        Convierte cada serie (diaria o de menor frecuencia) a datos diarios usando merge_asof.\n",
    "        Cada día se asocia al valor reportado más reciente (forward fill).\n",
    "        \"\"\"\n",
    "        if self.daily_index is None:\n",
    "            self.logger.error(\"El índice diario no ha sido generado\")\n",
    "            return None\n",
    "\n",
    "        combined = self.daily_index.copy()\n",
    "        for variable, df in self.processed_data.items():\n",
    "            if df is None or df.empty:\n",
    "                self.logger.warning(f\"Omitiendo {variable} por falta de datos\")\n",
    "                continue\n",
    "            df = df.sort_values('fecha')\n",
    "            df_daily = pd.merge_asof(combined, df, on='fecha', direction='backward')\n",
    "            col_name = self.stats[variable]['nuevo_nombre']\n",
    "            df_daily[col_name] = df_daily[col_name].ffill()\n",
    "            combined = combined.merge(df_daily[['fecha', col_name]], on='fecha', how='left')\n",
    "        self.final_df = combined\n",
    "        self.logger.info(f\"DataFrame final combinado: {len(self.final_df)} filas, {len(self.final_df.columns)} columnas\")\n",
    "        return self.final_df\n",
    "\n",
    "    def analyze_coverage(self):\n",
    "        \"\"\"\n",
    "        Genera un resumen de cobertura y estadísticas para cada variable.\n",
    "        \"\"\"\n",
    "        total_days = len(self.daily_index)\n",
    "        self.logger.info(\"\\nResumen de Cobertura:\")\n",
    "        for variable, stats in self.stats.items():\n",
    "            self.logger.info(f\"- {variable}: {stats['coverage']:.2f}% desde {stats['date_min'].strftime('%Y-%m-%d')} a {stats['date_max'].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    def save_results(self, output_file='datos_economicos_procesados.xlsx'):\n",
    "        \"\"\"\n",
    "        Guarda el DataFrame final combinado y las estadísticas en un archivo Excel.\n",
    "        \"\"\"\n",
    "        if self.final_df is None:\n",
    "            self.logger.error(\"No hay datos combinados para guardar\")\n",
    "            return False\n",
    "        try:\n",
    "            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "                self.final_df.to_excel(writer, sheet_name='Datos Diarios', index=False)\n",
    "                df_stats = pd.DataFrame(self.stats).T\n",
    "                df_stats.to_excel(writer, sheet_name='Estadisticas')\n",
    "                meta = {\n",
    "                    'Proceso': ['FredDataProcessor'],\n",
    "                    'Fecha de proceso': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                    'Total indicadores': [len(self.stats)],\n",
    "                    'Periodo': [f\"{self.global_min_date.strftime('%Y-%m-%d')} a {self.global_max_date.strftime('%Y-%m-%d')}\"],\n",
    "                    'Total días': [len(self.daily_index)]\n",
    "                }\n",
    "                pd.DataFrame(meta).to_excel(writer, sheet_name='Metadatos', index=False)\n",
    "            self.logger.info(f\"Archivo guardado exitosamente: {output_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al guardar resultados: {e}\")\n",
    "            return False\n",
    "\n",
    "    def run(self, output_file='datos_economicos_procesados.xlsx'):\n",
    "        \"\"\"\n",
    "        Ejecuta el proceso completo:\n",
    "          1. Lee la configuración.\n",
    "          2. Procesa cada archivo de FRED (buscando las extensiones adecuadas).\n",
    "          3. Genera el índice diario global.\n",
    "          4. Convierte cada serie a datos diarios y las combina.\n",
    "          5. Analiza la cobertura.\n",
    "          6. Guarda los resultados.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        if self.read_config() is None:\n",
    "            return False\n",
    "\n",
    "        for _, config_row in self.config_data.iterrows():\n",
    "            var, df_processed = self.process_file(config_row)\n",
    "            self.processed_data[var] = df_processed\n",
    "\n",
    "        if len([df for df in self.processed_data.values() if df is not None]) == 0:\n",
    "            self.logger.error(\"No se procesó ningún archivo correctamente\")\n",
    "            return False\n",
    "\n",
    "        self.generate_daily_index()\n",
    "        self.combine_data()\n",
    "        self.analyze_coverage()\n",
    "        result = self.save_results(output_file)\n",
    "        end_time = time.time()\n",
    "        self.logger.info(\"\\nResumen de Ejecución:\")\n",
    "        self.logger.info(f\"Tiempo de ejecución: {end_time - start_time:.2f} segundos\")\n",
    "        self.logger.info(f\"Archivos procesados: {len(self.config_data)}\")\n",
    "        self.logger.info(f\"Archivo de salida: {output_file}\")\n",
    "        self.logger.info(f\"Estado: {'COMPLETADO' if result else 'ERROR'}\")\n",
    "        return result\n",
    "\n",
    "# Función principal para ejecutar el proceso\n",
    "def run_fred_data_processor(config_file='Data Engineering.xlsx',\n",
    "                            output_file='datos_economicos_procesados.xlsx',\n",
    "                            data_root='data/Macro/raw',\n",
    "                            log_file='freddataprocessor.log'):\n",
    "    processor = FredDataProcessor(config_file, data_root, log_file)\n",
    "    return processor.run(output_file)\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    success = run_fred_data_processor()\n",
    "    print(f\"Proceso {'completado exitosamente' if success else 'finalizado con errores'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
