# ğŸ“Š SP500 Index Analysis - Data Transformation Pipeline

Este proyecto aplica una serie de transformaciones modulares y secuenciales sobre datos macroeconÃ³micos para generar datasets entrenables para modelos predictivos, orientados al anÃ¡lisis del Ã­ndice S&P500.

El proceso estÃ¡ completamente orquestado por el archivo `run_pipeline.py` que ejecuta paso a paso cada transformaciÃ³n desde la carpeta `pipelines/`.

---

## ğŸ“ Estructura del Proyecto

```
SP500_index_analysis/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/           # Datos crudos originales
â”‚   â”œâ”€â”€ processed/     # Datos transformados intermedios
â”‚   â””â”€â”€ final/         # Datos finales listos para entrenamiento
â”‚
â”œâ”€â”€ models/            # Modelos entrenados (.pkl)
â”œâ”€â”€ pipelines/         # Scripts de procesamiento por paso
â”œâ”€â”€ logs/              # Logs de ejecuciÃ³n
â”œâ”€â”€ outputs/           # Predicciones listas para visualizaciÃ³n (ej. Power BI)
â”œâ”€â”€ notebooks/         # Jupyter notebooks exploratorios
â”œâ”€â”€ run_pipeline.py    # Orquestador principal del pipeline
â”œâ”€â”€ .gitignore         # ExclusiÃ³n de archivos sensibles
â””â”€â”€ requirements.txt   # Dependencias del proyecto
```

---

## â–¶ï¸ EjecuciÃ³n del pipeline

```bash
python run_pipeline.py
```

---

## ğŸ§© DescripciÃ³n de cada paso

### ğŸŸ£ Paso 0 - Preprocesamiento Inicial
**Script:** `pipelines/step_0_preprocess.py`  
- Limpia estructuras base y normaliza nombres y fechas.  
- **Input:** Archivos `.xlsx` o `.csv` de `data/raw/`  
- **Output:** Archivos estandarizados a `data/processed/`

---

### ğŸ”µ Paso 1 - UniÃ³n de Archivos
**Script:** `pipelines/step_1_merge_excels.py`  
- Une mÃºltiples archivos Excel en uno solo.  
- **Input:** Archivos macroeconÃ³micos  
- **Output:** `MERGEDEXCELS.xlsx`

---

### ğŸ”µ Paso 2 - GeneraciÃ³n de CategorÃ­as
**Script:** `pipelines/step_2_generate_categories.py`  
- Clasifica columnas en categorÃ­as econÃ³micas.  
- **Output:** `MERGEDEXCELS_CATEGORIZADO.xlsx`

---

### ğŸ”µ Paso 3 - Limpieza de Nombres de Columnas
**Script:** `pipelines/step_3_clean_columns.py`  
- Elimina redundancias y mejora la trazabilidad de variables.  
- **Output:** `MERGEDEXCELS_CATEGORIZADO_LIMPIO.xlsx`

---

### ğŸŸ  Paso 4 - Transformaciones e Indicadores
**Script:** `pipelines/step_4_transform_features.py`  
- Aplica indicadores tÃ©cnicos como:
  - MoM, YoY, medias mÃ³viles, z-score, log-retornos, RSI, Bollinger Bands.  
- **Output:** Datos enriquecidos por categorÃ­a.

---

### ğŸŸ  Paso 5 - EliminaciÃ³n de Relaciones Redundantes
**Script:** `pipelines/step_5_remove_relations.py`  
- Elimina multicolinealidad con VIF, y variables con alta correlaciÃ³n o baja varianza.  
- **Output:** Dataset reducido.

---

### ğŸŸ¡ Paso 6 - SelecciÃ³n de Variables Relevantes (FPI)
**Script:** `pipelines/step_6_fpi_selection.py`  
- Selecciona variables clave usando Feature Permutation Importance con CatBoost y validaciÃ³n temporal.  
- **Output:** `EUR_final_FPI.xlsx`

---

### ğŸŸ¢ Paso 7 - Entrenamiento de Modelos
**Script:** `pipelines/step_7_train_models.py`  
- Entrena y optimiza modelos CatBoost, LightGBM, XGBoost, MLP, SVM con Optuna.  
- **Output:**  
  - Modelos `.pkl` en `models/`  
  - Predicciones en `data/final/all_models_predictions.csv`

---

### ğŸŸ¢ Paso 8 - PreparaciÃ³n de Resultados para Dashboard
**Script:** `pipelines/step_8_prepare_output.py`  
- Convierte los resultados a formato `.csv` compatible con Power BI (formato espaÃ±ol).  
- **Output:** `outputs/archivo_para_powerbi.csv`

---

## ğŸ›¡ï¸ Seguridad y control de versiones

- Variables sensibles estÃ¡n definidas en `.env` (excluido con `.gitignore`)
- Los datos, modelos y logs estÃ¡n excluidos del versionado
- Usa ramas `feature/` o `refactor/` para nuevas funcionalidades

---

## âš™ï¸ Requisitos

```bash
pip install -r requirements.txt
```

---

## ğŸ§  Autor

Proyecto desarrollado por Stiven para anÃ¡lisis avanzado del Ã­ndice S&P500 usando datos macroeconÃ³micos estructurados y modelado basado en aprendizaje automÃ¡tico.
