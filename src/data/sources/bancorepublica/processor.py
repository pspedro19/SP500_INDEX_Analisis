import os
import re
import time
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import warnings
from src.core.utils import configure_logging, convertir_valor, detectar_formato_fecha_inteligente, convertir_fecha_adaptativo

class BancoRepublicaProcessor:
    """
    ü§ñ PROCESADOR AUTOM√ÅTICO para archivos del Banco de la Rep√∫blica
    INTEGRADO directamente en step_0_preprocess.py
    
    ‚úÖ COMPLETAMENTE AUTOM√ÅTICO: Detecta y procesa cualquier archivo Excel del Banco Rep√∫blica
    ‚úÖ BUSCA EN SUBCARPETAS: Recorre todas las carpetas categorizadas autom√°ticamente
    ‚úÖ FORMATO COLOMBIANO: Maneja dd/mm/aaaa y comas como decimales
    ‚úÖ INTEGRACI√ìN TOTAL: Mismo patr√≥n que los otros procesadores del sistema
    """
    
    def __init__(self, data_root='data/0_raw', log_file='logs/banco_republica.log'):
        self.data_root = data_root
        self.logger = configurar_logging(log_file)
        self.global_min_date = None
        self.global_max_date = None
        self.daily_index = None
        self.processed_data = {}
        self.final_df = None
        self.stats = {}
        self.discovered_files = []
        
        self.logger.info("=" * 80)
        self.logger.info("ü§ñ BANCO REP√öBLICA PROCESSOR - AUTOM√ÅTICO (INTEGRADO)")
        self.logger.info(f"Directorio de datos: {data_root}")
        self.logger.info(f"Fecha y hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info("=" * 80)

    def detect_banco_republica_file(self, file_path):
        """üîç DETECCI√ìN AUTOM√ÅTICA: ¬øEs un archivo del Banco Rep√∫blica?"""
        try:
            df = pd.read_excel(file_path, sheet_name=0, header=None, nrows=10)
            indicators = 0
            
            # 1. Primera columna contiene "Fecha"
            if 'fecha' in str(df.iloc[0, 0]).lower():
                indicators += 2
                
            # 2. Formato t√≠pico dd/mm/aaaa
            if 'dd/mm/aaaa' in str(df.iloc[1, 0]):
                indicators += 3
                
            # 3. Datos con formato colombiano (comas)
            sample_value = str(df.iloc[2, 1]) if len(df.columns) > 1 else ""
            if ',' in sample_value and any(c.isdigit() for c in sample_value):
                indicators += 2
                
            # 4. Pie de p√°gina "Descargado de sistema del Banco..."
            try:
                bottom_df = pd.read_excel(file_path, sheet_name=0, header=None, skiprows=max(0, len(df)-5))
                for _, row in bottom_df.iterrows():
                    if any('descargado' in str(cell).lower() for cell in row if pd.notna(cell)):
                        indicators += 3
                        break
            except:
                pass
            
            return indicators >= 5
            
        except Exception:
            return False

    def auto_discover_files(self):
        """üîç DESCUBRIMIENTO AUTOM√ÅTICO en todas las subcarpetas categorizadas"""
        self.logger.info("üîç Buscando archivos del Banco de la Rep√∫blica en subcarpetas...")
        
        discovered = []
        
        # Buscar recursivamente en TODAS las subcarpetas
        for root, dirs, files in os.walk(self.data_root):
            for file in files:
                if file.endswith(('.xlsx', '.xls')) and not file.startswith('~'):
                    file_path = os.path.join(root, file)
                    
                    if self.detect_banco_republica_file(file_path):
                        variable_name = Path(file).stem
                        target_col, macro_type = self.extract_file_info(file_path)
                        
                        discovered.append({
                            'Variable': variable_name,
                            'Archivo': file_path,
                            'TARGET': target_col,
                            'Tipo_Macro': macro_type,
                            'Carpeta': os.path.basename(os.path.dirname(file_path))
                        })
        
        self.discovered_files = discovered
        self.logger.info(f"‚úÖ Encontrados {len(discovered)} archivos del Banco Rep√∫blica:")
        
        for file_info in discovered:
            self.logger.info(f"   üìÅ {file_info['Carpeta']}/{file_info['Variable']} ‚Üí {file_info['Tipo_Macro']}")
        
        return discovered

    def extract_file_info(self, file_path):
        """üìä EXTRACCI√ìN AUTOM√ÅTICA usando carpeta + contenido"""
        try:
            df = pd.read_excel(file_path, sheet_name=0, header=None, nrows=3)
            target_col = str(df.iloc[0, 1]) if len(df.columns) > 1 else "valor"
            
            # Usar nombre de carpeta como clasificador principal
            folder_name = os.path.basename(os.path.dirname(file_path)).lower()
            
            folder_to_macro = {
                'bond': 'bond',
                'business_confidence': 'business_confidence', 
                'car_registrations': 'car_registrations',
                'comm_loans': 'comm_loans',
                'commodities': 'commodities',
                'consumer_confidence': 'consumer_confidence',
                'economics': 'economics',
                'exchange_rate': 'exchange_rate',
                'exports': 'exports',
                'index_pricing': 'index_pricing',
                'leading_economic_index': 'leading_economic_index',
                'unemployment_rate': 'unemployment_rate'
            }
            
            if folder_name in folder_to_macro:
                macro_type = folder_to_macro[folder_name]
            else:
                # Fallback: clasificaci√≥n por contenido
                header_text = target_col.lower()
                if any(term in header_text for term in ['colcap', '√≠ndice', 'burs√°til']):
                    macro_type = 'index_pricing'
                elif any(term in header_text for term in ['tasa de cambio', 'itcr']):
                    macro_type = 'exchange_rate'
                elif any(term in header_text for term in ['reservas', 'internacional']):
                    macro_type = 'exchange_rate'
                elif any(term in header_text for term in ['balanza', 'cuenta', 'inversi√≥n']):
                    macro_type = 'economics'
                else:
                    macro_type = 'economics'
                
            return target_col, macro_type
            
        except Exception:
            return "valor", "economics"

    def convert_colombian_date(self, date_str):
        """üìÖ Conversi√≥n de fechas formato colombiano"""
        if pd.isna(date_str) or not isinstance(date_str, str):
            return None
        try:
            return pd.to_datetime(date_str, format='%d/%m/%Y', dayfirst=True)
        except:
            try:
                return pd.to_datetime(date_str, dayfirst=True)
            except:
                return None

    def convert_colombian_number(self, value_str):
        """üí∞ Conversi√≥n de n√∫meros formato colombiano"""
        if pd.isna(value_str):
            return None
        if isinstance(value_str, (int, float)):
            return float(value_str)
        if not isinstance(value_str, str):
            return None
            
        value_str = str(value_str).strip()
        if value_str in ['-', '', 'N/A', 'n/a']:
            return None
            
        try:
            # Formato colombiano: 1.234.567,89 ‚Üí 1234567.89
            if '.' in value_str and ',' in value_str:
                value_str = value_str.replace('.', '').replace(',', '.')
            elif ',' in value_str and '.' not in value_str:
                value_str = value_str.replace(',', '.')
            elif '.' in value_str and ',' not in value_str:
                if value_str.count('.') == 1 and len(value_str.split('.')[1]) <= 2:
                    pass  # Es decimal
                else:
                    value_str = value_str.replace('.', '')  # Separador de miles
            return float(value_str)
        except (ValueError, TypeError):
            return None

    def process_file_automatically(self, file_info):
        """‚ö° Procesamiento autom√°tico de un archivo"""
        variable = file_info['Variable']
        target_col = file_info['TARGET']
        macro_type = file_info['Tipo_Macro']
        file_path = file_info['Archivo']
        
        self.logger.info(f"\nüìä Procesando: {variable}")
        self.logger.info(f"   üìÅ Carpeta: {file_info['Carpeta']}")
        self.logger.info(f"   üéØ TARGET: {target_col}")
        self.logger.info(f"   üìÇ Tipo: {macro_type}")
        
        try:
            df = pd.read_excel(file_path, sheet_name=0, header=None)
            
            # Saltar headers y limpiar datos
            data_rows = df.iloc[2:].copy()
            data_rows = data_rows.dropna(subset=[0])
            data_rows = data_rows[~data_rows[0].astype(str).str.contains('Descargado|descargado', na=False)]
            
            if len(data_rows) == 0:
                self.logger.error(f"‚ùå No hay datos v√°lidos en {variable}")
                return variable, None
            
            # Procesamiento autom√°tico: fecha (A) + valor (B)
            result_df = pd.DataFrame()
            result_df['fecha'] = data_rows[0].apply(self.convert_colombian_date)
            result_df = result_df.dropna(subset=['fecha'])
            
            if len(data_rows.columns) > 1:
                # Nombre estandarizado compatible con sistema principal
                clean_name = re.sub(r'[^\w\s]', '', target_col).replace(' ', '_')[:50]
                nuevo_nombre = f"{clean_name}_{variable}_{macro_type}"
                
                result_df[nuevo_nombre] = data_rows[1].apply(self.convert_colombian_number)
                result_df = result_df.dropna(subset=[nuevo_nombre])
            
            result_df = result_df.sort_values('fecha')
            
            if len(result_df) == 0:
                self.logger.error(f"‚ùå Sin valores v√°lidos: {variable}")
                return variable, None
            
            # Actualizar fechas globales
            current_min = result_df['fecha'].min()
            current_max = result_df['fecha'].max()
            
            if self.global_min_date is None or current_min < self.global_min_date:
                self.global_min_date = current_min
            if self.global_max_date is None or current_max > self.global_max_date:
                self.global_max_date = current_max
            
            # Estad√≠sticas (formato compatible)
            self.stats[variable] = {
                'macro_type': macro_type,
                'target_column': target_col,
                'total_rows': len(result_df),
                'valid_values': result_df.iloc[:, 1].notna().sum(),
                'coverage': 100.0,
                'date_min': current_min,
                'date_max': current_max,
                'nuevo_nombre': nuevo_nombre
            }
            
            self.logger.info(f"   ‚úÖ {len(result_df)} valores v√°lidos")
            self.logger.info(f"   üìÖ {current_min.strftime('%Y-%m-%d')} a {current_max.strftime('%Y-%m-%d')}")
            
            return variable, result_df
            
        except Exception as e:
            self.logger.error(f"‚ùå Error procesando {variable}: {str(e)}")
            return variable, None

    def generate_daily_index(self):
        """üìÖ Generar √≠ndice diario"""
        if self.global_min_date is None or self.global_max_date is None:
            self.logger.error("‚ùå No se pudieron determinar fechas globales")
            return None
            
        self.daily_index = pd.DataFrame({
            'fecha': pd.date_range(start=self.global_min_date, end=self.global_max_date, freq='D')
        })
        
        self.logger.info(f"üìÖ √çndice diario: {len(self.daily_index)} d√≠as")
        return self.daily_index

    def combine_data(self):
        """üîó Combinar datos con merge_asof"""
        if self.daily_index is None:
            return None
            
        combined = self.daily_index.copy()
        
        for variable, df in self.processed_data.items():
            if df is None or df.empty:
                continue
                
            df = df.sort_values('fecha')
            df_daily = pd.merge_asof(combined, df, on='fecha', direction='backward')
            col_name = self.stats[variable]['nuevo_nombre']
            df_daily[col_name] = df_daily[col_name].ffill()
            combined = combined.merge(df_daily[['fecha', col_name]], on='fecha', how='left')
                                   
        self.final_df = combined
        self.logger.info(f"üîó Datos combinados: {len(self.final_df)} filas, {len(self.final_df.columns)} columnas")
        return self.final_df

    def save_results(self, output_file):
        """üíæ Guardar resultados"""
        if self.final_df is None:
            self.logger.error("‚ùå No hay datos para guardar")
            return False
            
        try:
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                self.final_df.to_excel(writer, sheet_name='Datos Diarios', index=False)
                df_stats = pd.DataFrame(self.stats).T
                df_stats.to_excel(writer, sheet_name='Estadisticas')
                
                meta = {
                    'Proceso': ['BancoRepublicaProcessor'],
                    'Fecha de proceso': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],
                    'Total indicadores': [len(self.stats)],
                    'Periodo': [f"{self.global_min_date.strftime('%Y-%m-%d')} a {self.global_max_date.strftime('%Y-%m-%d')}"],
                    'Total d√≠as': [len(self.daily_index)]
                }
                pd.DataFrame(meta).to_excel(writer, sheet_name='Metadatos', index=False)
                
            self.logger.info(f"üíæ Archivo guardado: {output_file}")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Error guardando: {str(e)}")
            return False

    def run(self, output_file):
        """üöÄ Ejecutar proceso completo"""
        start_time = time.time()
        
        if not self.auto_discover_files():
            self.logger.error("‚ùå No se encontraron archivos del Banco Rep√∫blica")
            return False
        
        for file_info in self.discovered_files:
            var, df_processed = self.process_file_automatically(file_info)
            self.processed_data[var] = df_processed
        
        successful = len([df for df in self.processed_data.values() if df is not None])
        if successful == 0:
            self.logger.error("‚ùå No se proces√≥ ning√∫n archivo correctamente")
            return False
        
        self.generate_daily_index()
        self.combine_data()
        result = self.save_results(output_file)
        
        end_time = time.time()
        self.logger.info(f"\n‚è±Ô∏è  Tiempo: {end_time - start_time:.2f} segundos")
        self.logger.info(f"‚úÖ Archivos procesados: {successful}")
        self.logger.info(f"üéØ Estado: {'COMPLETADO' if result else 'ERROR'}")
        
        return result

# FUNCI√ìN INTEGRADA para usar como las otras
def ejecutar_banco_republica_processor(
    config_file=os.path.join(PROJECT_ROOT, 'pipelines/Data Engineering.xlsx'),
    output_file=os.path.join(PROJECT_ROOT, 'data/0_raw/datos_banco_republica_procesados.xlsx'),
    data_root=os.path.join(PROJECT_ROOT, 'data/0_raw'),
    log_file=os.path.join(PROJECT_ROOT, 'logs/banco_republica.log')
):
    """
    ü§ñ PROCESADOR DEL BANCO REP√öBLICA - INTEGRADO
    Funci√≥n que sigue el mismo patr√≥n que las otras del sistema
    
    ‚úÖ Busca autom√°ticamente en todas las subcarpetas categorizadas
    ‚úÖ Detecta y procesa archivos del Banco Rep√∫blica autom√°ticamente
    ‚úÖ Genera Excel independiente con misma estructura que los otros
    """
    processor = BancoRepublicaProcessor(data_root, log_file)
    return processor.run(output_file)

# FUNCI√ìN PARA EJECUTAR TODOS LOS PROCESADORES (incluyendo Banco Rep√∫blica)
def ejecutar_todos_los_procesadores():
    """
    üöÄ Ejecuta TODOS los procesadores del sistema:
    1. MyInvesting Copy-Paste
    2. MyInvesting Normal  
    3. FRED Data
    4. Other Data
    5. üÜï Banco Rep√∫blica (AUTOM√ÅTICO)
    
    Mantiene los 5 Excel separados como est√° originalmente
    """
    print("üöÄ Ejecutando TODOS los procesadores de datos econ√≥micos...")
    print("=" * 70)
    
    resultados = {}
    
    # 1. MyInvesting Copy-Paste
    print("\n1Ô∏è‚É£ MyInvesting Copy-Paste...")
    try:
        success1 = run_economic_data_processor()
        resultados['MyInvesting CP'] = success1
        print("‚úÖ Completado" if success1 else "‚ùå Error")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        resultados['MyInvesting CP'] = False
    
    # 2. MyInvesting Normal
    print("\n2Ô∏è‚É£ MyInvesting Normal...")
    try:
        success2 = ejecutar_myinvestingreportnormal()
        resultados['MyInvesting Normal'] = success2
        print("‚úÖ Completado" if success2 else "‚ùå Error")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        resultados['MyInvesting Normal'] = False
    
    # 3. FRED Data
    print("\n3Ô∏è‚É£ FRED Data...")
    try:
        success3 = run_fred_data_processor()
        resultados['FRED'] = success3
        print("‚úÖ Completado" if success3 else "‚ùå Error")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        resultados['FRED'] = False
    
    # 4. Other Data
    print("\n4Ô∏è‚É£ Other Data...")
    try:
        success4 = ejecutar_otherdataprocessor()
        resultados['Other'] = success4
        print("‚úÖ Completado" if success4 else "‚ùå Error")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        resultados['Other'] = False
    
    # 5. üÜï Banco Rep√∫blica
    print("\n5Ô∏è‚É£ üÜï Banco Rep√∫blica (AUTOM√ÅTICO)...")
    try:
        success5 = ejecutar_banco_republica_processor()
        resultados['Banco Rep√∫blica'] = success5
        print("‚úÖ Completado" if success5 else "‚ùå Error")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        resultados['Banco Rep√∫blica'] = False
    
    # Resumen final
    print("\n" + "=" * 70)
    print("üìä RESUMEN FINAL")
    print("=" * 70)
    
    exitosos = sum(resultados.values())
    total = len(resultados)
    
    print(f"üìà Procesadores exitosos: {exitosos}/{total}")
    print(f"\nüìÅ Archivos generados:")
    
    archivos_esperados = [
        "datos_economicos_procesados_cp.xlsx",
        "datos_economicos_normales_procesados.xlsx", 
        "datos_economicos_procesados_Fred.xlsx",
        "datos_economicos_other_procesados.xlsx",
        "datos_banco_republica_procesados.xlsx"
    ]
    
    for i, (nombre, success) in enumerate(resultados.items()):
        icono = "‚úÖ" if success else "‚ùå"
        archivo = archivos_esperados[i] if success else "No generado"
        print(f"   {icono} {nombre}: {archivo}")
    
    print(f"\nüéØ Estado general: {'EXITOSO' if exitosos >= 3 else 'PARCIAL' if exitosos > 0 else 'FALLIDO'}")
    print(f"üìÇ Ubicaci√≥n: data/0_raw/")
    
    return exitosos >= 3



# PROCESADOR DANE EXPORTACIONES - INTEGRADO AL SISTEMA
# Agregar este c√≥digo al archivo step_0_preprocess.py existente

import pandas as pd
import numpy as np
import os
import re
import time
import logging
from datetime import datetime, timedelta
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# CORRECCI√ìN DANE PROCESSOR - Reemplazar en step_0_preprocess.py

